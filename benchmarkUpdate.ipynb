{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "benchmarkUpdate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSfi7suitvMOK1G+EkUNkt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tenten0727/benchmarkUpdate1/blob/master/benchmarkUpdate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Vjn_nwu4i_k",
        "colab_type": "text"
      },
      "source": [
        "# googleマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJF2JyE94iD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "22c714f2-7577-4025-a511-e32d2c2ba907"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRRB4JeS33TO",
        "colab_type": "text"
      },
      "source": [
        "# ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEmOCznC4Ao8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8cd89369-6cec-40f6-9e9c-047f9d94bcb2"
      },
      "source": [
        "!pip install optuna\n",
        "import pandas as pd\n",
        "import optuna.integration.lightgbm as lgb\n",
        "import numpy as np\n",
        "import warnings\n",
        "import gc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from google.colab import files\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt \n",
        "import datetime\n",
        "import collections\n",
        "\n",
        "warnings.simplefilter('ignore')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/b0/9a6313c78bca92abfacc08a2ad8b27bfe845256f615786ee2b6452ae1978/optuna-2.0.0.tar.gz (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 3.2MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 6.1MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/06/03b1f92d46546a18eabf33ff7f37ef422c18c93d5a926bf590fee32ebe75/cliff-3.4.0-py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.3MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/63/88/d5e9b78151dce671d7e78ee4cc8905d83208254caa2a386b163ae0ab0027/cmaes-0.6.0-py3-none-any.whl\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/81/12d77537c82c5d46aa2721dfee25a0e873ef5920ebd0827152f411effb57/colorlog-4.2.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from optuna) (20.4)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.19)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/ba/aa953a11ec014b23df057ecdbc922fdb40ca8463466b1193f3367d2711a6/pbr-5.4.5-py2.py3-none-any.whl (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 15.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.15.0)\n",
            "Collecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/6c/60bfe4e7c3ae2e95b30925beba84371502fe06a1ed6a8b51bfd920b2a9c7/cmd2-1.3.8-py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 14.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/f4/041afc90e684f2b7d00a7f49abcbaf0b8c03e916bbc398ce49dce2a3c408/stevedore-3.2.0-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/5b/55866e1cde0f86f5eec59dab5de8a66628cb0d53da74b8dbc15ad8dabda3/pyperclip-1.8.0.tar.gz\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (49.6.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.1.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.1.0)\n",
            "Building wheels for collected packages: alembic\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159540 sha256=3f7408ab07a5b11d83d8502ad0161098567f0607976c6ba975afc8aabb0e7b46\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
            "Successfully built alembic\n",
            "Building wheels for collected packages: optuna, pyperclip\n",
            "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.0.0-cp36-none-any.whl size=312967 sha256=d7763f681c7640b89224965d5853148418abc78749645a3b434e46546bf370a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/c9/03/c45484454bf657ffed0ed6af153bd3d213928df115eb2a56eb\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.0-cp36-none-any.whl size=8693 sha256=3714d4e221ea3f42da5e2af31710f5c50935ab24220492bf9b2deb2d81264c75\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/ac/0a/b784f0afe26eaf52e88a7e15c7369090deea0354fa1c6fc689\n",
            "Successfully built optuna pyperclip\n",
            "Installing collected packages: python-editor, Mako, alembic, pbr, pyperclip, colorama, cmd2, stevedore, cliff, cmaes, colorlog, optuna\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.2 cliff-3.4.0 cmaes-0.6.0 cmd2-1.3.8 colorama-0.4.3 colorlog-4.2.1 optuna-2.0.0 pbr-5.4.5 pyperclip-1.8.0 python-editor-1.0.4 stevedore-3.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUK-E88F4aKr",
        "colab_type": "text"
      },
      "source": [
        "# data読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEsaV8uq4dtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('/content/gdrive/My Drive/SIGNATE/Beginner1/train.csv')\n",
        "test_df = pd.read_csv('/content/gdrive/My Drive/SIGNATE/Beginner1/test.csv')\n",
        "submit_df = pd.read_csv('/content/gdrive/My Drive/SIGNATE/Beginner1/submit_sample.csv',header=None)\n",
        "\n",
        "categorical_features = ['job', 'marital', 'education','default','housing','loan','contact','month','poutcome']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K73Idp-24cwU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "3807b7f4-a7c3-4185-a069-d0326d26a478"
      },
      "source": [
        "print(train_df['job'].unique())\n",
        "train_df.describe(include='all')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['services' 'entrepreneur' 'management' 'technician' 'unemployed'\n",
            " 'blue-collar' 'admin.' 'retired' 'self-employed' 'housemaid' 'student']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>27100.000000</td>\n",
              "      <td>27100.000000</td>\n",
              "      <td>27100</td>\n",
              "      <td>27100</td>\n",
              "      <td>27100</td>\n",
              "      <td>27100</td>\n",
              "      <td>27100.000000</td>\n",
              "      <td>27100</td>\n",
              "      <td>27100</td>\n",
              "      <td>27100</td>\n",
              "      <td>27100.000000</td>\n",
              "      <td>27100</td>\n",
              "      <td>27100.000000</td>\n",
              "      <td>27100.000000</td>\n",
              "      <td>27100.000000</td>\n",
              "      <td>27100.000000</td>\n",
              "      <td>27100</td>\n",
              "      <td>27100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>NaN</td>\n",
              "      <td>may</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>unknown</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5957</td>\n",
              "      <td>17565</td>\n",
              "      <td>15955</td>\n",
              "      <td>27090</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15819</td>\n",
              "      <td>23651</td>\n",
              "      <td>19147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11232</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23099</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13549.500000</td>\n",
              "      <td>36.073284</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47682.901771</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.747565</td>\n",
              "      <td>NaN</td>\n",
              "      <td>229.325387</td>\n",
              "      <td>1.775830</td>\n",
              "      <td>432.482399</td>\n",
              "      <td>0.085720</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.077934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7823.240484</td>\n",
              "      <td>7.816417</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31650.760036</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.569588</td>\n",
              "      <td>NaN</td>\n",
              "      <td>204.939958</td>\n",
              "      <td>0.950045</td>\n",
              "      <td>252.150648</td>\n",
              "      <td>0.365889</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.268072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-6847.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6774.750000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20015.750000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>214.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13549.500000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47624.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>432.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>20324.250000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75330.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>650.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>27099.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>102121.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3076.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>870.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id           age  ... poutcome             y\n",
              "count   27100.000000  27100.000000  ...    27100  27100.000000\n",
              "unique           NaN           NaN  ...        4           NaN\n",
              "top              NaN           NaN  ...  unknown           NaN\n",
              "freq             NaN           NaN  ...    23099           NaN\n",
              "mean    13549.500000     36.073284  ...      NaN      0.077934\n",
              "std      7823.240484      7.816417  ...      NaN      0.268072\n",
              "min         0.000000     22.000000  ...      NaN      0.000000\n",
              "25%      6774.750000     31.000000  ...      NaN      0.000000\n",
              "50%     13549.500000     33.000000  ...      NaN      0.000000\n",
              "75%     20324.250000     37.000000  ...      NaN      0.000000\n",
              "max     27099.000000     90.000000  ...      NaN      1.000000\n",
              "\n",
              "[11 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH-2L5ff4odN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "544a49d2-c923-4923-f7b4-620d134764da"
      },
      "source": [
        "print(test_df['job'].unique())\n",
        "test_df.describe(include='all')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['technician' 'services' 'admin.' 'management' 'blue-collar'\n",
            " 'self-employed' 'housemaid' 'unemployed' 'retired' 'entrepreneur'\n",
            " 'student' 'unknown']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>18050.000000</td>\n",
              "      <td>18050.000000</td>\n",
              "      <td>18050</td>\n",
              "      <td>18050</td>\n",
              "      <td>18050</td>\n",
              "      <td>18050</td>\n",
              "      <td>18050.000000</td>\n",
              "      <td>18050</td>\n",
              "      <td>18050</td>\n",
              "      <td>18050</td>\n",
              "      <td>18050.000000</td>\n",
              "      <td>18050</td>\n",
              "      <td>18050.000000</td>\n",
              "      <td>18050.000000</td>\n",
              "      <td>18050.000000</td>\n",
              "      <td>18050.000000</td>\n",
              "      <td>18050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>NaN</td>\n",
              "      <td>may</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>unknown</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4086</td>\n",
              "      <td>11653</td>\n",
              "      <td>10799</td>\n",
              "      <td>18046</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10418</td>\n",
              "      <td>15729</td>\n",
              "      <td>12607</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7586</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9024.500000</td>\n",
              "      <td>36.104266</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47158.451801</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.763934</td>\n",
              "      <td>NaN</td>\n",
              "      <td>229.315014</td>\n",
              "      <td>1.770083</td>\n",
              "      <td>436.171801</td>\n",
              "      <td>0.090859</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5210.730515</td>\n",
              "      <td>7.863805</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31469.525699</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.571112</td>\n",
              "      <td>NaN</td>\n",
              "      <td>208.796946</td>\n",
              "      <td>0.944872</td>\n",
              "      <td>251.392519</td>\n",
              "      <td>0.375801</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-6838.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4512.250000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19654.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>219.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9024.500000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>46886.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>436.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>13536.750000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>74178.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>345.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>654.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>18049.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>102124.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3076.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>870.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id           age  ...      previous poutcome\n",
              "count   18050.000000  18050.000000  ...  18050.000000    18050\n",
              "unique           NaN           NaN  ...           NaN        4\n",
              "top              NaN           NaN  ...           NaN  unknown\n",
              "freq             NaN           NaN  ...           NaN    15426\n",
              "mean     9024.500000     36.104266  ...      0.090859      NaN\n",
              "std      5210.730515      7.863805  ...      0.375801      NaN\n",
              "min         0.000000     20.000000  ...      0.000000      NaN\n",
              "25%      4512.250000     31.000000  ...      0.000000      NaN\n",
              "50%      9024.500000     33.000000  ...      0.000000      NaN\n",
              "75%     13536.750000     37.000000  ...      0.000000      NaN\n",
              "max     18049.000000     90.000000  ...      3.000000      NaN\n",
              "\n",
              "[11 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZf6w5W958v9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e9233750-c295-459f-dce0-a10be2ed6941"
      },
      "source": [
        "for column in test_df[categorical_features].columns:\n",
        "  dif_column = set(train_df[column].unique()) ^ set(test_df[column].unique())\n",
        "  print('%s: different %s' %(column,  dif_column))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "job: different {'unknown'}\n",
            "marital: different set()\n",
            "education: different set()\n",
            "default: different set()\n",
            "housing: different set()\n",
            "loan: different set()\n",
            "contact: different set()\n",
            "month: different set()\n",
            "poutcome: different set()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj5fxOlD5H_T",
        "colab_type": "text"
      },
      "source": [
        "# data量確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOiYLg2x5KDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73c1fbef-fb50-4fc2-c8e3-8c0f3ee61f39"
      },
      "source": [
        "train_df.shape, test_df.shape, submit_df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((27100, 18), (18050, 17), (18050, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v1PoI075o9Z",
        "colab_type": "text"
      },
      "source": [
        "# testデータがわかるようにダミーの目的変数を代入"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdTYJPtw5-0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['y']=-999"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u61s0wdA6MT3",
        "colab_type": "text"
      },
      "source": [
        "# trainデータ、testデータを結合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRs1caBG6TH9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9a8483f2-01f5-452c-ff62-29ba625f6c64"
      },
      "source": [
        "all_df = pd.concat([train_df, test_df])\n",
        "del train_df, test_df\n",
        "gc.collect()\n",
        "all_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>services</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>12294</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>21</td>\n",
              "      <td>nov</td>\n",
              "      <td>101</td>\n",
              "      <td>3</td>\n",
              "      <td>498</td>\n",
              "      <td>0</td>\n",
              "      <td>other</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>entrepreneur</td>\n",
              "      <td>single</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>43027</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>22</td>\n",
              "      <td>aug</td>\n",
              "      <td>158</td>\n",
              "      <td>2</td>\n",
              "      <td>702</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>35</td>\n",
              "      <td>management</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>12252</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>cellular</td>\n",
              "      <td>11</td>\n",
              "      <td>nov</td>\n",
              "      <td>351</td>\n",
              "      <td>1</td>\n",
              "      <td>826</td>\n",
              "      <td>0</td>\n",
              "      <td>failure</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "      <td>technician</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>99121</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>unknown</td>\n",
              "      <td>16</td>\n",
              "      <td>may</td>\n",
              "      <td>658</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>failure</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>48</td>\n",
              "      <td>unemployed</td>\n",
              "      <td>married</td>\n",
              "      <td>primary</td>\n",
              "      <td>no</td>\n",
              "      <td>42005</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>telephone</td>\n",
              "      <td>3</td>\n",
              "      <td>apr</td>\n",
              "      <td>177</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  age           job  marital  ... pdays previous  poutcome  y\n",
              "0   0   31      services  married  ...   498        0     other  0\n",
              "1   1   29  entrepreneur   single  ...   702        0   unknown  1\n",
              "2   2   35    management  married  ...   826        0   failure  0\n",
              "3   3   31    technician  married  ...   120        0   failure  0\n",
              "4   4   48    unemployed  married  ...   273        0   unknown  0\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d4ZY0ca7bzU",
        "colab_type": "text"
      },
      "source": [
        "# カテゴリカラムの前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFTsxhO_7ewU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in categorical_features:\n",
        "    lbl = preprocessing.LabelEncoder()\n",
        "    lbl.fit(all_df[col])\n",
        "    all_df[col]=lbl.transform(all_df[col])\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K5oaif8S0wO",
        "colab_type": "text"
      },
      "source": [
        "## ターゲットエンコーディング"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WksEM3NS5AX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0da1efa6-bbd3-46b6-904b-a616277bddfa"
      },
      "source": [
        "for category in categorical_features:\n",
        "  target_mean = all_df[all_df['y'] != -999].groupby(category).y.mean()\n",
        "  if(category == 'job'):\n",
        "    target_mean.loc[11] = np.mean(target_mean.values)\n",
        "  all_df['target_'+category] = all_df[category].map(target_mean)\n",
        "  print(target_mean)\n",
        "  all_df.drop(column, axis=1)\n",
        "\n",
        "all_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "job\n",
            "0     0.086602\n",
            "1     0.057915\n",
            "2     0.082251\n",
            "3     0.090186\n",
            "4     0.086607\n",
            "5     0.167331\n",
            "6     0.096303\n",
            "7     0.065965\n",
            "8     0.294618\n",
            "9     0.042930\n",
            "10    0.134591\n",
            "11    0.109573\n",
            "Name: y, dtype: float64\n",
            "marital\n",
            "0    0.064476\n",
            "1    0.062511\n",
            "2    0.120704\n",
            "Name: y, dtype: float64\n",
            "education\n",
            "0    0.065185\n",
            "1    0.064369\n",
            "2    0.104498\n",
            "3    0.151993\n",
            "Name: y, dtype: float64\n",
            "default\n",
            "0    0.077962\n",
            "1    0.000000\n",
            "Name: y, dtype: float64\n",
            "housing\n",
            "0    0.130219\n",
            "1    0.040647\n",
            "Name: y, dtype: float64\n",
            "loan\n",
            "0    0.084352\n",
            "1    0.033923\n",
            "Name: y, dtype: float64\n",
            "contact\n",
            "0    0.091346\n",
            "1    0.089674\n",
            "2    0.038546\n",
            "Name: y, dtype: float64\n",
            "month\n",
            "0     0.203491\n",
            "1     0.068323\n",
            "2     0.148661\n",
            "3     0.127424\n",
            "4     0.086786\n",
            "5     0.057032\n",
            "6     0.462617\n",
            "7     0.044160\n",
            "8     0.062852\n",
            "9     0.567010\n",
            "10    0.296296\n",
            "Name: y, dtype: float64\n",
            "poutcome\n",
            "0    0.043798\n",
            "1    0.048426\n",
            "2    0.679039\n",
            "3    0.071085\n",
            "Name: y, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "      <th>target_job</th>\n",
              "      <th>target_marital</th>\n",
              "      <th>target_education</th>\n",
              "      <th>target_default</th>\n",
              "      <th>target_housing</th>\n",
              "      <th>target_loan</th>\n",
              "      <th>target_contact</th>\n",
              "      <th>target_month</th>\n",
              "      <th>target_poutcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12294</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>8</td>\n",
              "      <td>101</td>\n",
              "      <td>3</td>\n",
              "      <td>498</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.065965</td>\n",
              "      <td>0.062511</td>\n",
              "      <td>0.064369</td>\n",
              "      <td>0.077962</td>\n",
              "      <td>0.040647</td>\n",
              "      <td>0.084352</td>\n",
              "      <td>0.091346</td>\n",
              "      <td>0.062852</td>\n",
              "      <td>0.048426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>43027</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>158</td>\n",
              "      <td>2</td>\n",
              "      <td>702</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.082251</td>\n",
              "      <td>0.120704</td>\n",
              "      <td>0.104498</td>\n",
              "      <td>0.077962</td>\n",
              "      <td>0.130219</td>\n",
              "      <td>0.084352</td>\n",
              "      <td>0.091346</td>\n",
              "      <td>0.068323</td>\n",
              "      <td>0.071085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>35</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>12252</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>351</td>\n",
              "      <td>1</td>\n",
              "      <td>826</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.086607</td>\n",
              "      <td>0.062511</td>\n",
              "      <td>0.104498</td>\n",
              "      <td>0.077962</td>\n",
              "      <td>0.040647</td>\n",
              "      <td>0.084352</td>\n",
              "      <td>0.091346</td>\n",
              "      <td>0.062852</td>\n",
              "      <td>0.043798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>99121</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>658</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.042930</td>\n",
              "      <td>0.062511</td>\n",
              "      <td>0.064369</td>\n",
              "      <td>0.077962</td>\n",
              "      <td>0.040647</td>\n",
              "      <td>0.033923</td>\n",
              "      <td>0.038546</td>\n",
              "      <td>0.044160</td>\n",
              "      <td>0.043798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>48</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42005</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>177</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.134591</td>\n",
              "      <td>0.062511</td>\n",
              "      <td>0.065185</td>\n",
              "      <td>0.077962</td>\n",
              "      <td>0.040647</td>\n",
              "      <td>0.084352</td>\n",
              "      <td>0.089674</td>\n",
              "      <td>0.203491</td>\n",
              "      <td>0.071085</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  age  job  ...  target_contact  target_month  target_poutcome\n",
              "0   0   31    7  ...        0.091346      0.062852         0.048426\n",
              "1   1   29    2  ...        0.091346      0.068323         0.071085\n",
              "2   2   35    4  ...        0.091346      0.062852         0.043798\n",
              "3   3   31    9  ...        0.038546      0.044160         0.043798\n",
              "4   4   48   10  ...        0.089674      0.203491         0.071085\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD_pCHwgNWGl",
        "colab_type": "text"
      },
      "source": [
        "## Count Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CMkdfsyNclI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for category in categorical_features:\n",
        "#   counters = collections.Counter(all_df[all_df['y'] != -999][category].values)\n",
        "#   all_df['count_'+category] = all_df[category].map(counters)\n",
        "#   all_df[category].drop\n",
        "\n",
        "# all_df.head()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCk9v1YeDVc4",
        "colab_type": "text"
      },
      "source": [
        "特徴量選択"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDyrEImC9uqJ",
        "colab_type": "text"
      },
      "source": [
        "# train, testに再度分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DQtJZ9y92Xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = all_df[all_df['y'] != -999]\n",
        "test_df = all_df[all_df['y'] == -999]\n",
        "\n",
        "y_train = train_df['y']\n",
        "X_train = train_df.drop(['y', 'id'], axis=1)\n",
        "X_test = test_df.drop(['y', 'id'], axis=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD4ze-sz-fKs",
        "colab_type": "text"
      },
      "source": [
        "# trainをさらに分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luvkU4mb-kIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=00.3, random_state=0, stratify=y_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D80aGGuW_Cye",
        "colab_type": "text"
      },
      "source": [
        "# ligitgbmを使用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu2bTWSJ_Jqp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91fbbdb0-b1e7-403f-84c6-994edea34e79"
      },
      "source": [
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
        "\n",
        "params = {\n",
        "    'objective': 'binary'\n",
        "}\n",
        "\n",
        "model = lgb.train(\n",
        "    params, lgb_train,\n",
        "    valid_sets=[lgb_train, lgb_eval],\n",
        "    verbose_eval=10,\n",
        "    num_boost_round=1000,\n",
        "    early_stopping_rounds=100\n",
        ")\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.214054\tvalid_1's binary_logloss: 0.220973\n",
            "[20]\ttraining's binary_logloss: 0.195542\tvalid_1's binary_logloss: 0.208762\n",
            "[30]\ttraining's binary_logloss: 0.183706\tvalid_1's binary_logloss: 0.203648\n",
            "[40]\ttraining's binary_logloss: 0.174593\tvalid_1's binary_logloss: 0.201398\n",
            "[50]\ttraining's binary_logloss: 0.167628\tvalid_1's binary_logloss: 0.200411\n",
            "[60]\ttraining's binary_logloss: 0.161442\tvalid_1's binary_logloss: 0.200033\n",
            "[70]\ttraining's binary_logloss: 0.155996\tvalid_1's binary_logloss: 0.200189\n",
            "[80]\ttraining's binary_logloss: 0.150372\tvalid_1's binary_logloss: 0.20047\n",
            "[90]\ttraining's binary_logloss: 0.145734\tvalid_1's binary_logloss: 0.200707\n",
            "[100]\ttraining's binary_logloss: 0.140852\tvalid_1's binary_logloss: 0.201224\n",
            "[110]\ttraining's binary_logloss: 0.136793\tvalid_1's binary_logloss: 0.2013\n",
            "[120]\ttraining's binary_logloss: 0.133069\tvalid_1's binary_logloss: 0.201861\n",
            "[130]\ttraining's binary_logloss: 0.129371\tvalid_1's binary_logloss: 0.202414\n",
            "[140]\ttraining's binary_logloss: 0.125771\tvalid_1's binary_logloss: 0.202761\n",
            "[150]\ttraining's binary_logloss: 0.12268\tvalid_1's binary_logloss: 0.203524\n",
            "Early stopping, best iteration is:\n",
            "[57]\ttraining's binary_logloss: 0.163349\tvalid_1's binary_logloss: 0.199886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.199886:  14%|#4        | 1/7 [00:00<00:05,  1.15it/s][I 2020-08-30 05:31:05,644] Trial 0 finished with value: 0.1998860080601817 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.1998860080601817.\n",
            "feature_fraction, val_score: 0.199886:  14%|#4        | 1/7 [00:00<00:05,  1.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.209841\tvalid_1's binary_logloss: 0.218468\n",
            "[20]\ttraining's binary_logloss: 0.191349\tvalid_1's binary_logloss: 0.207473\n",
            "[30]\ttraining's binary_logloss: 0.17956\tvalid_1's binary_logloss: 0.202755\n",
            "[40]\ttraining's binary_logloss: 0.170851\tvalid_1's binary_logloss: 0.201275\n",
            "[50]\ttraining's binary_logloss: 0.16389\tvalid_1's binary_logloss: 0.20022\n",
            "[60]\ttraining's binary_logloss: 0.15751\tvalid_1's binary_logloss: 0.200505\n",
            "[70]\ttraining's binary_logloss: 0.151727\tvalid_1's binary_logloss: 0.200493\n",
            "[80]\ttraining's binary_logloss: 0.146521\tvalid_1's binary_logloss: 0.200372\n",
            "[90]\ttraining's binary_logloss: 0.141188\tvalid_1's binary_logloss: 0.200884\n",
            "[100]\ttraining's binary_logloss: 0.136576\tvalid_1's binary_logloss: 0.201305\n",
            "[110]\ttraining's binary_logloss: 0.132505\tvalid_1's binary_logloss: 0.201641\n",
            "[120]\ttraining's binary_logloss: 0.12795\tvalid_1's binary_logloss: 0.202052\n",
            "[130]\ttraining's binary_logloss: 0.123371\tvalid_1's binary_logloss: 0.202561\n",
            "[140]\ttraining's binary_logloss: 0.11946\tvalid_1's binary_logloss: 0.202826\n",
            "[150]\ttraining's binary_logloss: 0.115802\tvalid_1's binary_logloss: 0.20343\n",
            "Early stopping, best iteration is:\n",
            "[50]\ttraining's binary_logloss: 0.16389\tvalid_1's binary_logloss: 0.20022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.199886:  29%|##8       | 2/7 [00:01<00:04,  1.17it/s][I 2020-08-30 05:31:06,449] Trial 1 finished with value: 0.20022017787875648 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.1998860080601817.\n",
            "feature_fraction, val_score: 0.199886:  29%|##8       | 2/7 [00:01<00:04,  1.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.209491\tvalid_1's binary_logloss: 0.21749\n",
            "[20]\ttraining's binary_logloss: 0.190543\tvalid_1's binary_logloss: 0.207661\n",
            "[30]\ttraining's binary_logloss: 0.17807\tvalid_1's binary_logloss: 0.202854\n",
            "[40]\ttraining's binary_logloss: 0.168671\tvalid_1's binary_logloss: 0.200912\n",
            "[50]\ttraining's binary_logloss: 0.161086\tvalid_1's binary_logloss: 0.200194\n",
            "[60]\ttraining's binary_logloss: 0.155031\tvalid_1's binary_logloss: 0.199958\n",
            "[70]\ttraining's binary_logloss: 0.148499\tvalid_1's binary_logloss: 0.200314\n",
            "[80]\ttraining's binary_logloss: 0.142576\tvalid_1's binary_logloss: 0.200578\n",
            "[90]\ttraining's binary_logloss: 0.137242\tvalid_1's binary_logloss: 0.201041\n",
            "[100]\ttraining's binary_logloss: 0.132731\tvalid_1's binary_logloss: 0.202096\n",
            "[110]\ttraining's binary_logloss: 0.128017\tvalid_1's binary_logloss: 0.202628\n",
            "[120]\ttraining's binary_logloss: 0.12372\tvalid_1's binary_logloss: 0.203405\n",
            "[130]\ttraining's binary_logloss: 0.119095\tvalid_1's binary_logloss: 0.203656\n",
            "[140]\ttraining's binary_logloss: 0.115763\tvalid_1's binary_logloss: 0.204193\n",
            "[150]\ttraining's binary_logloss: 0.111938\tvalid_1's binary_logloss: 0.204917\n",
            "[160]\ttraining's binary_logloss: 0.108016\tvalid_1's binary_logloss: 0.205228\n",
            "Early stopping, best iteration is:\n",
            "[66]\ttraining's binary_logloss: 0.150965\tvalid_1's binary_logloss: 0.199927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.199886:  43%|####2     | 3/7 [00:02<00:03,  1.18it/s][I 2020-08-30 05:31:07,296] Trial 2 finished with value: 0.19992650139641563 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.1998860080601817.\n",
            "feature_fraction, val_score: 0.199886:  43%|####2     | 3/7 [00:02<00:03,  1.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.209074\tvalid_1's binary_logloss: 0.218342\n",
            "[20]\ttraining's binary_logloss: 0.190616\tvalid_1's binary_logloss: 0.208175\n",
            "[30]\ttraining's binary_logloss: 0.178052\tvalid_1's binary_logloss: 0.204207\n",
            "[40]\ttraining's binary_logloss: 0.167757\tvalid_1's binary_logloss: 0.202241\n",
            "[50]\ttraining's binary_logloss: 0.159883\tvalid_1's binary_logloss: 0.202294\n",
            "[60]\ttraining's binary_logloss: 0.152339\tvalid_1's binary_logloss: 0.202388\n",
            "[70]\ttraining's binary_logloss: 0.145566\tvalid_1's binary_logloss: 0.203051\n",
            "[80]\ttraining's binary_logloss: 0.139767\tvalid_1's binary_logloss: 0.203394\n",
            "[90]\ttraining's binary_logloss: 0.13431\tvalid_1's binary_logloss: 0.203905\n",
            "[100]\ttraining's binary_logloss: 0.129172\tvalid_1's binary_logloss: 0.204612\n",
            "[110]\ttraining's binary_logloss: 0.124329\tvalid_1's binary_logloss: 0.20513\n",
            "[120]\ttraining's binary_logloss: 0.119585\tvalid_1's binary_logloss: 0.205312\n",
            "[130]\ttraining's binary_logloss: 0.115285\tvalid_1's binary_logloss: 0.206465\n",
            "[140]\ttraining's binary_logloss: 0.111303\tvalid_1's binary_logloss: 0.207087\n",
            "[150]\ttraining's binary_logloss: 0.107793\tvalid_1's binary_logloss: 0.207765\n",
            "Early stopping, best iteration is:\n",
            "[55]\ttraining's binary_logloss: 0.155863\tvalid_1's binary_logloss: 0.202015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.199886:  57%|#####7    | 4/7 [00:03<00:02,  1.18it/s][I 2020-08-30 05:31:08,133] Trial 3 finished with value: 0.20201499295653724 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.1998860080601817.\n",
            "feature_fraction, val_score: 0.199886:  57%|#####7    | 4/7 [00:03<00:02,  1.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.210896\tvalid_1's binary_logloss: 0.219362\n",
            "[20]\ttraining's binary_logloss: 0.192588\tvalid_1's binary_logloss: 0.207547\n",
            "[30]\ttraining's binary_logloss: 0.181539\tvalid_1's binary_logloss: 0.203026\n",
            "[40]\ttraining's binary_logloss: 0.172766\tvalid_1's binary_logloss: 0.201077\n",
            "[50]\ttraining's binary_logloss: 0.165286\tvalid_1's binary_logloss: 0.200031\n",
            "[60]\ttraining's binary_logloss: 0.159344\tvalid_1's binary_logloss: 0.19986\n",
            "[70]\ttraining's binary_logloss: 0.153258\tvalid_1's binary_logloss: 0.199941\n",
            "[80]\ttraining's binary_logloss: 0.148401\tvalid_1's binary_logloss: 0.200708\n",
            "[90]\ttraining's binary_logloss: 0.14375\tvalid_1's binary_logloss: 0.200993\n",
            "[100]\ttraining's binary_logloss: 0.139393\tvalid_1's binary_logloss: 0.20092\n",
            "[110]\ttraining's binary_logloss: 0.135765\tvalid_1's binary_logloss: 0.201521\n",
            "[120]\ttraining's binary_logloss: 0.131291\tvalid_1's binary_logloss: 0.201637\n",
            "[130]\ttraining's binary_logloss: 0.126983\tvalid_1's binary_logloss: 0.20186\n",
            "[140]\ttraining's binary_logloss: 0.123623\tvalid_1's binary_logloss: 0.202362\n",
            "[150]\ttraining's binary_logloss: 0.12003\tvalid_1's binary_logloss: 0.202685\n",
            "[160]\ttraining's binary_logloss: 0.116636\tvalid_1's binary_logloss: 0.202931\n",
            "Early stopping, best iteration is:\n",
            "[65]\ttraining's binary_logloss: 0.156663\tvalid_1's binary_logloss: 0.199679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.199679:  71%|#######1  | 5/7 [00:04<00:01,  1.21it/s][I 2020-08-30 05:31:08,908] Trial 4 finished with value: 0.19967889333503727 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 0.19967889333503727.\n",
            "feature_fraction, val_score: 0.199679:  71%|#######1  | 5/7 [00:04<00:01,  1.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.208796\tvalid_1's binary_logloss: 0.21839\n",
            "[20]\ttraining's binary_logloss: 0.19051\tvalid_1's binary_logloss: 0.208611\n",
            "[30]\ttraining's binary_logloss: 0.177152\tvalid_1's binary_logloss: 0.204434\n",
            "[40]\ttraining's binary_logloss: 0.167489\tvalid_1's binary_logloss: 0.202809\n",
            "[50]\ttraining's binary_logloss: 0.15937\tvalid_1's binary_logloss: 0.203028\n",
            "[60]\ttraining's binary_logloss: 0.151745\tvalid_1's binary_logloss: 0.203274\n",
            "[70]\ttraining's binary_logloss: 0.145076\tvalid_1's binary_logloss: 0.203639\n",
            "[80]\ttraining's binary_logloss: 0.139296\tvalid_1's binary_logloss: 0.204377\n",
            "[90]\ttraining's binary_logloss: 0.133775\tvalid_1's binary_logloss: 0.204822\n",
            "[100]\ttraining's binary_logloss: 0.12913\tvalid_1's binary_logloss: 0.205467\n",
            "[110]\ttraining's binary_logloss: 0.124078\tvalid_1's binary_logloss: 0.205928\n",
            "[120]\ttraining's binary_logloss: 0.119685\tvalid_1's binary_logloss: 0.20644\n",
            "[130]\ttraining's binary_logloss: 0.115864\tvalid_1's binary_logloss: 0.207439\n",
            "[140]\ttraining's binary_logloss: 0.111334\tvalid_1's binary_logloss: 0.208684\n",
            "Early stopping, best iteration is:\n",
            "[46]\ttraining's binary_logloss: 0.162336\tvalid_1's binary_logloss: 0.202649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.199679:  86%|########5 | 6/7 [00:04<00:00,  1.21it/s][I 2020-08-30 05:31:09,745] Trial 5 finished with value: 0.20264936045775314 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 0.19967889333503727.\n",
            "feature_fraction, val_score: 0.199679:  86%|########5 | 6/7 [00:04<00:00,  1.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.20938\tvalid_1's binary_logloss: 0.218108\n",
            "[20]\ttraining's binary_logloss: 0.191187\tvalid_1's binary_logloss: 0.207241\n",
            "[30]\ttraining's binary_logloss: 0.178924\tvalid_1's binary_logloss: 0.203009\n",
            "[40]\ttraining's binary_logloss: 0.169264\tvalid_1's binary_logloss: 0.201535\n",
            "[50]\ttraining's binary_logloss: 0.161453\tvalid_1's binary_logloss: 0.201461\n",
            "[60]\ttraining's binary_logloss: 0.154869\tvalid_1's binary_logloss: 0.201393\n",
            "[70]\ttraining's binary_logloss: 0.148924\tvalid_1's binary_logloss: 0.201709\n",
            "[80]\ttraining's binary_logloss: 0.143547\tvalid_1's binary_logloss: 0.201812\n",
            "[90]\ttraining's binary_logloss: 0.138056\tvalid_1's binary_logloss: 0.202265\n",
            "[100]\ttraining's binary_logloss: 0.133325\tvalid_1's binary_logloss: 0.20284\n",
            "[110]\ttraining's binary_logloss: 0.12854\tvalid_1's binary_logloss: 0.203399\n",
            "[120]\ttraining's binary_logloss: 0.124499\tvalid_1's binary_logloss: 0.203928\n",
            "[130]\ttraining's binary_logloss: 0.120172\tvalid_1's binary_logloss: 0.204583\n",
            "[140]\ttraining's binary_logloss: 0.11606\tvalid_1's binary_logloss: 0.205135\n",
            "Early stopping, best iteration is:\n",
            "[44]\ttraining's binary_logloss: 0.165777\tvalid_1's binary_logloss: 0.201232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction, val_score: 0.199679: 100%|##########| 7/7 [00:05<00:00,  1.25it/s][I 2020-08-30 05:31:10,484] Trial 6 finished with value: 0.20123184958832466 and parameters: {'feature_fraction': 0.7}. Best is trial 4 with value: 0.19967889333503727.\n",
            "feature_fraction, val_score: 0.199679: 100%|##########| 7/7 [00:05<00:00,  1.22it/s]\n",
            "num_leaves, val_score: 0.199679:   0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.212028\tvalid_1's binary_logloss: 0.219469\n",
            "[20]\ttraining's binary_logloss: 0.193959\tvalid_1's binary_logloss: 0.207771\n",
            "[30]\ttraining's binary_logloss: 0.183283\tvalid_1's binary_logloss: 0.20329\n",
            "[40]\ttraining's binary_logloss: 0.174583\tvalid_1's binary_logloss: 0.20127\n",
            "[50]\ttraining's binary_logloss: 0.167149\tvalid_1's binary_logloss: 0.200439\n",
            "[60]\ttraining's binary_logloss: 0.161268\tvalid_1's binary_logloss: 0.200273\n",
            "[70]\ttraining's binary_logloss: 0.155191\tvalid_1's binary_logloss: 0.200096\n",
            "[80]\ttraining's binary_logloss: 0.150213\tvalid_1's binary_logloss: 0.200668\n",
            "[90]\ttraining's binary_logloss: 0.145382\tvalid_1's binary_logloss: 0.201103\n",
            "[100]\ttraining's binary_logloss: 0.141371\tvalid_1's binary_logloss: 0.201544\n",
            "[110]\ttraining's binary_logloss: 0.137802\tvalid_1's binary_logloss: 0.201821\n",
            "[120]\ttraining's binary_logloss: 0.133944\tvalid_1's binary_logloss: 0.202512\n",
            "[130]\ttraining's binary_logloss: 0.130027\tvalid_1's binary_logloss: 0.20303\n",
            "[140]\ttraining's binary_logloss: 0.126665\tvalid_1's binary_logloss: 0.203351\n",
            "[150]\ttraining's binary_logloss: 0.12329\tvalid_1's binary_logloss: 0.203577\n",
            "[160]\ttraining's binary_logloss: 0.119595\tvalid_1's binary_logloss: 0.204228\n",
            "Early stopping, best iteration is:\n",
            "[69]\ttraining's binary_logloss: 0.155737\tvalid_1's binary_logloss: 0.200044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.199679:   5%|5         | 1/20 [00:00<00:14,  1.27it/s][I 2020-08-30 05:31:11,284] Trial 7 finished with value: 0.20004394705860823 and parameters: {'num_leaves': 29}. Best is trial 7 with value: 0.20004394705860823.\n",
            "num_leaves, val_score: 0.199679:   5%|5         | 1/20 [00:00<00:14,  1.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.182041\tvalid_1's binary_logloss: 0.216634\n",
            "[20]\ttraining's binary_logloss: 0.145854\tvalid_1's binary_logloss: 0.208138\n",
            "[30]\ttraining's binary_logloss: 0.12224\tvalid_1's binary_logloss: 0.205854\n",
            "[40]\ttraining's binary_logloss: 0.10236\tvalid_1's binary_logloss: 0.2071\n",
            "[50]\ttraining's binary_logloss: 0.0878609\tvalid_1's binary_logloss: 0.20819\n",
            "[60]\ttraining's binary_logloss: 0.0769008\tvalid_1's binary_logloss: 0.210224\n",
            "[70]\ttraining's binary_logloss: 0.0671325\tvalid_1's binary_logloss: 0.212618\n",
            "[80]\ttraining's binary_logloss: 0.0589551\tvalid_1's binary_logloss: 0.216053\n",
            "[90]\ttraining's binary_logloss: 0.0520369\tvalid_1's binary_logloss: 0.219327\n",
            "[100]\ttraining's binary_logloss: 0.0461242\tvalid_1's binary_logloss: 0.222259\n",
            "[110]\ttraining's binary_logloss: 0.0412452\tvalid_1's binary_logloss: 0.22534\n",
            "[120]\ttraining's binary_logloss: 0.0364979\tvalid_1's binary_logloss: 0.228661\n",
            "Early stopping, best iteration is:\n",
            "[29]\ttraining's binary_logloss: 0.124053\tvalid_1's binary_logloss: 0.20562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.199679:  10%|#         | 2/20 [00:01<00:15,  1.14it/s][I 2020-08-30 05:31:12,379] Trial 8 finished with value: 0.20562000356755764 and parameters: {'num_leaves': 146}. Best is trial 7 with value: 0.20004394705860823.\n",
            "num_leaves, val_score: 0.199679:  10%|#         | 2/20 [00:01<00:15,  1.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.202104\tvalid_1's binary_logloss: 0.21755\n",
            "[20]\ttraining's binary_logloss: 0.178738\tvalid_1's binary_logloss: 0.207467\n",
            "[30]\ttraining's binary_logloss: 0.163677\tvalid_1's binary_logloss: 0.203305\n",
            "[40]\ttraining's binary_logloss: 0.150989\tvalid_1's binary_logloss: 0.201586\n",
            "[50]\ttraining's binary_logloss: 0.141033\tvalid_1's binary_logloss: 0.201569\n",
            "[60]\ttraining's binary_logloss: 0.132487\tvalid_1's binary_logloss: 0.201772\n",
            "[70]\ttraining's binary_logloss: 0.125879\tvalid_1's binary_logloss: 0.202439\n",
            "[80]\ttraining's binary_logloss: 0.117911\tvalid_1's binary_logloss: 0.203642\n",
            "[90]\ttraining's binary_logloss: 0.111853\tvalid_1's binary_logloss: 0.204139\n",
            "[100]\ttraining's binary_logloss: 0.10656\tvalid_1's binary_logloss: 0.205276\n",
            "[110]\ttraining's binary_logloss: 0.101685\tvalid_1's binary_logloss: 0.206182\n",
            "[120]\ttraining's binary_logloss: 0.0963169\tvalid_1's binary_logloss: 0.207129\n",
            "[130]\ttraining's binary_logloss: 0.0915968\tvalid_1's binary_logloss: 0.207995\n",
            "[140]\ttraining's binary_logloss: 0.0869652\tvalid_1's binary_logloss: 0.208451\n",
            "Early stopping, best iteration is:\n",
            "[47]\ttraining's binary_logloss: 0.143749\tvalid_1's binary_logloss: 0.20137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.199679:  15%|#5        | 3/20 [00:02<00:15,  1.13it/s][I 2020-08-30 05:31:13,286] Trial 9 finished with value: 0.20137038948906325 and parameters: {'num_leaves': 55}. Best is trial 7 with value: 0.20004394705860823.\n",
            "num_leaves, val_score: 0.199679:  15%|#5        | 3/20 [00:02<00:15,  1.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.169001\tvalid_1's binary_logloss: 0.217188\n",
            "[20]\ttraining's binary_logloss: 0.124873\tvalid_1's binary_logloss: 0.209551\n",
            "[30]\ttraining's binary_logloss: 0.0971164\tvalid_1's binary_logloss: 0.208026\n",
            "[40]\ttraining's binary_logloss: 0.0741512\tvalid_1's binary_logloss: 0.211523\n",
            "[50]\ttraining's binary_logloss: 0.0585471\tvalid_1's binary_logloss: 0.215583\n",
            "[60]\ttraining's binary_logloss: 0.047063\tvalid_1's binary_logloss: 0.22049\n",
            "[70]\ttraining's binary_logloss: 0.0376761\tvalid_1's binary_logloss: 0.226898\n",
            "[80]\ttraining's binary_logloss: 0.0302639\tvalid_1's binary_logloss: 0.232853\n",
            "[90]\ttraining's binary_logloss: 0.0245087\tvalid_1's binary_logloss: 0.239663\n",
            "[100]\ttraining's binary_logloss: 0.0202301\tvalid_1's binary_logloss: 0.246508\n",
            "[110]\ttraining's binary_logloss: 0.0169648\tvalid_1's binary_logloss: 0.253349\n",
            "[120]\ttraining's binary_logloss: 0.0136268\tvalid_1's binary_logloss: 0.261111\n",
            "Early stopping, best iteration is:\n",
            "[29]\ttraining's binary_logloss: 0.0994834\tvalid_1's binary_logloss: 0.207666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.199679:  20%|##        | 4/20 [00:04<00:16,  1.06s/it][I 2020-08-30 05:31:14,752] Trial 10 finished with value: 0.2076656022753752 and parameters: {'num_leaves': 249}. Best is trial 7 with value: 0.20004394705860823.\n",
            "num_leaves, val_score: 0.199679:  20%|##        | 4/20 [00:04<00:16,  1.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.168457\tvalid_1's binary_logloss: 0.217011\n",
            "[20]\ttraining's binary_logloss: 0.12432\tvalid_1's binary_logloss: 0.209167\n",
            "[30]\ttraining's binary_logloss: 0.0962026\tvalid_1's binary_logloss: 0.207567\n",
            "[40]\ttraining's binary_logloss: 0.0735292\tvalid_1's binary_logloss: 0.211115\n",
            "[50]\ttraining's binary_logloss: 0.0580285\tvalid_1's binary_logloss: 0.215346\n",
            "[60]\ttraining's binary_logloss: 0.0465538\tvalid_1's binary_logloss: 0.219623\n",
            "[70]\ttraining's binary_logloss: 0.0371608\tvalid_1's binary_logloss: 0.225938\n",
            "[80]\ttraining's binary_logloss: 0.0296346\tvalid_1's binary_logloss: 0.233936\n",
            "[90]\ttraining's binary_logloss: 0.024337\tvalid_1's binary_logloss: 0.240713\n",
            "[100]\ttraining's binary_logloss: 0.0198511\tvalid_1's binary_logloss: 0.24777\n",
            "[110]\ttraining's binary_logloss: 0.01639\tvalid_1's binary_logloss: 0.254487\n",
            "[120]\ttraining's binary_logloss: 0.0130856\tvalid_1's binary_logloss: 0.263055\n",
            "Early stopping, best iteration is:\n",
            "[28]\ttraining's binary_logloss: 0.101371\tvalid_1's binary_logloss: 0.20727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.199679:  25%|##5       | 5/20 [00:05<00:17,  1.19s/it][I 2020-08-30 05:31:16,232] Trial 11 finished with value: 0.20727008788578855 and parameters: {'num_leaves': 255}. Best is trial 7 with value: 0.20004394705860823.\n",
            "num_leaves, val_score: 0.199679:  25%|##5       | 5/20 [00:05<00:17,  1.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.180888\tvalid_1's binary_logloss: 0.217146\n",
            "[20]\ttraining's binary_logloss: 0.14379\tvalid_1's binary_logloss: 0.208042\n",
            "[30]\ttraining's binary_logloss: 0.120074\tvalid_1's binary_logloss: 0.206022\n",
            "[40]\ttraining's binary_logloss: 0.100366\tvalid_1's binary_logloss: 0.207747\n",
            "[50]\ttraining's binary_logloss: 0.0855828\tvalid_1's binary_logloss: 0.209095\n",
            "[60]\ttraining's binary_logloss: 0.0740373\tvalid_1's binary_logloss: 0.211298\n",
            "[70]\ttraining's binary_logloss: 0.0639782\tvalid_1's binary_logloss: 0.214027\n",
            "[80]\ttraining's binary_logloss: 0.0550418\tvalid_1's binary_logloss: 0.217317\n",
            "[90]\ttraining's binary_logloss: 0.0481649\tvalid_1's binary_logloss: 0.220955\n",
            "[100]\ttraining's binary_logloss: 0.0425218\tvalid_1's binary_logloss: 0.224878\n",
            "[110]\ttraining's binary_logloss: 0.0378155\tvalid_1's binary_logloss: 0.227957\n",
            "[120]\ttraining's binary_logloss: 0.0330431\tvalid_1's binary_logloss: 0.232761\n",
            "Early stopping, best iteration is:\n",
            "[29]\ttraining's binary_logloss: 0.121969\tvalid_1's binary_logloss: 0.206006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.199679:  30%|###       | 6/20 [00:06<00:16,  1.17s/it][I 2020-08-30 05:31:17,363] Trial 12 finished with value: 0.20600556045905347 and parameters: {'num_leaves': 154}. Best is trial 7 with value: 0.20004394705860823.\n",
            "num_leaves, val_score: 0.199679:  30%|###       | 6/20 [00:06<00:16,  1.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.195295\tvalid_1's binary_logloss: 0.217843\n",
            "[20]\ttraining's binary_logloss: 0.168049\tvalid_1's binary_logloss: 0.207415\n",
            "[30]\ttraining's binary_logloss: 0.149873\tvalid_1's binary_logloss: 0.203776\n",
            "[40]\ttraining's binary_logloss: 0.134803\tvalid_1's binary_logloss: 0.203328\n",
            "[50]\ttraining's binary_logloss: 0.123121\tvalid_1's binary_logloss: 0.203006\n",
            "[60]\ttraining's binary_logloss: 0.113349\tvalid_1's binary_logloss: 0.203142\n",
            "[70]\ttraining's binary_logloss: 0.104537\tvalid_1's binary_logloss: 0.203742\n",
            "[80]\ttraining's binary_logloss: 0.0964693\tvalid_1's binary_logloss: 0.204798\n",
            "[90]\ttraining's binary_logloss: 0.089653\tvalid_1's binary_logloss: 0.206085\n",
            "[100]\ttraining's binary_logloss: 0.0840143\tvalid_1's binary_logloss: 0.207313\n",
            "[110]\ttraining's binary_logloss: 0.0789406\tvalid_1's binary_logloss: 0.208833\n",
            "[120]\ttraining's binary_logloss: 0.073481\tvalid_1's binary_logloss: 0.210322\n",
            "[130]\ttraining's binary_logloss: 0.0691318\tvalid_1's binary_logloss: 0.211878\n",
            "[140]\ttraining's binary_logloss: 0.0652569\tvalid_1's binary_logloss: 0.213336\n",
            "Early stopping, best iteration is:\n",
            "[48]\ttraining's binary_logloss: 0.125508\tvalid_1's binary_logloss: 0.202737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.199679:  35%|###5      | 7/20 [00:07<00:14,  1.11s/it][I 2020-08-30 05:31:18,317] Trial 13 finished with value: 0.2027366328757039 and parameters: {'num_leaves': 78}. Best is trial 7 with value: 0.20004394705860823.\n",
            "num_leaves, val_score: 0.199679:  35%|###5      | 7/20 [00:07<00:14,  1.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.173881\tvalid_1's binary_logloss: 0.21722\n",
            "[20]\ttraining's binary_logloss: 0.13311\tvalid_1's binary_logloss: 0.209528\n",
            "[30]\ttraining's binary_logloss: 0.106055\tvalid_1's binary_logloss: 0.207604\n",
            "[40]\ttraining's binary_logloss: 0.0840723\tvalid_1's binary_logloss: 0.210013\n",
            "[50]\ttraining's binary_logloss: 0.0687407\tvalid_1's binary_logloss: 0.212088\n",
            "[60]\ttraining's binary_logloss: 0.0573152\tvalid_1's binary_logloss: 0.215462\n",
            "[70]\ttraining's binary_logloss: 0.0472455\tvalid_1's binary_logloss: 0.2199\n",
            "[80]\ttraining's binary_logloss: 0.0390966\tvalid_1's binary_logloss: 0.22549\n",
            "[90]\ttraining's binary_logloss: 0.03269\tvalid_1's binary_logloss: 0.231479\n",
            "[100]\ttraining's binary_logloss: 0.0278358\tvalid_1's binary_logloss: 0.236744\n",
            "[110]\ttraining's binary_logloss: 0.0240028\tvalid_1's binary_logloss: 0.243184\n",
            "[120]\ttraining's binary_logloss: 0.0199671\tvalid_1's binary_logloss: 0.249758\n",
            "Early stopping, best iteration is:\n",
            "[27]\ttraining's binary_logloss: 0.113877\tvalid_1's binary_logloss: 0.207144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.199679:  40%|####      | 8/20 [00:09<00:13,  1.16s/it][I 2020-08-30 05:31:19,619] Trial 14 finished with value: 0.20714414377826976 and parameters: {'num_leaves': 204}. Best is trial 7 with value: 0.20004394705860823.\n",
            "num_leaves, val_score: 0.199679:  40%|####      | 8/20 [00:09<00:13,  1.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.238186\tvalid_1's binary_logloss: 0.238418\n",
            "[20]\ttraining's binary_logloss: 0.228601\tvalid_1's binary_logloss: 0.228767\n",
            "[30]\ttraining's binary_logloss: 0.223008\tvalid_1's binary_logloss: 0.22298\n",
            "[40]\ttraining's binary_logloss: 0.219329\tvalid_1's binary_logloss: 0.218817\n",
            "[50]\ttraining's binary_logloss: 0.216118\tvalid_1's binary_logloss: 0.215655\n",
            "[60]\ttraining's binary_logloss: 0.213661\tvalid_1's binary_logloss: 0.213283\n",
            "[70]\ttraining's binary_logloss: 0.211932\tvalid_1's binary_logloss: 0.211478\n",
            "[80]\ttraining's binary_logloss: 0.210351\tvalid_1's binary_logloss: 0.210086\n",
            "[90]\ttraining's binary_logloss: 0.208946\tvalid_1's binary_logloss: 0.208816\n",
            "[100]\ttraining's binary_logloss: 0.207716\tvalid_1's binary_logloss: 0.207705\n",
            "[110]\ttraining's binary_logloss: 0.206607\tvalid_1's binary_logloss: 0.206775\n",
            "[120]\ttraining's binary_logloss: 0.205671\tvalid_1's binary_logloss: 0.206162\n",
            "[130]\ttraining's binary_logloss: 0.204824\tvalid_1's binary_logloss: 0.205459\n",
            "[140]\ttraining's binary_logloss: 0.204076\tvalid_1's binary_logloss: 0.205075\n",
            "[150]\ttraining's binary_logloss: 0.20339\tvalid_1's binary_logloss: 0.204585\n",
            "[160]\ttraining's binary_logloss: 0.202749\tvalid_1's binary_logloss: 0.20417\n",
            "[170]\ttraining's binary_logloss: 0.20197\tvalid_1's binary_logloss: 0.20362\n",
            "[180]\ttraining's binary_logloss: 0.201271\tvalid_1's binary_logloss: 0.203375\n",
            "[190]\ttraining's binary_logloss: 0.200763\tvalid_1's binary_logloss: 0.203185\n",
            "[200]\ttraining's binary_logloss: 0.200162\tvalid_1's binary_logloss: 0.202751\n",
            "[210]\ttraining's binary_logloss: 0.199652\tvalid_1's binary_logloss: 0.202591\n",
            "[220]\ttraining's binary_logloss: 0.199156\tvalid_1's binary_logloss: 0.202414\n",
            "[230]\ttraining's binary_logloss: 0.198691\tvalid_1's binary_logloss: 0.202212\n",
            "[240]\ttraining's binary_logloss: 0.198185\tvalid_1's binary_logloss: 0.201971\n",
            "[250]\ttraining's binary_logloss: 0.197742\tvalid_1's binary_logloss: 0.201775\n",
            "[260]\ttraining's binary_logloss: 0.197164\tvalid_1's binary_logloss: 0.201344\n",
            "[270]\ttraining's binary_logloss: 0.196757\tvalid_1's binary_logloss: 0.201147\n",
            "[280]\ttraining's binary_logloss: 0.196261\tvalid_1's binary_logloss: 0.200889\n",
            "[290]\ttraining's binary_logloss: 0.195888\tvalid_1's binary_logloss: 0.200688\n",
            "[300]\ttraining's binary_logloss: 0.195511\tvalid_1's binary_logloss: 0.200448\n",
            "[310]\ttraining's binary_logloss: 0.195144\tvalid_1's binary_logloss: 0.200303\n",
            "[320]\ttraining's binary_logloss: 0.194802\tvalid_1's binary_logloss: 0.200179\n",
            "[330]\ttraining's binary_logloss: 0.194434\tvalid_1's binary_logloss: 0.200047\n",
            "[340]\ttraining's binary_logloss: 0.194089\tvalid_1's binary_logloss: 0.199951\n",
            "[350]\ttraining's binary_logloss: 0.193758\tvalid_1's binary_logloss: 0.199841\n",
            "[360]\ttraining's binary_logloss: 0.193441\tvalid_1's binary_logloss: 0.199772\n",
            "[370]\ttraining's binary_logloss: 0.193136\tvalid_1's binary_logloss: 0.199765\n",
            "[380]\ttraining's binary_logloss: 0.192853\tvalid_1's binary_logloss: 0.199722\n",
            "[390]\ttraining's binary_logloss: 0.192563\tvalid_1's binary_logloss: 0.199553\n",
            "[400]\ttraining's binary_logloss: 0.192281\tvalid_1's binary_logloss: 0.199506\n",
            "[410]\ttraining's binary_logloss: 0.19195\tvalid_1's binary_logloss: 0.199488\n",
            "[420]\ttraining's binary_logloss: 0.191697\tvalid_1's binary_logloss: 0.19941\n",
            "[430]\ttraining's binary_logloss: 0.191421\tvalid_1's binary_logloss: 0.199249\n",
            "[440]\ttraining's binary_logloss: 0.191152\tvalid_1's binary_logloss: 0.199287\n",
            "[450]\ttraining's binary_logloss: 0.190845\tvalid_1's binary_logloss: 0.199267\n",
            "[460]\ttraining's binary_logloss: 0.190633\tvalid_1's binary_logloss: 0.199172\n",
            "[470]\ttraining's binary_logloss: 0.190319\tvalid_1's binary_logloss: 0.199126\n",
            "[480]\ttraining's binary_logloss: 0.189999\tvalid_1's binary_logloss: 0.199017\n",
            "[490]\ttraining's binary_logloss: 0.189775\tvalid_1's binary_logloss: 0.198935\n",
            "[500]\ttraining's binary_logloss: 0.18954\tvalid_1's binary_logloss: 0.198884\n",
            "[510]\ttraining's binary_logloss: 0.189267\tvalid_1's binary_logloss: 0.198909\n",
            "[520]\ttraining's binary_logloss: 0.18901\tvalid_1's binary_logloss: 0.198929\n",
            "[530]\ttraining's binary_logloss: 0.18875\tvalid_1's binary_logloss: 0.198925\n",
            "[540]\ttraining's binary_logloss: 0.188548\tvalid_1's binary_logloss: 0.198903\n",
            "[550]\ttraining's binary_logloss: 0.188317\tvalid_1's binary_logloss: 0.199002\n",
            "[560]\ttraining's binary_logloss: 0.188047\tvalid_1's binary_logloss: 0.1989\n",
            "[570]\ttraining's binary_logloss: 0.187837\tvalid_1's binary_logloss: 0.198856\n",
            "[580]\ttraining's binary_logloss: 0.187597\tvalid_1's binary_logloss: 0.198855\n",
            "[590]\ttraining's binary_logloss: 0.187329\tvalid_1's binary_logloss: 0.1987\n",
            "[600]\ttraining's binary_logloss: 0.187165\tvalid_1's binary_logloss: 0.198719\n",
            "[610]\ttraining's binary_logloss: 0.186939\tvalid_1's binary_logloss: 0.198694\n",
            "[620]\ttraining's binary_logloss: 0.186688\tvalid_1's binary_logloss: 0.198779\n",
            "[630]\ttraining's binary_logloss: 0.186401\tvalid_1's binary_logloss: 0.198818\n",
            "[640]\ttraining's binary_logloss: 0.186155\tvalid_1's binary_logloss: 0.198746\n",
            "[650]\ttraining's binary_logloss: 0.185946\tvalid_1's binary_logloss: 0.19877\n",
            "[660]\ttraining's binary_logloss: 0.185721\tvalid_1's binary_logloss: 0.198719\n",
            "[670]\ttraining's binary_logloss: 0.185443\tvalid_1's binary_logloss: 0.198813\n",
            "[680]\ttraining's binary_logloss: 0.185225\tvalid_1's binary_logloss: 0.19872\n",
            "[690]\ttraining's binary_logloss: 0.18498\tvalid_1's binary_logloss: 0.198578\n",
            "[700]\ttraining's binary_logloss: 0.184792\tvalid_1's binary_logloss: 0.198514\n",
            "[710]\ttraining's binary_logloss: 0.184611\tvalid_1's binary_logloss: 0.198446\n",
            "[720]\ttraining's binary_logloss: 0.184411\tvalid_1's binary_logloss: 0.198492\n",
            "[730]\ttraining's binary_logloss: 0.184185\tvalid_1's binary_logloss: 0.198553\n",
            "[740]\ttraining's binary_logloss: 0.183997\tvalid_1's binary_logloss: 0.198614\n",
            "[750]\ttraining's binary_logloss: 0.183722\tvalid_1's binary_logloss: 0.198506\n",
            "[760]\ttraining's binary_logloss: 0.183517\tvalid_1's binary_logloss: 0.198482\n",
            "[770]\ttraining's binary_logloss: 0.183345\tvalid_1's binary_logloss: 0.198469\n",
            "[780]\ttraining's binary_logloss: 0.183166\tvalid_1's binary_logloss: 0.198471\n",
            "[790]\ttraining's binary_logloss: 0.183011\tvalid_1's binary_logloss: 0.198421\n",
            "[800]\ttraining's binary_logloss: 0.182817\tvalid_1's binary_logloss: 0.198422\n",
            "[810]\ttraining's binary_logloss: 0.182641\tvalid_1's binary_logloss: 0.198446\n",
            "[820]\ttraining's binary_logloss: 0.182454\tvalid_1's binary_logloss: 0.198437\n",
            "[830]\ttraining's binary_logloss: 0.182256\tvalid_1's binary_logloss: 0.198506\n",
            "[840]\ttraining's binary_logloss: 0.182019\tvalid_1's binary_logloss: 0.198416\n",
            "[850]\ttraining's binary_logloss: 0.181844\tvalid_1's binary_logloss: 0.198444\n",
            "[860]\ttraining's binary_logloss: 0.181632\tvalid_1's binary_logloss: 0.198519\n",
            "[870]\ttraining's binary_logloss: 0.181402\tvalid_1's binary_logloss: 0.198513\n",
            "[880]\ttraining's binary_logloss: 0.181228\tvalid_1's binary_logloss: 0.198514\n",
            "[890]\ttraining's binary_logloss: 0.180992\tvalid_1's binary_logloss: 0.198606\n",
            "[900]\ttraining's binary_logloss: 0.18076\tvalid_1's binary_logloss: 0.198592\n",
            "[910]\ttraining's binary_logloss: 0.180541\tvalid_1's binary_logloss: 0.198568\n",
            "[920]\ttraining's binary_logloss: 0.18033\tvalid_1's binary_logloss: 0.19864\n",
            "[930]\ttraining's binary_logloss: 0.180158\tvalid_1's binary_logloss: 0.198673\n",
            "Early stopping, best iteration is:\n",
            "[839]\ttraining's binary_logloss: 0.182055\tvalid_1's binary_logloss: 0.198392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.198392:  45%|####5     | 9/20 [00:12<00:19,  1.73s/it][I 2020-08-30 05:31:22,681] Trial 15 finished with value: 0.1983923473823983 and parameters: {'num_leaves': 3}. Best is trial 15 with value: 0.1983923473823983.\n",
            "num_leaves, val_score: 0.198392:  45%|####5     | 9/20 [00:12<00:19,  1.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169136\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.197935:  50%|#####     | 10/20 [00:13<00:17,  1.73s/it][I 2020-08-30 05:31:24,401] Trial 16 finished with value: 0.19793479158111074 and parameters: {'num_leaves': 5}. Best is trial 16 with value: 0.19793479158111074.\n",
            "num_leaves, val_score: 0.197935:  50%|#####     | 10/20 [00:13<00:17,  1.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.246756\tvalid_1's binary_logloss: 0.24609\n",
            "[20]\ttraining's binary_logloss: 0.237939\tvalid_1's binary_logloss: 0.237789\n",
            "[30]\ttraining's binary_logloss: 0.232906\tvalid_1's binary_logloss: 0.23284\n",
            "[40]\ttraining's binary_logloss: 0.229666\tvalid_1's binary_logloss: 0.229347\n",
            "[50]\ttraining's binary_logloss: 0.227085\tvalid_1's binary_logloss: 0.226586\n",
            "[60]\ttraining's binary_logloss: 0.225082\tvalid_1's binary_logloss: 0.224375\n",
            "[70]\ttraining's binary_logloss: 0.223405\tvalid_1's binary_logloss: 0.222642\n",
            "[80]\ttraining's binary_logloss: 0.221933\tvalid_1's binary_logloss: 0.221146\n",
            "[90]\ttraining's binary_logloss: 0.220618\tvalid_1's binary_logloss: 0.219793\n",
            "[100]\ttraining's binary_logloss: 0.219445\tvalid_1's binary_logloss: 0.218443\n",
            "[110]\ttraining's binary_logloss: 0.218408\tvalid_1's binary_logloss: 0.217326\n",
            "[120]\ttraining's binary_logloss: 0.217477\tvalid_1's binary_logloss: 0.216371\n",
            "[130]\ttraining's binary_logloss: 0.216606\tvalid_1's binary_logloss: 0.215539\n",
            "[140]\ttraining's binary_logloss: 0.215831\tvalid_1's binary_logloss: 0.214563\n",
            "[150]\ttraining's binary_logloss: 0.21511\tvalid_1's binary_logloss: 0.213858\n",
            "[160]\ttraining's binary_logloss: 0.214463\tvalid_1's binary_logloss: 0.2131\n",
            "[170]\ttraining's binary_logloss: 0.213854\tvalid_1's binary_logloss: 0.212572\n",
            "[180]\ttraining's binary_logloss: 0.213303\tvalid_1's binary_logloss: 0.211912\n",
            "[190]\ttraining's binary_logloss: 0.212796\tvalid_1's binary_logloss: 0.211422\n",
            "[200]\ttraining's binary_logloss: 0.212325\tvalid_1's binary_logloss: 0.210985\n",
            "[210]\ttraining's binary_logloss: 0.211888\tvalid_1's binary_logloss: 0.210473\n",
            "[220]\ttraining's binary_logloss: 0.211478\tvalid_1's binary_logloss: 0.210157\n",
            "[230]\ttraining's binary_logloss: 0.211099\tvalid_1's binary_logloss: 0.209814\n",
            "[240]\ttraining's binary_logloss: 0.210742\tvalid_1's binary_logloss: 0.209358\n",
            "[250]\ttraining's binary_logloss: 0.210407\tvalid_1's binary_logloss: 0.208975\n",
            "[260]\ttraining's binary_logloss: 0.210092\tvalid_1's binary_logloss: 0.208771\n",
            "[270]\ttraining's binary_logloss: 0.209796\tvalid_1's binary_logloss: 0.20852\n",
            "[280]\ttraining's binary_logloss: 0.209516\tvalid_1's binary_logloss: 0.208228\n",
            "[290]\ttraining's binary_logloss: 0.209249\tvalid_1's binary_logloss: 0.207988\n",
            "[300]\ttraining's binary_logloss: 0.209002\tvalid_1's binary_logloss: 0.207719\n",
            "[310]\ttraining's binary_logloss: 0.208758\tvalid_1's binary_logloss: 0.2075\n",
            "[320]\ttraining's binary_logloss: 0.208529\tvalid_1's binary_logloss: 0.207255\n",
            "[330]\ttraining's binary_logloss: 0.208309\tvalid_1's binary_logloss: 0.207139\n",
            "[340]\ttraining's binary_logloss: 0.208099\tvalid_1's binary_logloss: 0.20691\n",
            "[350]\ttraining's binary_logloss: 0.207897\tvalid_1's binary_logloss: 0.206703\n",
            "[360]\ttraining's binary_logloss: 0.207705\tvalid_1's binary_logloss: 0.206543\n",
            "[370]\ttraining's binary_logloss: 0.207521\tvalid_1's binary_logloss: 0.206349\n",
            "[380]\ttraining's binary_logloss: 0.207343\tvalid_1's binary_logloss: 0.206234\n",
            "[390]\ttraining's binary_logloss: 0.20717\tvalid_1's binary_logloss: 0.206085\n",
            "[400]\ttraining's binary_logloss: 0.207007\tvalid_1's binary_logloss: 0.205905\n",
            "[410]\ttraining's binary_logloss: 0.206851\tvalid_1's binary_logloss: 0.205754\n",
            "[420]\ttraining's binary_logloss: 0.2067\tvalid_1's binary_logloss: 0.205599\n",
            "[430]\ttraining's binary_logloss: 0.206553\tvalid_1's binary_logloss: 0.205521\n",
            "[440]\ttraining's binary_logloss: 0.206413\tvalid_1's binary_logloss: 0.205351\n",
            "[450]\ttraining's binary_logloss: 0.20628\tvalid_1's binary_logloss: 0.205225\n",
            "[460]\ttraining's binary_logloss: 0.206149\tvalid_1's binary_logloss: 0.205081\n",
            "[470]\ttraining's binary_logloss: 0.206024\tvalid_1's binary_logloss: 0.205008\n",
            "[480]\ttraining's binary_logloss: 0.205902\tvalid_1's binary_logloss: 0.204894\n",
            "[490]\ttraining's binary_logloss: 0.20578\tvalid_1's binary_logloss: 0.204822\n",
            "[500]\ttraining's binary_logloss: 0.205662\tvalid_1's binary_logloss: 0.204721\n",
            "[510]\ttraining's binary_logloss: 0.205548\tvalid_1's binary_logloss: 0.204647\n",
            "[520]\ttraining's binary_logloss: 0.205438\tvalid_1's binary_logloss: 0.204533\n",
            "[530]\ttraining's binary_logloss: 0.205329\tvalid_1's binary_logloss: 0.204449\n",
            "[540]\ttraining's binary_logloss: 0.205225\tvalid_1's binary_logloss: 0.204327\n",
            "[550]\ttraining's binary_logloss: 0.205121\tvalid_1's binary_logloss: 0.204196\n",
            "[560]\ttraining's binary_logloss: 0.20502\tvalid_1's binary_logloss: 0.20411\n",
            "[570]\ttraining's binary_logloss: 0.204922\tvalid_1's binary_logloss: 0.204011\n",
            "[580]\ttraining's binary_logloss: 0.204827\tvalid_1's binary_logloss: 0.203966\n",
            "[590]\ttraining's binary_logloss: 0.204735\tvalid_1's binary_logloss: 0.203936\n",
            "[600]\ttraining's binary_logloss: 0.204643\tvalid_1's binary_logloss: 0.203805\n",
            "[610]\ttraining's binary_logloss: 0.204555\tvalid_1's binary_logloss: 0.203762\n",
            "[620]\ttraining's binary_logloss: 0.204469\tvalid_1's binary_logloss: 0.20371\n",
            "[630]\ttraining's binary_logloss: 0.204383\tvalid_1's binary_logloss: 0.203608\n",
            "[640]\ttraining's binary_logloss: 0.2043\tvalid_1's binary_logloss: 0.203564\n",
            "[650]\ttraining's binary_logloss: 0.204219\tvalid_1's binary_logloss: 0.203494\n",
            "[660]\ttraining's binary_logloss: 0.20414\tvalid_1's binary_logloss: 0.203431\n",
            "[670]\ttraining's binary_logloss: 0.204064\tvalid_1's binary_logloss: 0.203324\n",
            "[680]\ttraining's binary_logloss: 0.203988\tvalid_1's binary_logloss: 0.203296\n",
            "[690]\ttraining's binary_logloss: 0.203915\tvalid_1's binary_logloss: 0.203245\n",
            "[700]\ttraining's binary_logloss: 0.203842\tvalid_1's binary_logloss: 0.20317\n",
            "[710]\ttraining's binary_logloss: 0.203771\tvalid_1's binary_logloss: 0.203108\n",
            "[720]\ttraining's binary_logloss: 0.203699\tvalid_1's binary_logloss: 0.203078\n",
            "[730]\ttraining's binary_logloss: 0.203629\tvalid_1's binary_logloss: 0.203043\n",
            "[740]\ttraining's binary_logloss: 0.20356\tvalid_1's binary_logloss: 0.202988\n",
            "[750]\ttraining's binary_logloss: 0.203492\tvalid_1's binary_logloss: 0.202918\n",
            "[760]\ttraining's binary_logloss: 0.203425\tvalid_1's binary_logloss: 0.202858\n",
            "[770]\ttraining's binary_logloss: 0.203359\tvalid_1's binary_logloss: 0.202812\n",
            "[780]\ttraining's binary_logloss: 0.203294\tvalid_1's binary_logloss: 0.202771\n",
            "[790]\ttraining's binary_logloss: 0.20323\tvalid_1's binary_logloss: 0.202778\n",
            "[800]\ttraining's binary_logloss: 0.203167\tvalid_1's binary_logloss: 0.202771\n",
            "[810]\ttraining's binary_logloss: 0.203105\tvalid_1's binary_logloss: 0.20271\n",
            "[820]\ttraining's binary_logloss: 0.203041\tvalid_1's binary_logloss: 0.202676\n",
            "[830]\ttraining's binary_logloss: 0.20298\tvalid_1's binary_logloss: 0.202604\n",
            "[840]\ttraining's binary_logloss: 0.202919\tvalid_1's binary_logloss: 0.202538\n",
            "[850]\ttraining's binary_logloss: 0.202859\tvalid_1's binary_logloss: 0.20251\n",
            "[860]\ttraining's binary_logloss: 0.2028\tvalid_1's binary_logloss: 0.202488\n",
            "[870]\ttraining's binary_logloss: 0.202741\tvalid_1's binary_logloss: 0.202454\n",
            "[880]\ttraining's binary_logloss: 0.202683\tvalid_1's binary_logloss: 0.202412\n",
            "[890]\ttraining's binary_logloss: 0.202625\tvalid_1's binary_logloss: 0.202393\n",
            "[900]\ttraining's binary_logloss: 0.202568\tvalid_1's binary_logloss: 0.202337\n",
            "[910]\ttraining's binary_logloss: 0.202513\tvalid_1's binary_logloss: 0.202308\n",
            "[920]\ttraining's binary_logloss: 0.202456\tvalid_1's binary_logloss: 0.202295\n",
            "[930]\ttraining's binary_logloss: 0.202401\tvalid_1's binary_logloss: 0.202238\n",
            "[940]\ttraining's binary_logloss: 0.202346\tvalid_1's binary_logloss: 0.202193\n",
            "[950]\ttraining's binary_logloss: 0.202293\tvalid_1's binary_logloss: 0.202195\n",
            "[960]\ttraining's binary_logloss: 0.202239\tvalid_1's binary_logloss: 0.202139\n",
            "[970]\ttraining's binary_logloss: 0.202186\tvalid_1's binary_logloss: 0.202119\n",
            "[980]\ttraining's binary_logloss: 0.202133\tvalid_1's binary_logloss: 0.202084\n",
            "[990]\ttraining's binary_logloss: 0.202082\tvalid_1's binary_logloss: 0.202079\n",
            "[1000]\ttraining's binary_logloss: 0.20203\tvalid_1's binary_logloss: 0.202058\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.20203\tvalid_1's binary_logloss: 0.202058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.197935:  55%|#####5    | 11/20 [00:17<00:19,  2.17s/it][I 2020-08-30 05:31:27,596] Trial 17 finished with value: 0.20205814268333028 and parameters: {'num_leaves': 2}. Best is trial 16 with value: 0.19793479158111074.\n",
            "num_leaves, val_score: 0.197935:  55%|#####5    | 11/20 [00:17<00:19,  2.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.238186\tvalid_1's binary_logloss: 0.238418\n",
            "[20]\ttraining's binary_logloss: 0.228601\tvalid_1's binary_logloss: 0.228767\n",
            "[30]\ttraining's binary_logloss: 0.223008\tvalid_1's binary_logloss: 0.22298\n",
            "[40]\ttraining's binary_logloss: 0.219329\tvalid_1's binary_logloss: 0.218817\n",
            "[50]\ttraining's binary_logloss: 0.216118\tvalid_1's binary_logloss: 0.215655\n",
            "[60]\ttraining's binary_logloss: 0.213661\tvalid_1's binary_logloss: 0.213283\n",
            "[70]\ttraining's binary_logloss: 0.211932\tvalid_1's binary_logloss: 0.211478\n",
            "[80]\ttraining's binary_logloss: 0.210351\tvalid_1's binary_logloss: 0.210086\n",
            "[90]\ttraining's binary_logloss: 0.208946\tvalid_1's binary_logloss: 0.208816\n",
            "[100]\ttraining's binary_logloss: 0.207716\tvalid_1's binary_logloss: 0.207705\n",
            "[110]\ttraining's binary_logloss: 0.206607\tvalid_1's binary_logloss: 0.206775\n",
            "[120]\ttraining's binary_logloss: 0.205671\tvalid_1's binary_logloss: 0.206162\n",
            "[130]\ttraining's binary_logloss: 0.204824\tvalid_1's binary_logloss: 0.205459\n",
            "[140]\ttraining's binary_logloss: 0.204076\tvalid_1's binary_logloss: 0.205075\n",
            "[150]\ttraining's binary_logloss: 0.20339\tvalid_1's binary_logloss: 0.204585\n",
            "[160]\ttraining's binary_logloss: 0.202749\tvalid_1's binary_logloss: 0.20417\n",
            "[170]\ttraining's binary_logloss: 0.20197\tvalid_1's binary_logloss: 0.20362\n",
            "[180]\ttraining's binary_logloss: 0.201271\tvalid_1's binary_logloss: 0.203375\n",
            "[190]\ttraining's binary_logloss: 0.200763\tvalid_1's binary_logloss: 0.203185\n",
            "[200]\ttraining's binary_logloss: 0.200162\tvalid_1's binary_logloss: 0.202751\n",
            "[210]\ttraining's binary_logloss: 0.199652\tvalid_1's binary_logloss: 0.202591\n",
            "[220]\ttraining's binary_logloss: 0.199156\tvalid_1's binary_logloss: 0.202414\n",
            "[230]\ttraining's binary_logloss: 0.198691\tvalid_1's binary_logloss: 0.202212\n",
            "[240]\ttraining's binary_logloss: 0.198185\tvalid_1's binary_logloss: 0.201971\n",
            "[250]\ttraining's binary_logloss: 0.197742\tvalid_1's binary_logloss: 0.201775\n",
            "[260]\ttraining's binary_logloss: 0.197164\tvalid_1's binary_logloss: 0.201344\n",
            "[270]\ttraining's binary_logloss: 0.196757\tvalid_1's binary_logloss: 0.201147\n",
            "[280]\ttraining's binary_logloss: 0.196261\tvalid_1's binary_logloss: 0.200889\n",
            "[290]\ttraining's binary_logloss: 0.195888\tvalid_1's binary_logloss: 0.200688\n",
            "[300]\ttraining's binary_logloss: 0.195511\tvalid_1's binary_logloss: 0.200448\n",
            "[310]\ttraining's binary_logloss: 0.195144\tvalid_1's binary_logloss: 0.200303\n",
            "[320]\ttraining's binary_logloss: 0.194802\tvalid_1's binary_logloss: 0.200179\n",
            "[330]\ttraining's binary_logloss: 0.194434\tvalid_1's binary_logloss: 0.200047\n",
            "[340]\ttraining's binary_logloss: 0.194089\tvalid_1's binary_logloss: 0.199951\n",
            "[350]\ttraining's binary_logloss: 0.193758\tvalid_1's binary_logloss: 0.199841\n",
            "[360]\ttraining's binary_logloss: 0.193441\tvalid_1's binary_logloss: 0.199772\n",
            "[370]\ttraining's binary_logloss: 0.193136\tvalid_1's binary_logloss: 0.199765\n",
            "[380]\ttraining's binary_logloss: 0.192853\tvalid_1's binary_logloss: 0.199722\n",
            "[390]\ttraining's binary_logloss: 0.192563\tvalid_1's binary_logloss: 0.199553\n",
            "[400]\ttraining's binary_logloss: 0.192281\tvalid_1's binary_logloss: 0.199506\n",
            "[410]\ttraining's binary_logloss: 0.19195\tvalid_1's binary_logloss: 0.199488\n",
            "[420]\ttraining's binary_logloss: 0.191697\tvalid_1's binary_logloss: 0.19941\n",
            "[430]\ttraining's binary_logloss: 0.191421\tvalid_1's binary_logloss: 0.199249\n",
            "[440]\ttraining's binary_logloss: 0.191152\tvalid_1's binary_logloss: 0.199287\n",
            "[450]\ttraining's binary_logloss: 0.190845\tvalid_1's binary_logloss: 0.199267\n",
            "[460]\ttraining's binary_logloss: 0.190633\tvalid_1's binary_logloss: 0.199172\n",
            "[470]\ttraining's binary_logloss: 0.190319\tvalid_1's binary_logloss: 0.199126\n",
            "[480]\ttraining's binary_logloss: 0.189999\tvalid_1's binary_logloss: 0.199017\n",
            "[490]\ttraining's binary_logloss: 0.189775\tvalid_1's binary_logloss: 0.198935\n",
            "[500]\ttraining's binary_logloss: 0.18954\tvalid_1's binary_logloss: 0.198884\n",
            "[510]\ttraining's binary_logloss: 0.189267\tvalid_1's binary_logloss: 0.198909\n",
            "[520]\ttraining's binary_logloss: 0.18901\tvalid_1's binary_logloss: 0.198929\n",
            "[530]\ttraining's binary_logloss: 0.18875\tvalid_1's binary_logloss: 0.198925\n",
            "[540]\ttraining's binary_logloss: 0.188548\tvalid_1's binary_logloss: 0.198903\n",
            "[550]\ttraining's binary_logloss: 0.188317\tvalid_1's binary_logloss: 0.199002\n",
            "[560]\ttraining's binary_logloss: 0.188047\tvalid_1's binary_logloss: 0.1989\n",
            "[570]\ttraining's binary_logloss: 0.187837\tvalid_1's binary_logloss: 0.198856\n",
            "[580]\ttraining's binary_logloss: 0.187597\tvalid_1's binary_logloss: 0.198855\n",
            "[590]\ttraining's binary_logloss: 0.187329\tvalid_1's binary_logloss: 0.1987\n",
            "[600]\ttraining's binary_logloss: 0.187165\tvalid_1's binary_logloss: 0.198719\n",
            "[610]\ttraining's binary_logloss: 0.186939\tvalid_1's binary_logloss: 0.198694\n",
            "[620]\ttraining's binary_logloss: 0.186688\tvalid_1's binary_logloss: 0.198779\n",
            "[630]\ttraining's binary_logloss: 0.186401\tvalid_1's binary_logloss: 0.198818\n",
            "[640]\ttraining's binary_logloss: 0.186155\tvalid_1's binary_logloss: 0.198746\n",
            "[650]\ttraining's binary_logloss: 0.185946\tvalid_1's binary_logloss: 0.19877\n",
            "[660]\ttraining's binary_logloss: 0.185721\tvalid_1's binary_logloss: 0.198719\n",
            "[670]\ttraining's binary_logloss: 0.185443\tvalid_1's binary_logloss: 0.198813\n",
            "[680]\ttraining's binary_logloss: 0.185225\tvalid_1's binary_logloss: 0.19872\n",
            "[690]\ttraining's binary_logloss: 0.18498\tvalid_1's binary_logloss: 0.198578\n",
            "[700]\ttraining's binary_logloss: 0.184792\tvalid_1's binary_logloss: 0.198514\n",
            "[710]\ttraining's binary_logloss: 0.184611\tvalid_1's binary_logloss: 0.198446\n",
            "[720]\ttraining's binary_logloss: 0.184411\tvalid_1's binary_logloss: 0.198492\n",
            "[730]\ttraining's binary_logloss: 0.184185\tvalid_1's binary_logloss: 0.198553\n",
            "[740]\ttraining's binary_logloss: 0.183997\tvalid_1's binary_logloss: 0.198614\n",
            "[750]\ttraining's binary_logloss: 0.183722\tvalid_1's binary_logloss: 0.198506\n",
            "[760]\ttraining's binary_logloss: 0.183517\tvalid_1's binary_logloss: 0.198482\n",
            "[770]\ttraining's binary_logloss: 0.183345\tvalid_1's binary_logloss: 0.198469\n",
            "[780]\ttraining's binary_logloss: 0.183166\tvalid_1's binary_logloss: 0.198471\n",
            "[790]\ttraining's binary_logloss: 0.183011\tvalid_1's binary_logloss: 0.198421\n",
            "[800]\ttraining's binary_logloss: 0.182817\tvalid_1's binary_logloss: 0.198422\n",
            "[810]\ttraining's binary_logloss: 0.182641\tvalid_1's binary_logloss: 0.198446\n",
            "[820]\ttraining's binary_logloss: 0.182454\tvalid_1's binary_logloss: 0.198437\n",
            "[830]\ttraining's binary_logloss: 0.182256\tvalid_1's binary_logloss: 0.198506\n",
            "[840]\ttraining's binary_logloss: 0.182019\tvalid_1's binary_logloss: 0.198416\n",
            "[850]\ttraining's binary_logloss: 0.181844\tvalid_1's binary_logloss: 0.198444\n",
            "[860]\ttraining's binary_logloss: 0.181632\tvalid_1's binary_logloss: 0.198519\n",
            "[870]\ttraining's binary_logloss: 0.181402\tvalid_1's binary_logloss: 0.198513\n",
            "[880]\ttraining's binary_logloss: 0.181228\tvalid_1's binary_logloss: 0.198514\n",
            "[890]\ttraining's binary_logloss: 0.180992\tvalid_1's binary_logloss: 0.198606\n",
            "[900]\ttraining's binary_logloss: 0.18076\tvalid_1's binary_logloss: 0.198592\n",
            "[910]\ttraining's binary_logloss: 0.180541\tvalid_1's binary_logloss: 0.198568\n",
            "[920]\ttraining's binary_logloss: 0.18033\tvalid_1's binary_logloss: 0.19864\n",
            "[930]\ttraining's binary_logloss: 0.180158\tvalid_1's binary_logloss: 0.198673\n",
            "Early stopping, best iteration is:\n",
            "[839]\ttraining's binary_logloss: 0.182055\tvalid_1's binary_logloss: 0.198392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.197935:  60%|######    | 12/20 [00:20<00:19,  2.47s/it][I 2020-08-30 05:31:30,755] Trial 18 finished with value: 0.1983923473823983 and parameters: {'num_leaves': 3}. Best is trial 16 with value: 0.19793479158111074.\n",
            "num_leaves, val_score: 0.197935:  60%|######    | 12/20 [00:20<00:19,  2.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.192808\tvalid_1's binary_logloss: 0.217356\n",
            "[20]\ttraining's binary_logloss: 0.163851\tvalid_1's binary_logloss: 0.207483\n",
            "[30]\ttraining's binary_logloss: 0.14481\tvalid_1's binary_logloss: 0.204026\n",
            "[40]\ttraining's binary_logloss: 0.128138\tvalid_1's binary_logloss: 0.203803\n",
            "[50]\ttraining's binary_logloss: 0.115782\tvalid_1's binary_logloss: 0.203218\n",
            "[60]\ttraining's binary_logloss: 0.105994\tvalid_1's binary_logloss: 0.204275\n",
            "[70]\ttraining's binary_logloss: 0.0968005\tvalid_1's binary_logloss: 0.205683\n",
            "[80]\ttraining's binary_logloss: 0.0887833\tvalid_1's binary_logloss: 0.206865\n",
            "[90]\ttraining's binary_logloss: 0.081621\tvalid_1's binary_logloss: 0.208435\n",
            "[100]\ttraining's binary_logloss: 0.0757351\tvalid_1's binary_logloss: 0.21043\n",
            "[110]\ttraining's binary_logloss: 0.0707114\tvalid_1's binary_logloss: 0.211854\n",
            "[120]\ttraining's binary_logloss: 0.0651232\tvalid_1's binary_logloss: 0.2136\n",
            "[130]\ttraining's binary_logloss: 0.0600727\tvalid_1's binary_logloss: 0.215432\n",
            "[140]\ttraining's binary_logloss: 0.0559457\tvalid_1's binary_logloss: 0.21691\n",
            "Early stopping, best iteration is:\n",
            "[46]\ttraining's binary_logloss: 0.120767\tvalid_1's binary_logloss: 0.20284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.197935:  65%|######5   | 13/20 [00:21<00:14,  2.04s/it][I 2020-08-30 05:31:31,792] Trial 19 finished with value: 0.20283978706765196 and parameters: {'num_leaves': 89}. Best is trial 16 with value: 0.19793479158111074.\n",
            "num_leaves, val_score: 0.197935:  65%|######5   | 13/20 [00:21<00:14,  2.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.238186\tvalid_1's binary_logloss: 0.238418\n",
            "[20]\ttraining's binary_logloss: 0.228601\tvalid_1's binary_logloss: 0.228767\n",
            "[30]\ttraining's binary_logloss: 0.223008\tvalid_1's binary_logloss: 0.22298\n",
            "[40]\ttraining's binary_logloss: 0.219329\tvalid_1's binary_logloss: 0.218817\n",
            "[50]\ttraining's binary_logloss: 0.216118\tvalid_1's binary_logloss: 0.215655\n",
            "[60]\ttraining's binary_logloss: 0.213661\tvalid_1's binary_logloss: 0.213283\n",
            "[70]\ttraining's binary_logloss: 0.211932\tvalid_1's binary_logloss: 0.211478\n",
            "[80]\ttraining's binary_logloss: 0.210351\tvalid_1's binary_logloss: 0.210086\n",
            "[90]\ttraining's binary_logloss: 0.208946\tvalid_1's binary_logloss: 0.208816\n",
            "[100]\ttraining's binary_logloss: 0.207716\tvalid_1's binary_logloss: 0.207705\n",
            "[110]\ttraining's binary_logloss: 0.206607\tvalid_1's binary_logloss: 0.206775\n",
            "[120]\ttraining's binary_logloss: 0.205671\tvalid_1's binary_logloss: 0.206162\n",
            "[130]\ttraining's binary_logloss: 0.204824\tvalid_1's binary_logloss: 0.205459\n",
            "[140]\ttraining's binary_logloss: 0.204076\tvalid_1's binary_logloss: 0.205075\n",
            "[150]\ttraining's binary_logloss: 0.20339\tvalid_1's binary_logloss: 0.204585\n",
            "[160]\ttraining's binary_logloss: 0.202749\tvalid_1's binary_logloss: 0.20417\n",
            "[170]\ttraining's binary_logloss: 0.20197\tvalid_1's binary_logloss: 0.20362\n",
            "[180]\ttraining's binary_logloss: 0.201271\tvalid_1's binary_logloss: 0.203375\n",
            "[190]\ttraining's binary_logloss: 0.200763\tvalid_1's binary_logloss: 0.203185\n",
            "[200]\ttraining's binary_logloss: 0.200162\tvalid_1's binary_logloss: 0.202751\n",
            "[210]\ttraining's binary_logloss: 0.199652\tvalid_1's binary_logloss: 0.202591\n",
            "[220]\ttraining's binary_logloss: 0.199156\tvalid_1's binary_logloss: 0.202414\n",
            "[230]\ttraining's binary_logloss: 0.198691\tvalid_1's binary_logloss: 0.202212\n",
            "[240]\ttraining's binary_logloss: 0.198185\tvalid_1's binary_logloss: 0.201971\n",
            "[250]\ttraining's binary_logloss: 0.197742\tvalid_1's binary_logloss: 0.201775\n",
            "[260]\ttraining's binary_logloss: 0.197164\tvalid_1's binary_logloss: 0.201344\n",
            "[270]\ttraining's binary_logloss: 0.196757\tvalid_1's binary_logloss: 0.201147\n",
            "[280]\ttraining's binary_logloss: 0.196261\tvalid_1's binary_logloss: 0.200889\n",
            "[290]\ttraining's binary_logloss: 0.195888\tvalid_1's binary_logloss: 0.200688\n",
            "[300]\ttraining's binary_logloss: 0.195511\tvalid_1's binary_logloss: 0.200448\n",
            "[310]\ttraining's binary_logloss: 0.195144\tvalid_1's binary_logloss: 0.200303\n",
            "[320]\ttraining's binary_logloss: 0.194802\tvalid_1's binary_logloss: 0.200179\n",
            "[330]\ttraining's binary_logloss: 0.194434\tvalid_1's binary_logloss: 0.200047\n",
            "[340]\ttraining's binary_logloss: 0.194089\tvalid_1's binary_logloss: 0.199951\n",
            "[350]\ttraining's binary_logloss: 0.193758\tvalid_1's binary_logloss: 0.199841\n",
            "[360]\ttraining's binary_logloss: 0.193441\tvalid_1's binary_logloss: 0.199772\n",
            "[370]\ttraining's binary_logloss: 0.193136\tvalid_1's binary_logloss: 0.199765\n",
            "[380]\ttraining's binary_logloss: 0.192853\tvalid_1's binary_logloss: 0.199722\n",
            "[390]\ttraining's binary_logloss: 0.192563\tvalid_1's binary_logloss: 0.199553\n",
            "[400]\ttraining's binary_logloss: 0.192281\tvalid_1's binary_logloss: 0.199506\n",
            "[410]\ttraining's binary_logloss: 0.19195\tvalid_1's binary_logloss: 0.199488\n",
            "[420]\ttraining's binary_logloss: 0.191697\tvalid_1's binary_logloss: 0.19941\n",
            "[430]\ttraining's binary_logloss: 0.191421\tvalid_1's binary_logloss: 0.199249\n",
            "[440]\ttraining's binary_logloss: 0.191152\tvalid_1's binary_logloss: 0.199287\n",
            "[450]\ttraining's binary_logloss: 0.190845\tvalid_1's binary_logloss: 0.199267\n",
            "[460]\ttraining's binary_logloss: 0.190633\tvalid_1's binary_logloss: 0.199172\n",
            "[470]\ttraining's binary_logloss: 0.190319\tvalid_1's binary_logloss: 0.199126\n",
            "[480]\ttraining's binary_logloss: 0.189999\tvalid_1's binary_logloss: 0.199017\n",
            "[490]\ttraining's binary_logloss: 0.189775\tvalid_1's binary_logloss: 0.198935\n",
            "[500]\ttraining's binary_logloss: 0.18954\tvalid_1's binary_logloss: 0.198884\n",
            "[510]\ttraining's binary_logloss: 0.189267\tvalid_1's binary_logloss: 0.198909\n",
            "[520]\ttraining's binary_logloss: 0.18901\tvalid_1's binary_logloss: 0.198929\n",
            "[530]\ttraining's binary_logloss: 0.18875\tvalid_1's binary_logloss: 0.198925\n",
            "[540]\ttraining's binary_logloss: 0.188548\tvalid_1's binary_logloss: 0.198903\n",
            "[550]\ttraining's binary_logloss: 0.188317\tvalid_1's binary_logloss: 0.199002\n",
            "[560]\ttraining's binary_logloss: 0.188047\tvalid_1's binary_logloss: 0.1989\n",
            "[570]\ttraining's binary_logloss: 0.187837\tvalid_1's binary_logloss: 0.198856\n",
            "[580]\ttraining's binary_logloss: 0.187597\tvalid_1's binary_logloss: 0.198855\n",
            "[590]\ttraining's binary_logloss: 0.187329\tvalid_1's binary_logloss: 0.1987\n",
            "[600]\ttraining's binary_logloss: 0.187165\tvalid_1's binary_logloss: 0.198719\n",
            "[610]\ttraining's binary_logloss: 0.186939\tvalid_1's binary_logloss: 0.198694\n",
            "[620]\ttraining's binary_logloss: 0.186688\tvalid_1's binary_logloss: 0.198779\n",
            "[630]\ttraining's binary_logloss: 0.186401\tvalid_1's binary_logloss: 0.198818\n",
            "[640]\ttraining's binary_logloss: 0.186155\tvalid_1's binary_logloss: 0.198746\n",
            "[650]\ttraining's binary_logloss: 0.185946\tvalid_1's binary_logloss: 0.19877\n",
            "[660]\ttraining's binary_logloss: 0.185721\tvalid_1's binary_logloss: 0.198719\n",
            "[670]\ttraining's binary_logloss: 0.185443\tvalid_1's binary_logloss: 0.198813\n",
            "[680]\ttraining's binary_logloss: 0.185225\tvalid_1's binary_logloss: 0.19872\n",
            "[690]\ttraining's binary_logloss: 0.18498\tvalid_1's binary_logloss: 0.198578\n",
            "[700]\ttraining's binary_logloss: 0.184792\tvalid_1's binary_logloss: 0.198514\n",
            "[710]\ttraining's binary_logloss: 0.184611\tvalid_1's binary_logloss: 0.198446\n",
            "[720]\ttraining's binary_logloss: 0.184411\tvalid_1's binary_logloss: 0.198492\n",
            "[730]\ttraining's binary_logloss: 0.184185\tvalid_1's binary_logloss: 0.198553\n",
            "[740]\ttraining's binary_logloss: 0.183997\tvalid_1's binary_logloss: 0.198614\n",
            "[750]\ttraining's binary_logloss: 0.183722\tvalid_1's binary_logloss: 0.198506\n",
            "[760]\ttraining's binary_logloss: 0.183517\tvalid_1's binary_logloss: 0.198482\n",
            "[770]\ttraining's binary_logloss: 0.183345\tvalid_1's binary_logloss: 0.198469\n",
            "[780]\ttraining's binary_logloss: 0.183166\tvalid_1's binary_logloss: 0.198471\n",
            "[790]\ttraining's binary_logloss: 0.183011\tvalid_1's binary_logloss: 0.198421\n",
            "[800]\ttraining's binary_logloss: 0.182817\tvalid_1's binary_logloss: 0.198422\n",
            "[810]\ttraining's binary_logloss: 0.182641\tvalid_1's binary_logloss: 0.198446\n",
            "[820]\ttraining's binary_logloss: 0.182454\tvalid_1's binary_logloss: 0.198437\n",
            "[830]\ttraining's binary_logloss: 0.182256\tvalid_1's binary_logloss: 0.198506\n",
            "[840]\ttraining's binary_logloss: 0.182019\tvalid_1's binary_logloss: 0.198416\n",
            "[850]\ttraining's binary_logloss: 0.181844\tvalid_1's binary_logloss: 0.198444\n",
            "[860]\ttraining's binary_logloss: 0.181632\tvalid_1's binary_logloss: 0.198519\n",
            "[870]\ttraining's binary_logloss: 0.181402\tvalid_1's binary_logloss: 0.198513\n",
            "[880]\ttraining's binary_logloss: 0.181228\tvalid_1's binary_logloss: 0.198514\n",
            "[890]\ttraining's binary_logloss: 0.180992\tvalid_1's binary_logloss: 0.198606\n",
            "[900]\ttraining's binary_logloss: 0.18076\tvalid_1's binary_logloss: 0.198592\n",
            "[910]\ttraining's binary_logloss: 0.180541\tvalid_1's binary_logloss: 0.198568\n",
            "[920]\ttraining's binary_logloss: 0.18033\tvalid_1's binary_logloss: 0.19864\n",
            "[930]\ttraining's binary_logloss: 0.180158\tvalid_1's binary_logloss: 0.198673\n",
            "Early stopping, best iteration is:\n",
            "[839]\ttraining's binary_logloss: 0.182055\tvalid_1's binary_logloss: 0.198392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.197935:  70%|#######   | 14/20 [00:24<00:14,  2.38s/it][I 2020-08-30 05:31:34,981] Trial 20 finished with value: 0.1983923473823983 and parameters: {'num_leaves': 3}. Best is trial 16 with value: 0.19793479158111074.\n",
            "num_leaves, val_score: 0.197935:  70%|#######   | 14/20 [00:24<00:14,  2.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.246756\tvalid_1's binary_logloss: 0.24609\n",
            "[20]\ttraining's binary_logloss: 0.237939\tvalid_1's binary_logloss: 0.237789\n",
            "[30]\ttraining's binary_logloss: 0.232906\tvalid_1's binary_logloss: 0.23284\n",
            "[40]\ttraining's binary_logloss: 0.229666\tvalid_1's binary_logloss: 0.229347\n",
            "[50]\ttraining's binary_logloss: 0.227085\tvalid_1's binary_logloss: 0.226586\n",
            "[60]\ttraining's binary_logloss: 0.225082\tvalid_1's binary_logloss: 0.224375\n",
            "[70]\ttraining's binary_logloss: 0.223405\tvalid_1's binary_logloss: 0.222642\n",
            "[80]\ttraining's binary_logloss: 0.221933\tvalid_1's binary_logloss: 0.221146\n",
            "[90]\ttraining's binary_logloss: 0.220618\tvalid_1's binary_logloss: 0.219793\n",
            "[100]\ttraining's binary_logloss: 0.219445\tvalid_1's binary_logloss: 0.218443\n",
            "[110]\ttraining's binary_logloss: 0.218408\tvalid_1's binary_logloss: 0.217326\n",
            "[120]\ttraining's binary_logloss: 0.217477\tvalid_1's binary_logloss: 0.216371\n",
            "[130]\ttraining's binary_logloss: 0.216606\tvalid_1's binary_logloss: 0.215539\n",
            "[140]\ttraining's binary_logloss: 0.215831\tvalid_1's binary_logloss: 0.214563\n",
            "[150]\ttraining's binary_logloss: 0.21511\tvalid_1's binary_logloss: 0.213858\n",
            "[160]\ttraining's binary_logloss: 0.214463\tvalid_1's binary_logloss: 0.2131\n",
            "[170]\ttraining's binary_logloss: 0.213854\tvalid_1's binary_logloss: 0.212572\n",
            "[180]\ttraining's binary_logloss: 0.213303\tvalid_1's binary_logloss: 0.211912\n",
            "[190]\ttraining's binary_logloss: 0.212796\tvalid_1's binary_logloss: 0.211422\n",
            "[200]\ttraining's binary_logloss: 0.212325\tvalid_1's binary_logloss: 0.210985\n",
            "[210]\ttraining's binary_logloss: 0.211888\tvalid_1's binary_logloss: 0.210473\n",
            "[220]\ttraining's binary_logloss: 0.211478\tvalid_1's binary_logloss: 0.210157\n",
            "[230]\ttraining's binary_logloss: 0.211099\tvalid_1's binary_logloss: 0.209814\n",
            "[240]\ttraining's binary_logloss: 0.210742\tvalid_1's binary_logloss: 0.209358\n",
            "[250]\ttraining's binary_logloss: 0.210407\tvalid_1's binary_logloss: 0.208975\n",
            "[260]\ttraining's binary_logloss: 0.210092\tvalid_1's binary_logloss: 0.208771\n",
            "[270]\ttraining's binary_logloss: 0.209796\tvalid_1's binary_logloss: 0.20852\n",
            "[280]\ttraining's binary_logloss: 0.209516\tvalid_1's binary_logloss: 0.208228\n",
            "[290]\ttraining's binary_logloss: 0.209249\tvalid_1's binary_logloss: 0.207988\n",
            "[300]\ttraining's binary_logloss: 0.209002\tvalid_1's binary_logloss: 0.207719\n",
            "[310]\ttraining's binary_logloss: 0.208758\tvalid_1's binary_logloss: 0.2075\n",
            "[320]\ttraining's binary_logloss: 0.208529\tvalid_1's binary_logloss: 0.207255\n",
            "[330]\ttraining's binary_logloss: 0.208309\tvalid_1's binary_logloss: 0.207139\n",
            "[340]\ttraining's binary_logloss: 0.208099\tvalid_1's binary_logloss: 0.20691\n",
            "[350]\ttraining's binary_logloss: 0.207897\tvalid_1's binary_logloss: 0.206703\n",
            "[360]\ttraining's binary_logloss: 0.207705\tvalid_1's binary_logloss: 0.206543\n",
            "[370]\ttraining's binary_logloss: 0.207521\tvalid_1's binary_logloss: 0.206349\n",
            "[380]\ttraining's binary_logloss: 0.207343\tvalid_1's binary_logloss: 0.206234\n",
            "[390]\ttraining's binary_logloss: 0.20717\tvalid_1's binary_logloss: 0.206085\n",
            "[400]\ttraining's binary_logloss: 0.207007\tvalid_1's binary_logloss: 0.205905\n",
            "[410]\ttraining's binary_logloss: 0.206851\tvalid_1's binary_logloss: 0.205754\n",
            "[420]\ttraining's binary_logloss: 0.2067\tvalid_1's binary_logloss: 0.205599\n",
            "[430]\ttraining's binary_logloss: 0.206553\tvalid_1's binary_logloss: 0.205521\n",
            "[440]\ttraining's binary_logloss: 0.206413\tvalid_1's binary_logloss: 0.205351\n",
            "[450]\ttraining's binary_logloss: 0.20628\tvalid_1's binary_logloss: 0.205225\n",
            "[460]\ttraining's binary_logloss: 0.206149\tvalid_1's binary_logloss: 0.205081\n",
            "[470]\ttraining's binary_logloss: 0.206024\tvalid_1's binary_logloss: 0.205008\n",
            "[480]\ttraining's binary_logloss: 0.205902\tvalid_1's binary_logloss: 0.204894\n",
            "[490]\ttraining's binary_logloss: 0.20578\tvalid_1's binary_logloss: 0.204822\n",
            "[500]\ttraining's binary_logloss: 0.205662\tvalid_1's binary_logloss: 0.204721\n",
            "[510]\ttraining's binary_logloss: 0.205548\tvalid_1's binary_logloss: 0.204647\n",
            "[520]\ttraining's binary_logloss: 0.205438\tvalid_1's binary_logloss: 0.204533\n",
            "[530]\ttraining's binary_logloss: 0.205329\tvalid_1's binary_logloss: 0.204449\n",
            "[540]\ttraining's binary_logloss: 0.205225\tvalid_1's binary_logloss: 0.204327\n",
            "[550]\ttraining's binary_logloss: 0.205121\tvalid_1's binary_logloss: 0.204196\n",
            "[560]\ttraining's binary_logloss: 0.20502\tvalid_1's binary_logloss: 0.20411\n",
            "[570]\ttraining's binary_logloss: 0.204922\tvalid_1's binary_logloss: 0.204011\n",
            "[580]\ttraining's binary_logloss: 0.204827\tvalid_1's binary_logloss: 0.203966\n",
            "[590]\ttraining's binary_logloss: 0.204735\tvalid_1's binary_logloss: 0.203936\n",
            "[600]\ttraining's binary_logloss: 0.204643\tvalid_1's binary_logloss: 0.203805\n",
            "[610]\ttraining's binary_logloss: 0.204555\tvalid_1's binary_logloss: 0.203762\n",
            "[620]\ttraining's binary_logloss: 0.204469\tvalid_1's binary_logloss: 0.20371\n",
            "[630]\ttraining's binary_logloss: 0.204383\tvalid_1's binary_logloss: 0.203608\n",
            "[640]\ttraining's binary_logloss: 0.2043\tvalid_1's binary_logloss: 0.203564\n",
            "[650]\ttraining's binary_logloss: 0.204219\tvalid_1's binary_logloss: 0.203494\n",
            "[660]\ttraining's binary_logloss: 0.20414\tvalid_1's binary_logloss: 0.203431\n",
            "[670]\ttraining's binary_logloss: 0.204064\tvalid_1's binary_logloss: 0.203324\n",
            "[680]\ttraining's binary_logloss: 0.203988\tvalid_1's binary_logloss: 0.203296\n",
            "[690]\ttraining's binary_logloss: 0.203915\tvalid_1's binary_logloss: 0.203245\n",
            "[700]\ttraining's binary_logloss: 0.203842\tvalid_1's binary_logloss: 0.20317\n",
            "[710]\ttraining's binary_logloss: 0.203771\tvalid_1's binary_logloss: 0.203108\n",
            "[720]\ttraining's binary_logloss: 0.203699\tvalid_1's binary_logloss: 0.203078\n",
            "[730]\ttraining's binary_logloss: 0.203629\tvalid_1's binary_logloss: 0.203043\n",
            "[740]\ttraining's binary_logloss: 0.20356\tvalid_1's binary_logloss: 0.202988\n",
            "[750]\ttraining's binary_logloss: 0.203492\tvalid_1's binary_logloss: 0.202918\n",
            "[760]\ttraining's binary_logloss: 0.203425\tvalid_1's binary_logloss: 0.202858\n",
            "[770]\ttraining's binary_logloss: 0.203359\tvalid_1's binary_logloss: 0.202812\n",
            "[780]\ttraining's binary_logloss: 0.203294\tvalid_1's binary_logloss: 0.202771\n",
            "[790]\ttraining's binary_logloss: 0.20323\tvalid_1's binary_logloss: 0.202778\n",
            "[800]\ttraining's binary_logloss: 0.203167\tvalid_1's binary_logloss: 0.202771\n",
            "[810]\ttraining's binary_logloss: 0.203105\tvalid_1's binary_logloss: 0.20271\n",
            "[820]\ttraining's binary_logloss: 0.203041\tvalid_1's binary_logloss: 0.202676\n",
            "[830]\ttraining's binary_logloss: 0.20298\tvalid_1's binary_logloss: 0.202604\n",
            "[840]\ttraining's binary_logloss: 0.202919\tvalid_1's binary_logloss: 0.202538\n",
            "[850]\ttraining's binary_logloss: 0.202859\tvalid_1's binary_logloss: 0.20251\n",
            "[860]\ttraining's binary_logloss: 0.2028\tvalid_1's binary_logloss: 0.202488\n",
            "[870]\ttraining's binary_logloss: 0.202741\tvalid_1's binary_logloss: 0.202454\n",
            "[880]\ttraining's binary_logloss: 0.202683\tvalid_1's binary_logloss: 0.202412\n",
            "[890]\ttraining's binary_logloss: 0.202625\tvalid_1's binary_logloss: 0.202393\n",
            "[900]\ttraining's binary_logloss: 0.202568\tvalid_1's binary_logloss: 0.202337\n",
            "[910]\ttraining's binary_logloss: 0.202513\tvalid_1's binary_logloss: 0.202308\n",
            "[920]\ttraining's binary_logloss: 0.202456\tvalid_1's binary_logloss: 0.202295\n",
            "[930]\ttraining's binary_logloss: 0.202401\tvalid_1's binary_logloss: 0.202238\n",
            "[940]\ttraining's binary_logloss: 0.202346\tvalid_1's binary_logloss: 0.202193\n",
            "[950]\ttraining's binary_logloss: 0.202293\tvalid_1's binary_logloss: 0.202195\n",
            "[960]\ttraining's binary_logloss: 0.202239\tvalid_1's binary_logloss: 0.202139\n",
            "[970]\ttraining's binary_logloss: 0.202186\tvalid_1's binary_logloss: 0.202119\n",
            "[980]\ttraining's binary_logloss: 0.202133\tvalid_1's binary_logloss: 0.202084\n",
            "[990]\ttraining's binary_logloss: 0.202082\tvalid_1's binary_logloss: 0.202079\n",
            "[1000]\ttraining's binary_logloss: 0.20203\tvalid_1's binary_logloss: 0.202058\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.20203\tvalid_1's binary_logloss: 0.202058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.197935:  75%|#######5  | 15/20 [00:27<00:13,  2.64s/it][I 2020-08-30 05:31:38,217] Trial 21 finished with value: 0.20205814268333028 and parameters: {'num_leaves': 2}. Best is trial 16 with value: 0.19793479158111074.\n",
            "num_leaves, val_score: 0.197935:  75%|#######5  | 15/20 [00:27<00:13,  2.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.208845\tvalid_1's binary_logloss: 0.218622\n",
            "[20]\ttraining's binary_logloss: 0.189335\tvalid_1's binary_logloss: 0.207164\n",
            "[30]\ttraining's binary_logloss: 0.177138\tvalid_1's binary_logloss: 0.202478\n",
            "[40]\ttraining's binary_logloss: 0.167766\tvalid_1's binary_logloss: 0.200977\n",
            "[50]\ttraining's binary_logloss: 0.159615\tvalid_1's binary_logloss: 0.199907\n",
            "[60]\ttraining's binary_logloss: 0.152531\tvalid_1's binary_logloss: 0.200122\n",
            "[70]\ttraining's binary_logloss: 0.145435\tvalid_1's binary_logloss: 0.200191\n",
            "[80]\ttraining's binary_logloss: 0.139602\tvalid_1's binary_logloss: 0.200528\n",
            "[90]\ttraining's binary_logloss: 0.133837\tvalid_1's binary_logloss: 0.201089\n",
            "[100]\ttraining's binary_logloss: 0.129547\tvalid_1's binary_logloss: 0.201644\n",
            "[110]\ttraining's binary_logloss: 0.125601\tvalid_1's binary_logloss: 0.202013\n",
            "[120]\ttraining's binary_logloss: 0.121308\tvalid_1's binary_logloss: 0.202514\n",
            "[130]\ttraining's binary_logloss: 0.117216\tvalid_1's binary_logloss: 0.203345\n",
            "[140]\ttraining's binary_logloss: 0.112911\tvalid_1's binary_logloss: 0.20411\n",
            "[150]\ttraining's binary_logloss: 0.109326\tvalid_1's binary_logloss: 0.204871\n",
            "Early stopping, best iteration is:\n",
            "[51]\ttraining's binary_logloss: 0.159052\tvalid_1's binary_logloss: 0.19964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.197935:  80%|########  | 16/20 [00:28<00:08,  2.09s/it][I 2020-08-30 05:31:39,014] Trial 22 finished with value: 0.19963955070271475 and parameters: {'num_leaves': 36}. Best is trial 16 with value: 0.19793479158111074.\n",
            "num_leaves, val_score: 0.197935:  80%|########  | 16/20 [00:28<00:08,  2.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.233823\tvalid_1's binary_logloss: 0.234045\n",
            "[20]\ttraining's binary_logloss: 0.223665\tvalid_1's binary_logloss: 0.224054\n",
            "[30]\ttraining's binary_logloss: 0.21771\tvalid_1's binary_logloss: 0.217744\n",
            "[40]\ttraining's binary_logloss: 0.213805\tvalid_1's binary_logloss: 0.213509\n",
            "[50]\ttraining's binary_logloss: 0.210621\tvalid_1's binary_logloss: 0.210636\n",
            "[60]\ttraining's binary_logloss: 0.208116\tvalid_1's binary_logloss: 0.208399\n",
            "[70]\ttraining's binary_logloss: 0.206284\tvalid_1's binary_logloss: 0.206922\n",
            "[80]\ttraining's binary_logloss: 0.204615\tvalid_1's binary_logloss: 0.205719\n",
            "[90]\ttraining's binary_logloss: 0.202909\tvalid_1's binary_logloss: 0.204623\n",
            "[100]\ttraining's binary_logloss: 0.201717\tvalid_1's binary_logloss: 0.204015\n",
            "[110]\ttraining's binary_logloss: 0.200584\tvalid_1's binary_logloss: 0.203344\n",
            "[120]\ttraining's binary_logloss: 0.199664\tvalid_1's binary_logloss: 0.203154\n",
            "[130]\ttraining's binary_logloss: 0.198693\tvalid_1's binary_logloss: 0.202881\n",
            "[140]\ttraining's binary_logloss: 0.197689\tvalid_1's binary_logloss: 0.202187\n",
            "[150]\ttraining's binary_logloss: 0.196715\tvalid_1's binary_logloss: 0.201849\n",
            "[160]\ttraining's binary_logloss: 0.195941\tvalid_1's binary_logloss: 0.201639\n",
            "[170]\ttraining's binary_logloss: 0.195022\tvalid_1's binary_logloss: 0.201277\n",
            "[180]\ttraining's binary_logloss: 0.194254\tvalid_1's binary_logloss: 0.201017\n",
            "[190]\ttraining's binary_logloss: 0.193362\tvalid_1's binary_logloss: 0.200833\n",
            "[200]\ttraining's binary_logloss: 0.192673\tvalid_1's binary_logloss: 0.200708\n",
            "[210]\ttraining's binary_logloss: 0.192023\tvalid_1's binary_logloss: 0.20043\n",
            "[220]\ttraining's binary_logloss: 0.191308\tvalid_1's binary_logloss: 0.200193\n",
            "[230]\ttraining's binary_logloss: 0.190594\tvalid_1's binary_logloss: 0.200119\n",
            "[240]\ttraining's binary_logloss: 0.189948\tvalid_1's binary_logloss: 0.199922\n",
            "[250]\ttraining's binary_logloss: 0.189396\tvalid_1's binary_logloss: 0.200022\n",
            "[260]\ttraining's binary_logloss: 0.188712\tvalid_1's binary_logloss: 0.199759\n",
            "[270]\ttraining's binary_logloss: 0.1881\tvalid_1's binary_logloss: 0.199684\n",
            "[280]\ttraining's binary_logloss: 0.187536\tvalid_1's binary_logloss: 0.19952\n",
            "[290]\ttraining's binary_logloss: 0.186994\tvalid_1's binary_logloss: 0.199406\n",
            "[300]\ttraining's binary_logloss: 0.186512\tvalid_1's binary_logloss: 0.199363\n",
            "[310]\ttraining's binary_logloss: 0.185927\tvalid_1's binary_logloss: 0.199182\n",
            "[320]\ttraining's binary_logloss: 0.185337\tvalid_1's binary_logloss: 0.199222\n",
            "[330]\ttraining's binary_logloss: 0.184771\tvalid_1's binary_logloss: 0.199141\n",
            "[340]\ttraining's binary_logloss: 0.184211\tvalid_1's binary_logloss: 0.199084\n",
            "[350]\ttraining's binary_logloss: 0.183664\tvalid_1's binary_logloss: 0.19903\n",
            "[360]\ttraining's binary_logloss: 0.183059\tvalid_1's binary_logloss: 0.198886\n",
            "[370]\ttraining's binary_logloss: 0.182575\tvalid_1's binary_logloss: 0.19871\n",
            "[380]\ttraining's binary_logloss: 0.182193\tvalid_1's binary_logloss: 0.198712\n",
            "[390]\ttraining's binary_logloss: 0.181567\tvalid_1's binary_logloss: 0.198689\n",
            "[400]\ttraining's binary_logloss: 0.18111\tvalid_1's binary_logloss: 0.198497\n",
            "[410]\ttraining's binary_logloss: 0.18064\tvalid_1's binary_logloss: 0.19847\n",
            "[420]\ttraining's binary_logloss: 0.180192\tvalid_1's binary_logloss: 0.198493\n",
            "[430]\ttraining's binary_logloss: 0.179758\tvalid_1's binary_logloss: 0.198313\n",
            "[440]\ttraining's binary_logloss: 0.179359\tvalid_1's binary_logloss: 0.198416\n",
            "[450]\ttraining's binary_logloss: 0.178994\tvalid_1's binary_logloss: 0.198488\n",
            "[460]\ttraining's binary_logloss: 0.178557\tvalid_1's binary_logloss: 0.198431\n",
            "[470]\ttraining's binary_logloss: 0.178098\tvalid_1's binary_logloss: 0.19846\n",
            "[480]\ttraining's binary_logloss: 0.177528\tvalid_1's binary_logloss: 0.198385\n",
            "[490]\ttraining's binary_logloss: 0.177092\tvalid_1's binary_logloss: 0.198254\n",
            "[500]\ttraining's binary_logloss: 0.176607\tvalid_1's binary_logloss: 0.198254\n",
            "[510]\ttraining's binary_logloss: 0.17621\tvalid_1's binary_logloss: 0.198255\n",
            "[520]\ttraining's binary_logloss: 0.175766\tvalid_1's binary_logloss: 0.198309\n",
            "[530]\ttraining's binary_logloss: 0.175387\tvalid_1's binary_logloss: 0.198358\n",
            "[540]\ttraining's binary_logloss: 0.174953\tvalid_1's binary_logloss: 0.198313\n",
            "[550]\ttraining's binary_logloss: 0.174509\tvalid_1's binary_logloss: 0.198289\n",
            "[560]\ttraining's binary_logloss: 0.174214\tvalid_1's binary_logloss: 0.198291\n",
            "[570]\ttraining's binary_logloss: 0.173904\tvalid_1's binary_logloss: 0.198281\n",
            "[580]\ttraining's binary_logloss: 0.173543\tvalid_1's binary_logloss: 0.198344\n",
            "[590]\ttraining's binary_logloss: 0.173134\tvalid_1's binary_logloss: 0.198307\n",
            "Early stopping, best iteration is:\n",
            "[493]\ttraining's binary_logloss: 0.176956\tvalid_1's binary_logloss: 0.198207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.197935:  85%|########5 | 17/20 [00:30<00:06,  2.08s/it][I 2020-08-30 05:31:41,093] Trial 23 finished with value: 0.19820694434638192 and parameters: {'num_leaves': 4}. Best is trial 16 with value: 0.19793479158111074.\n",
            "num_leaves, val_score: 0.197935:  85%|########5 | 17/20 [00:30<00:06,  2.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.208845\tvalid_1's binary_logloss: 0.218622\n",
            "[20]\ttraining's binary_logloss: 0.189335\tvalid_1's binary_logloss: 0.207164\n",
            "[30]\ttraining's binary_logloss: 0.177138\tvalid_1's binary_logloss: 0.202478\n",
            "[40]\ttraining's binary_logloss: 0.167766\tvalid_1's binary_logloss: 0.200977\n",
            "[50]\ttraining's binary_logloss: 0.159615\tvalid_1's binary_logloss: 0.199907\n",
            "[60]\ttraining's binary_logloss: 0.152531\tvalid_1's binary_logloss: 0.200122\n",
            "[70]\ttraining's binary_logloss: 0.145435\tvalid_1's binary_logloss: 0.200191\n",
            "[80]\ttraining's binary_logloss: 0.139602\tvalid_1's binary_logloss: 0.200528\n",
            "[90]\ttraining's binary_logloss: 0.133837\tvalid_1's binary_logloss: 0.201089\n",
            "[100]\ttraining's binary_logloss: 0.129547\tvalid_1's binary_logloss: 0.201644\n",
            "[110]\ttraining's binary_logloss: 0.125601\tvalid_1's binary_logloss: 0.202013\n",
            "[120]\ttraining's binary_logloss: 0.121308\tvalid_1's binary_logloss: 0.202514\n",
            "[130]\ttraining's binary_logloss: 0.117216\tvalid_1's binary_logloss: 0.203345\n",
            "[140]\ttraining's binary_logloss: 0.112911\tvalid_1's binary_logloss: 0.20411\n",
            "[150]\ttraining's binary_logloss: 0.109326\tvalid_1's binary_logloss: 0.204871\n",
            "Early stopping, best iteration is:\n",
            "[51]\ttraining's binary_logloss: 0.159052\tvalid_1's binary_logloss: 0.19964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.197935:  90%|######### | 18/20 [00:31<00:03,  1.69s/it][I 2020-08-30 05:31:41,854] Trial 24 finished with value: 0.19963955070271475 and parameters: {'num_leaves': 36}. Best is trial 16 with value: 0.19793479158111074.\n",
            "num_leaves, val_score: 0.197935:  90%|######### | 18/20 [00:31<00:03,  1.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.192808\tvalid_1's binary_logloss: 0.217356\n",
            "[20]\ttraining's binary_logloss: 0.163851\tvalid_1's binary_logloss: 0.207483\n",
            "[30]\ttraining's binary_logloss: 0.14481\tvalid_1's binary_logloss: 0.204026\n",
            "[40]\ttraining's binary_logloss: 0.128138\tvalid_1's binary_logloss: 0.203803\n",
            "[50]\ttraining's binary_logloss: 0.115782\tvalid_1's binary_logloss: 0.203218\n",
            "[60]\ttraining's binary_logloss: 0.105994\tvalid_1's binary_logloss: 0.204275\n",
            "[70]\ttraining's binary_logloss: 0.0968005\tvalid_1's binary_logloss: 0.205683\n",
            "[80]\ttraining's binary_logloss: 0.0887833\tvalid_1's binary_logloss: 0.206865\n",
            "[90]\ttraining's binary_logloss: 0.081621\tvalid_1's binary_logloss: 0.208435\n",
            "[100]\ttraining's binary_logloss: 0.0757351\tvalid_1's binary_logloss: 0.21043\n",
            "[110]\ttraining's binary_logloss: 0.0707114\tvalid_1's binary_logloss: 0.211854\n",
            "[120]\ttraining's binary_logloss: 0.0651232\tvalid_1's binary_logloss: 0.2136\n",
            "[130]\ttraining's binary_logloss: 0.0600727\tvalid_1's binary_logloss: 0.215432\n",
            "[140]\ttraining's binary_logloss: 0.0559457\tvalid_1's binary_logloss: 0.21691\n",
            "Early stopping, best iteration is:\n",
            "[46]\ttraining's binary_logloss: 0.120767\tvalid_1's binary_logloss: 0.20284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.197935:  95%|#########5| 19/20 [00:32<00:01,  1.47s/it][I 2020-08-30 05:31:42,827] Trial 25 finished with value: 0.20283978706765196 and parameters: {'num_leaves': 89}. Best is trial 16 with value: 0.19793479158111074.\n",
            "num_leaves, val_score: 0.197935:  95%|#########5| 19/20 [00:32<00:01,  1.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.200159\tvalid_1's binary_logloss: 0.217543\n",
            "[20]\ttraining's binary_logloss: 0.175718\tvalid_1's binary_logloss: 0.207043\n",
            "[30]\ttraining's binary_logloss: 0.159734\tvalid_1's binary_logloss: 0.203368\n",
            "[40]\ttraining's binary_logloss: 0.146535\tvalid_1's binary_logloss: 0.202276\n",
            "[50]\ttraining's binary_logloss: 0.136132\tvalid_1's binary_logloss: 0.201893\n",
            "[60]\ttraining's binary_logloss: 0.12728\tvalid_1's binary_logloss: 0.202748\n",
            "[70]\ttraining's binary_logloss: 0.118852\tvalid_1's binary_logloss: 0.203484\n",
            "[80]\ttraining's binary_logloss: 0.111883\tvalid_1's binary_logloss: 0.203991\n",
            "[90]\ttraining's binary_logloss: 0.106004\tvalid_1's binary_logloss: 0.205246\n",
            "[100]\ttraining's binary_logloss: 0.0999817\tvalid_1's binary_logloss: 0.20606\n",
            "[110]\ttraining's binary_logloss: 0.0952748\tvalid_1's binary_logloss: 0.207077\n",
            "[120]\ttraining's binary_logloss: 0.090301\tvalid_1's binary_logloss: 0.208044\n",
            "[130]\ttraining's binary_logloss: 0.0851453\tvalid_1's binary_logloss: 0.209321\n",
            "[140]\ttraining's binary_logloss: 0.0811957\tvalid_1's binary_logloss: 0.210427\n",
            "Early stopping, best iteration is:\n",
            "[46]\ttraining's binary_logloss: 0.140161\tvalid_1's binary_logloss: 0.201488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "num_leaves, val_score: 0.197935: 100%|##########| 20/20 [00:33<00:00,  1.30s/it][I 2020-08-30 05:31:43,733] Trial 26 finished with value: 0.20148843656983298 and parameters: {'num_leaves': 61}. Best is trial 16 with value: 0.19793479158111074.\n",
            "num_leaves, val_score: 0.197935: 100%|##########| 20/20 [00:33<00:00,  1.66s/it]\n",
            "bagging, val_score: 0.197935:   0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230515\tvalid_1's binary_logloss: 0.230372\n",
            "[20]\ttraining's binary_logloss: 0.220315\tvalid_1's binary_logloss: 0.220904\n",
            "[30]\ttraining's binary_logloss: 0.213888\tvalid_1's binary_logloss: 0.215204\n",
            "[40]\ttraining's binary_logloss: 0.20936\tvalid_1's binary_logloss: 0.211033\n",
            "[50]\ttraining's binary_logloss: 0.206197\tvalid_1's binary_logloss: 0.20817\n",
            "[60]\ttraining's binary_logloss: 0.203545\tvalid_1's binary_logloss: 0.206102\n",
            "[70]\ttraining's binary_logloss: 0.201338\tvalid_1's binary_logloss: 0.204593\n",
            "[80]\ttraining's binary_logloss: 0.199655\tvalid_1's binary_logloss: 0.203723\n",
            "[90]\ttraining's binary_logloss: 0.197982\tvalid_1's binary_logloss: 0.203261\n",
            "[100]\ttraining's binary_logloss: 0.19651\tvalid_1's binary_logloss: 0.202117\n",
            "[110]\ttraining's binary_logloss: 0.195015\tvalid_1's binary_logloss: 0.201519\n",
            "[120]\ttraining's binary_logloss: 0.193627\tvalid_1's binary_logloss: 0.201222\n",
            "[130]\ttraining's binary_logloss: 0.19231\tvalid_1's binary_logloss: 0.201283\n",
            "[140]\ttraining's binary_logloss: 0.191066\tvalid_1's binary_logloss: 0.201172\n",
            "[150]\ttraining's binary_logloss: 0.19008\tvalid_1's binary_logloss: 0.201034\n",
            "[160]\ttraining's binary_logloss: 0.189015\tvalid_1's binary_logloss: 0.200525\n",
            "[170]\ttraining's binary_logloss: 0.188061\tvalid_1's binary_logloss: 0.20046\n",
            "[180]\ttraining's binary_logloss: 0.18699\tvalid_1's binary_logloss: 0.200338\n",
            "[190]\ttraining's binary_logloss: 0.186166\tvalid_1's binary_logloss: 0.200197\n",
            "[200]\ttraining's binary_logloss: 0.185095\tvalid_1's binary_logloss: 0.1999\n",
            "[210]\ttraining's binary_logloss: 0.184095\tvalid_1's binary_logloss: 0.199358\n",
            "[220]\ttraining's binary_logloss: 0.183189\tvalid_1's binary_logloss: 0.199408\n",
            "[230]\ttraining's binary_logloss: 0.182399\tvalid_1's binary_logloss: 0.199596\n",
            "[240]\ttraining's binary_logloss: 0.181494\tvalid_1's binary_logloss: 0.199592\n",
            "[250]\ttraining's binary_logloss: 0.180749\tvalid_1's binary_logloss: 0.199824\n",
            "[260]\ttraining's binary_logloss: 0.180086\tvalid_1's binary_logloss: 0.200051\n",
            "[270]\ttraining's binary_logloss: 0.179105\tvalid_1's binary_logloss: 0.199736\n",
            "[280]\ttraining's binary_logloss: 0.178178\tvalid_1's binary_logloss: 0.199663\n",
            "[290]\ttraining's binary_logloss: 0.177236\tvalid_1's binary_logloss: 0.199478\n",
            "[300]\ttraining's binary_logloss: 0.176504\tvalid_1's binary_logloss: 0.199639\n",
            "[310]\ttraining's binary_logloss: 0.175756\tvalid_1's binary_logloss: 0.199556\n",
            "Early stopping, best iteration is:\n",
            "[211]\ttraining's binary_logloss: 0.184018\tvalid_1's binary_logloss: 0.199347\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.197935:  10%|#         | 1/10 [00:01<00:10,  1.20s/it][I 2020-08-30 05:31:44,959] Trial 27 finished with value: 0.19934723811712116 and parameters: {'bagging_fraction': 0.6017816825712704, 'bagging_freq': 1}. Best is trial 27 with value: 0.19934723811712116.\n",
            "bagging, val_score: 0.197935:  10%|#         | 1/10 [00:01<00:10,  1.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230737\tvalid_1's binary_logloss: 0.230788\n",
            "[20]\ttraining's binary_logloss: 0.220317\tvalid_1's binary_logloss: 0.220607\n",
            "[30]\ttraining's binary_logloss: 0.213872\tvalid_1's binary_logloss: 0.214189\n",
            "[40]\ttraining's binary_logloss: 0.209871\tvalid_1's binary_logloss: 0.209894\n",
            "[50]\ttraining's binary_logloss: 0.206936\tvalid_1's binary_logloss: 0.207479\n",
            "[60]\ttraining's binary_logloss: 0.204285\tvalid_1's binary_logloss: 0.205207\n",
            "[70]\ttraining's binary_logloss: 0.202275\tvalid_1's binary_logloss: 0.203893\n",
            "[80]\ttraining's binary_logloss: 0.200412\tvalid_1's binary_logloss: 0.202932\n",
            "[90]\ttraining's binary_logloss: 0.198727\tvalid_1's binary_logloss: 0.202106\n",
            "[100]\ttraining's binary_logloss: 0.197444\tvalid_1's binary_logloss: 0.201783\n",
            "[110]\ttraining's binary_logloss: 0.196024\tvalid_1's binary_logloss: 0.20108\n",
            "[120]\ttraining's binary_logloss: 0.194664\tvalid_1's binary_logloss: 0.200624\n",
            "[130]\ttraining's binary_logloss: 0.193319\tvalid_1's binary_logloss: 0.200277\n",
            "[140]\ttraining's binary_logloss: 0.192174\tvalid_1's binary_logloss: 0.200158\n",
            "[150]\ttraining's binary_logloss: 0.191085\tvalid_1's binary_logloss: 0.199838\n",
            "[160]\ttraining's binary_logloss: 0.190132\tvalid_1's binary_logloss: 0.199597\n",
            "[170]\ttraining's binary_logloss: 0.189079\tvalid_1's binary_logloss: 0.19931\n",
            "[180]\ttraining's binary_logloss: 0.188085\tvalid_1's binary_logloss: 0.199126\n",
            "[190]\ttraining's binary_logloss: 0.187116\tvalid_1's binary_logloss: 0.199054\n",
            "[200]\ttraining's binary_logloss: 0.186045\tvalid_1's binary_logloss: 0.199162\n",
            "[210]\ttraining's binary_logloss: 0.185177\tvalid_1's binary_logloss: 0.199026\n",
            "[220]\ttraining's binary_logloss: 0.184297\tvalid_1's binary_logloss: 0.19913\n",
            "[230]\ttraining's binary_logloss: 0.183459\tvalid_1's binary_logloss: 0.199127\n",
            "[240]\ttraining's binary_logloss: 0.182595\tvalid_1's binary_logloss: 0.199017\n",
            "[250]\ttraining's binary_logloss: 0.18185\tvalid_1's binary_logloss: 0.198967\n",
            "[260]\ttraining's binary_logloss: 0.180998\tvalid_1's binary_logloss: 0.19903\n",
            "[270]\ttraining's binary_logloss: 0.180232\tvalid_1's binary_logloss: 0.199082\n",
            "[280]\ttraining's binary_logloss: 0.179449\tvalid_1's binary_logloss: 0.199081\n",
            "[290]\ttraining's binary_logloss: 0.178717\tvalid_1's binary_logloss: 0.199035\n",
            "[300]\ttraining's binary_logloss: 0.178095\tvalid_1's binary_logloss: 0.198966\n",
            "[310]\ttraining's binary_logloss: 0.17728\tvalid_1's binary_logloss: 0.198863\n",
            "[320]\ttraining's binary_logloss: 0.1765\tvalid_1's binary_logloss: 0.198859\n",
            "[330]\ttraining's binary_logloss: 0.175688\tvalid_1's binary_logloss: 0.199062\n",
            "[340]\ttraining's binary_logloss: 0.175053\tvalid_1's binary_logloss: 0.199098\n",
            "[350]\ttraining's binary_logloss: 0.174274\tvalid_1's binary_logloss: 0.198993\n",
            "[360]\ttraining's binary_logloss: 0.173622\tvalid_1's binary_logloss: 0.198879\n",
            "[370]\ttraining's binary_logloss: 0.172992\tvalid_1's binary_logloss: 0.199055\n",
            "[380]\ttraining's binary_logloss: 0.172358\tvalid_1's binary_logloss: 0.19898\n",
            "[390]\ttraining's binary_logloss: 0.17169\tvalid_1's binary_logloss: 0.199058\n",
            "[400]\ttraining's binary_logloss: 0.171143\tvalid_1's binary_logloss: 0.199074\n",
            "Early stopping, best iteration is:\n",
            "[308]\ttraining's binary_logloss: 0.177395\tvalid_1's binary_logloss: 0.198821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.197935:  20%|##        | 2/10 [00:02<00:10,  1.32s/it][I 2020-08-30 05:31:46,562] Trial 28 finished with value: 0.19882138818949646 and parameters: {'bagging_fraction': 0.9898306994321054, 'bagging_freq': 7}. Best is trial 28 with value: 0.19882138818949646.\n",
            "bagging, val_score: 0.197935:  20%|##        | 2/10 [00:02<00:10,  1.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.231972\tvalid_1's binary_logloss: 0.232131\n",
            "[20]\ttraining's binary_logloss: 0.219895\tvalid_1's binary_logloss: 0.220268\n",
            "[30]\ttraining's binary_logloss: 0.213467\tvalid_1's binary_logloss: 0.213987\n",
            "[40]\ttraining's binary_logloss: 0.209663\tvalid_1's binary_logloss: 0.210848\n",
            "[50]\ttraining's binary_logloss: 0.205875\tvalid_1's binary_logloss: 0.207537\n",
            "[60]\ttraining's binary_logloss: 0.203965\tvalid_1's binary_logloss: 0.205909\n",
            "[70]\ttraining's binary_logloss: 0.202063\tvalid_1's binary_logloss: 0.204977\n",
            "[80]\ttraining's binary_logloss: 0.200417\tvalid_1's binary_logloss: 0.204193\n",
            "[90]\ttraining's binary_logloss: 0.198845\tvalid_1's binary_logloss: 0.204123\n",
            "[100]\ttraining's binary_logloss: 0.197124\tvalid_1's binary_logloss: 0.203837\n",
            "[110]\ttraining's binary_logloss: 0.195868\tvalid_1's binary_logloss: 0.203522\n",
            "[120]\ttraining's binary_logloss: 0.194571\tvalid_1's binary_logloss: 0.203248\n",
            "[130]\ttraining's binary_logloss: 0.193378\tvalid_1's binary_logloss: 0.203219\n",
            "[140]\ttraining's binary_logloss: 0.192407\tvalid_1's binary_logloss: 0.203244\n",
            "[150]\ttraining's binary_logloss: 0.191324\tvalid_1's binary_logloss: 0.203192\n",
            "[160]\ttraining's binary_logloss: 0.190233\tvalid_1's binary_logloss: 0.202536\n",
            "[170]\ttraining's binary_logloss: 0.189023\tvalid_1's binary_logloss: 0.201994\n",
            "[180]\ttraining's binary_logloss: 0.188334\tvalid_1's binary_logloss: 0.201726\n",
            "[190]\ttraining's binary_logloss: 0.186955\tvalid_1's binary_logloss: 0.200974\n",
            "[200]\ttraining's binary_logloss: 0.186148\tvalid_1's binary_logloss: 0.200976\n",
            "[210]\ttraining's binary_logloss: 0.185537\tvalid_1's binary_logloss: 0.201125\n",
            "[220]\ttraining's binary_logloss: 0.184637\tvalid_1's binary_logloss: 0.201074\n",
            "[230]\ttraining's binary_logloss: 0.183728\tvalid_1's binary_logloss: 0.200794\n",
            "[240]\ttraining's binary_logloss: 0.18289\tvalid_1's binary_logloss: 0.20087\n",
            "[250]\ttraining's binary_logloss: 0.182235\tvalid_1's binary_logloss: 0.200484\n",
            "[260]\ttraining's binary_logloss: 0.181499\tvalid_1's binary_logloss: 0.200336\n",
            "[270]\ttraining's binary_logloss: 0.180579\tvalid_1's binary_logloss: 0.200122\n",
            "[280]\ttraining's binary_logloss: 0.179762\tvalid_1's binary_logloss: 0.200487\n",
            "[290]\ttraining's binary_logloss: 0.178943\tvalid_1's binary_logloss: 0.200755\n",
            "[300]\ttraining's binary_logloss: 0.178239\tvalid_1's binary_logloss: 0.200495\n",
            "[310]\ttraining's binary_logloss: 0.177597\tvalid_1's binary_logloss: 0.200534\n",
            "[320]\ttraining's binary_logloss: 0.176815\tvalid_1's binary_logloss: 0.200488\n",
            "[330]\ttraining's binary_logloss: 0.176205\tvalid_1's binary_logloss: 0.200482\n",
            "[340]\ttraining's binary_logloss: 0.175828\tvalid_1's binary_logloss: 0.200616\n",
            "[350]\ttraining's binary_logloss: 0.175039\tvalid_1's binary_logloss: 0.200584\n",
            "[360]\ttraining's binary_logloss: 0.174215\tvalid_1's binary_logloss: 0.200506\n",
            "[370]\ttraining's binary_logloss: 0.173815\tvalid_1's binary_logloss: 0.200908\n",
            "Early stopping, best iteration is:\n",
            "[272]\ttraining's binary_logloss: 0.180412\tvalid_1's binary_logloss: 0.200001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.197935:  30%|###       | 3/10 [00:04<00:09,  1.34s/it][I 2020-08-30 05:31:47,944] Trial 29 finished with value: 0.20000113523187976 and parameters: {'bagging_fraction': 0.4068482826207024, 'bagging_freq': 4}. Best is trial 28 with value: 0.19882138818949646.\n",
            "bagging, val_score: 0.197935:  30%|###       | 3/10 [00:04<00:09,  1.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230749\tvalid_1's binary_logloss: 0.231074\n",
            "[20]\ttraining's binary_logloss: 0.219828\tvalid_1's binary_logloss: 0.220109\n",
            "[30]\ttraining's binary_logloss: 0.213851\tvalid_1's binary_logloss: 0.214087\n",
            "[40]\ttraining's binary_logloss: 0.209854\tvalid_1's binary_logloss: 0.209946\n",
            "[50]\ttraining's binary_logloss: 0.206388\tvalid_1's binary_logloss: 0.206964\n",
            "[60]\ttraining's binary_logloss: 0.203948\tvalid_1's binary_logloss: 0.204946\n",
            "[70]\ttraining's binary_logloss: 0.201735\tvalid_1's binary_logloss: 0.203666\n",
            "[80]\ttraining's binary_logloss: 0.199919\tvalid_1's binary_logloss: 0.202716\n",
            "[90]\ttraining's binary_logloss: 0.198377\tvalid_1's binary_logloss: 0.202053\n",
            "[100]\ttraining's binary_logloss: 0.197037\tvalid_1's binary_logloss: 0.201526\n",
            "[110]\ttraining's binary_logloss: 0.195682\tvalid_1's binary_logloss: 0.200899\n",
            "[120]\ttraining's binary_logloss: 0.194239\tvalid_1's binary_logloss: 0.20059\n",
            "[130]\ttraining's binary_logloss: 0.192961\tvalid_1's binary_logloss: 0.200256\n",
            "[140]\ttraining's binary_logloss: 0.191735\tvalid_1's binary_logloss: 0.20007\n",
            "[150]\ttraining's binary_logloss: 0.190562\tvalid_1's binary_logloss: 0.200004\n",
            "[160]\ttraining's binary_logloss: 0.189555\tvalid_1's binary_logloss: 0.199809\n",
            "[170]\ttraining's binary_logloss: 0.18859\tvalid_1's binary_logloss: 0.199513\n",
            "[180]\ttraining's binary_logloss: 0.187526\tvalid_1's binary_logloss: 0.199289\n",
            "[190]\ttraining's binary_logloss: 0.18663\tvalid_1's binary_logloss: 0.199177\n",
            "[200]\ttraining's binary_logloss: 0.185752\tvalid_1's binary_logloss: 0.199094\n",
            "[210]\ttraining's binary_logloss: 0.184836\tvalid_1's binary_logloss: 0.199114\n",
            "[220]\ttraining's binary_logloss: 0.183947\tvalid_1's binary_logloss: 0.199152\n",
            "[230]\ttraining's binary_logloss: 0.183154\tvalid_1's binary_logloss: 0.199204\n",
            "[240]\ttraining's binary_logloss: 0.182385\tvalid_1's binary_logloss: 0.199134\n",
            "[250]\ttraining's binary_logloss: 0.181498\tvalid_1's binary_logloss: 0.19911\n",
            "[260]\ttraining's binary_logloss: 0.180789\tvalid_1's binary_logloss: 0.199245\n",
            "[270]\ttraining's binary_logloss: 0.17994\tvalid_1's binary_logloss: 0.199236\n",
            "[280]\ttraining's binary_logloss: 0.17913\tvalid_1's binary_logloss: 0.199176\n",
            "[290]\ttraining's binary_logloss: 0.17851\tvalid_1's binary_logloss: 0.199082\n",
            "[300]\ttraining's binary_logloss: 0.177863\tvalid_1's binary_logloss: 0.198959\n",
            "[310]\ttraining's binary_logloss: 0.177268\tvalid_1's binary_logloss: 0.198901\n",
            "[320]\ttraining's binary_logloss: 0.176653\tvalid_1's binary_logloss: 0.198952\n",
            "[330]\ttraining's binary_logloss: 0.175886\tvalid_1's binary_logloss: 0.199041\n",
            "[340]\ttraining's binary_logloss: 0.175178\tvalid_1's binary_logloss: 0.198997\n",
            "[350]\ttraining's binary_logloss: 0.174477\tvalid_1's binary_logloss: 0.198985\n",
            "[360]\ttraining's binary_logloss: 0.173743\tvalid_1's binary_logloss: 0.198937\n",
            "[370]\ttraining's binary_logloss: 0.173111\tvalid_1's binary_logloss: 0.198962\n",
            "[380]\ttraining's binary_logloss: 0.172446\tvalid_1's binary_logloss: 0.199021\n",
            "[390]\ttraining's binary_logloss: 0.171747\tvalid_1's binary_logloss: 0.199069\n",
            "[400]\ttraining's binary_logloss: 0.171075\tvalid_1's binary_logloss: 0.199013\n",
            "Early stopping, best iteration is:\n",
            "[307]\ttraining's binary_logloss: 0.177428\tvalid_1's binary_logloss: 0.198868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.197935:  40%|####      | 4/10 [00:05<00:08,  1.40s/it][I 2020-08-30 05:31:49,487] Trial 30 finished with value: 0.19886818954882798 and parameters: {'bagging_fraction': 0.9822919652602079, 'bagging_freq': 1}. Best is trial 28 with value: 0.19882138818949646.\n",
            "bagging, val_score: 0.197935:  40%|####      | 4/10 [00:05<00:08,  1.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.231085\tvalid_1's binary_logloss: 0.230926\n",
            "[20]\ttraining's binary_logloss: 0.220153\tvalid_1's binary_logloss: 0.220422\n",
            "[30]\ttraining's binary_logloss: 0.214056\tvalid_1's binary_logloss: 0.21436\n",
            "[40]\ttraining's binary_logloss: 0.210008\tvalid_1's binary_logloss: 0.210055\n",
            "[50]\ttraining's binary_logloss: 0.206524\tvalid_1's binary_logloss: 0.20715\n",
            "[60]\ttraining's binary_logloss: 0.204173\tvalid_1's binary_logloss: 0.205547\n",
            "[70]\ttraining's binary_logloss: 0.202115\tvalid_1's binary_logloss: 0.204097\n",
            "[80]\ttraining's binary_logloss: 0.200388\tvalid_1's binary_logloss: 0.203144\n",
            "[90]\ttraining's binary_logloss: 0.198806\tvalid_1's binary_logloss: 0.202187\n",
            "[100]\ttraining's binary_logloss: 0.197449\tvalid_1's binary_logloss: 0.201616\n",
            "[110]\ttraining's binary_logloss: 0.195863\tvalid_1's binary_logloss: 0.201188\n",
            "[120]\ttraining's binary_logloss: 0.194524\tvalid_1's binary_logloss: 0.201251\n",
            "[130]\ttraining's binary_logloss: 0.193373\tvalid_1's binary_logloss: 0.200889\n",
            "[140]\ttraining's binary_logloss: 0.192368\tvalid_1's binary_logloss: 0.20092\n",
            "[150]\ttraining's binary_logloss: 0.191367\tvalid_1's binary_logloss: 0.200875\n",
            "[160]\ttraining's binary_logloss: 0.190199\tvalid_1's binary_logloss: 0.200099\n",
            "[170]\ttraining's binary_logloss: 0.189068\tvalid_1's binary_logloss: 0.199876\n",
            "[180]\ttraining's binary_logloss: 0.18802\tvalid_1's binary_logloss: 0.199478\n",
            "[190]\ttraining's binary_logloss: 0.187183\tvalid_1's binary_logloss: 0.199406\n",
            "[200]\ttraining's binary_logloss: 0.186203\tvalid_1's binary_logloss: 0.199292\n",
            "[210]\ttraining's binary_logloss: 0.185055\tvalid_1's binary_logloss: 0.1995\n",
            "[220]\ttraining's binary_logloss: 0.184164\tvalid_1's binary_logloss: 0.199483\n",
            "[230]\ttraining's binary_logloss: 0.183344\tvalid_1's binary_logloss: 0.199582\n",
            "[240]\ttraining's binary_logloss: 0.182563\tvalid_1's binary_logloss: 0.199472\n",
            "[250]\ttraining's binary_logloss: 0.18171\tvalid_1's binary_logloss: 0.19955\n",
            "[260]\ttraining's binary_logloss: 0.180935\tvalid_1's binary_logloss: 0.199393\n",
            "[270]\ttraining's binary_logloss: 0.180171\tvalid_1's binary_logloss: 0.199169\n",
            "[280]\ttraining's binary_logloss: 0.179461\tvalid_1's binary_logloss: 0.199182\n",
            "[290]\ttraining's binary_logloss: 0.178854\tvalid_1's binary_logloss: 0.199103\n",
            "[300]\ttraining's binary_logloss: 0.177964\tvalid_1's binary_logloss: 0.199034\n",
            "[310]\ttraining's binary_logloss: 0.177146\tvalid_1's binary_logloss: 0.199319\n",
            "[320]\ttraining's binary_logloss: 0.176581\tvalid_1's binary_logloss: 0.199539\n",
            "[330]\ttraining's binary_logloss: 0.175866\tvalid_1's binary_logloss: 0.199621\n",
            "[340]\ttraining's binary_logloss: 0.175278\tvalid_1's binary_logloss: 0.199673\n",
            "[350]\ttraining's binary_logloss: 0.174659\tvalid_1's binary_logloss: 0.199744\n",
            "[360]\ttraining's binary_logloss: 0.173978\tvalid_1's binary_logloss: 0.199962\n",
            "[370]\ttraining's binary_logloss: 0.173406\tvalid_1's binary_logloss: 0.200098\n",
            "[380]\ttraining's binary_logloss: 0.172752\tvalid_1's binary_logloss: 0.200181\n",
            "[390]\ttraining's binary_logloss: 0.172049\tvalid_1's binary_logloss: 0.200144\n",
            "Early stopping, best iteration is:\n",
            "[298]\ttraining's binary_logloss: 0.178134\tvalid_1's binary_logloss: 0.19898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.197935:  50%|#####     | 5/10 [00:07<00:07,  1.44s/it][I 2020-08-30 05:31:51,013] Trial 31 finished with value: 0.19897959955263606 and parameters: {'bagging_fraction': 0.7623315016350299, 'bagging_freq': 7}. Best is trial 28 with value: 0.19882138818949646.\n",
            "bagging, val_score: 0.197935:  50%|#####     | 5/10 [00:07<00:07,  1.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.231989\tvalid_1's binary_logloss: 0.232253\n",
            "[20]\ttraining's binary_logloss: 0.220383\tvalid_1's binary_logloss: 0.22094\n",
            "[30]\ttraining's binary_logloss: 0.213723\tvalid_1's binary_logloss: 0.21444\n",
            "[40]\ttraining's binary_logloss: 0.209639\tvalid_1's binary_logloss: 0.21125\n",
            "[50]\ttraining's binary_logloss: 0.206114\tvalid_1's binary_logloss: 0.207658\n",
            "[60]\ttraining's binary_logloss: 0.204187\tvalid_1's binary_logloss: 0.20631\n",
            "[70]\ttraining's binary_logloss: 0.202206\tvalid_1's binary_logloss: 0.205287\n",
            "[80]\ttraining's binary_logloss: 0.200353\tvalid_1's binary_logloss: 0.204108\n",
            "[90]\ttraining's binary_logloss: 0.198549\tvalid_1's binary_logloss: 0.204093\n",
            "[100]\ttraining's binary_logloss: 0.196929\tvalid_1's binary_logloss: 0.203667\n",
            "[110]\ttraining's binary_logloss: 0.195674\tvalid_1's binary_logloss: 0.203344\n",
            "[120]\ttraining's binary_logloss: 0.194752\tvalid_1's binary_logloss: 0.203094\n",
            "[130]\ttraining's binary_logloss: 0.193478\tvalid_1's binary_logloss: 0.203068\n",
            "[140]\ttraining's binary_logloss: 0.19253\tvalid_1's binary_logloss: 0.203052\n",
            "[150]\ttraining's binary_logloss: 0.191393\tvalid_1's binary_logloss: 0.202885\n",
            "[160]\ttraining's binary_logloss: 0.190247\tvalid_1's binary_logloss: 0.202113\n",
            "[170]\ttraining's binary_logloss: 0.189225\tvalid_1's binary_logloss: 0.201859\n",
            "[180]\ttraining's binary_logloss: 0.188496\tvalid_1's binary_logloss: 0.201501\n",
            "[190]\ttraining's binary_logloss: 0.18721\tvalid_1's binary_logloss: 0.200969\n",
            "[200]\ttraining's binary_logloss: 0.186286\tvalid_1's binary_logloss: 0.200737\n",
            "[210]\ttraining's binary_logloss: 0.185674\tvalid_1's binary_logloss: 0.20091\n",
            "[220]\ttraining's binary_logloss: 0.184902\tvalid_1's binary_logloss: 0.200949\n",
            "[230]\ttraining's binary_logloss: 0.184141\tvalid_1's binary_logloss: 0.200535\n",
            "[240]\ttraining's binary_logloss: 0.183358\tvalid_1's binary_logloss: 0.200419\n",
            "[250]\ttraining's binary_logloss: 0.182668\tvalid_1's binary_logloss: 0.200127\n",
            "[260]\ttraining's binary_logloss: 0.18183\tvalid_1's binary_logloss: 0.199925\n",
            "[270]\ttraining's binary_logloss: 0.180937\tvalid_1's binary_logloss: 0.199801\n",
            "[280]\ttraining's binary_logloss: 0.180036\tvalid_1's binary_logloss: 0.200093\n",
            "[290]\ttraining's binary_logloss: 0.179152\tvalid_1's binary_logloss: 0.200253\n",
            "[300]\ttraining's binary_logloss: 0.178513\tvalid_1's binary_logloss: 0.199807\n",
            "[310]\ttraining's binary_logloss: 0.177847\tvalid_1's binary_logloss: 0.199803\n",
            "[320]\ttraining's binary_logloss: 0.177127\tvalid_1's binary_logloss: 0.199506\n",
            "[330]\ttraining's binary_logloss: 0.176574\tvalid_1's binary_logloss: 0.199501\n",
            "[340]\ttraining's binary_logloss: 0.176036\tvalid_1's binary_logloss: 0.199479\n",
            "[350]\ttraining's binary_logloss: 0.175426\tvalid_1's binary_logloss: 0.199304\n",
            "[360]\ttraining's binary_logloss: 0.174675\tvalid_1's binary_logloss: 0.199615\n",
            "[370]\ttraining's binary_logloss: 0.174148\tvalid_1's binary_logloss: 0.199975\n",
            "[380]\ttraining's binary_logloss: 0.173641\tvalid_1's binary_logloss: 0.200208\n",
            "[390]\ttraining's binary_logloss: 0.173036\tvalid_1's binary_logloss: 0.200615\n",
            "[400]\ttraining's binary_logloss: 0.172233\tvalid_1's binary_logloss: 0.200623\n",
            "[410]\ttraining's binary_logloss: 0.171695\tvalid_1's binary_logloss: 0.200106\n",
            "[420]\ttraining's binary_logloss: 0.171074\tvalid_1's binary_logloss: 0.200276\n",
            "[430]\ttraining's binary_logloss: 0.170541\tvalid_1's binary_logloss: 0.200358\n",
            "[440]\ttraining's binary_logloss: 0.169769\tvalid_1's binary_logloss: 0.200653\n",
            "Early stopping, best iteration is:\n",
            "[348]\ttraining's binary_logloss: 0.17551\tvalid_1's binary_logloss: 0.19924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.197935:  60%|######    | 6/10 [00:08<00:05,  1.49s/it][I 2020-08-30 05:31:52,625] Trial 32 finished with value: 0.1992396613771242 and parameters: {'bagging_fraction': 0.4088551860167708, 'bagging_freq': 4}. Best is trial 28 with value: 0.19882138818949646.\n",
            "bagging, val_score: 0.197935:  60%|######    | 6/10 [00:08<00:05,  1.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.231116\tvalid_1's binary_logloss: 0.231379\n",
            "[20]\ttraining's binary_logloss: 0.220792\tvalid_1's binary_logloss: 0.221011\n",
            "[30]\ttraining's binary_logloss: 0.213982\tvalid_1's binary_logloss: 0.214094\n",
            "[40]\ttraining's binary_logloss: 0.209996\tvalid_1's binary_logloss: 0.210448\n",
            "[50]\ttraining's binary_logloss: 0.206697\tvalid_1's binary_logloss: 0.207633\n",
            "[60]\ttraining's binary_logloss: 0.204592\tvalid_1's binary_logloss: 0.206612\n",
            "[70]\ttraining's binary_logloss: 0.202703\tvalid_1's binary_logloss: 0.205113\n",
            "[80]\ttraining's binary_logloss: 0.200741\tvalid_1's binary_logloss: 0.204142\n",
            "[90]\ttraining's binary_logloss: 0.199101\tvalid_1's binary_logloss: 0.203495\n",
            "[100]\ttraining's binary_logloss: 0.19776\tvalid_1's binary_logloss: 0.20295\n",
            "[110]\ttraining's binary_logloss: 0.196174\tvalid_1's binary_logloss: 0.202215\n",
            "[120]\ttraining's binary_logloss: 0.19468\tvalid_1's binary_logloss: 0.201573\n",
            "[130]\ttraining's binary_logloss: 0.193508\tvalid_1's binary_logloss: 0.201383\n",
            "[140]\ttraining's binary_logloss: 0.192354\tvalid_1's binary_logloss: 0.201136\n",
            "[150]\ttraining's binary_logloss: 0.19131\tvalid_1's binary_logloss: 0.201324\n",
            "[160]\ttraining's binary_logloss: 0.190295\tvalid_1's binary_logloss: 0.201258\n",
            "[170]\ttraining's binary_logloss: 0.189059\tvalid_1's binary_logloss: 0.201172\n",
            "[180]\ttraining's binary_logloss: 0.188007\tvalid_1's binary_logloss: 0.200823\n",
            "[190]\ttraining's binary_logloss: 0.1869\tvalid_1's binary_logloss: 0.200701\n",
            "[200]\ttraining's binary_logloss: 0.18588\tvalid_1's binary_logloss: 0.200423\n",
            "[210]\ttraining's binary_logloss: 0.184798\tvalid_1's binary_logloss: 0.200425\n",
            "[220]\ttraining's binary_logloss: 0.18376\tvalid_1's binary_logloss: 0.200263\n",
            "[230]\ttraining's binary_logloss: 0.182963\tvalid_1's binary_logloss: 0.20035\n",
            "[240]\ttraining's binary_logloss: 0.182175\tvalid_1's binary_logloss: 0.200415\n",
            "[250]\ttraining's binary_logloss: 0.181394\tvalid_1's binary_logloss: 0.200736\n",
            "[260]\ttraining's binary_logloss: 0.180612\tvalid_1's binary_logloss: 0.200718\n",
            "[270]\ttraining's binary_logloss: 0.179812\tvalid_1's binary_logloss: 0.20073\n",
            "[280]\ttraining's binary_logloss: 0.178939\tvalid_1's binary_logloss: 0.200756\n",
            "[290]\ttraining's binary_logloss: 0.17805\tvalid_1's binary_logloss: 0.200739\n",
            "[300]\ttraining's binary_logloss: 0.177303\tvalid_1's binary_logloss: 0.200647\n",
            "[310]\ttraining's binary_logloss: 0.17634\tvalid_1's binary_logloss: 0.200473\n",
            "[320]\ttraining's binary_logloss: 0.175613\tvalid_1's binary_logloss: 0.200566\n",
            "Early stopping, best iteration is:\n",
            "[225]\ttraining's binary_logloss: 0.183377\tvalid_1's binary_logloss: 0.200263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.197935:  70%|#######   | 7/10 [00:10<00:04,  1.41s/it][I 2020-08-30 05:31:53,845] Trial 33 finished with value: 0.2002633841717405 and parameters: {'bagging_fraction': 0.7386784072209718, 'bagging_freq': 6}. Best is trial 28 with value: 0.19882138818949646.\n",
            "bagging, val_score: 0.197935:  70%|#######   | 7/10 [00:10<00:04,  1.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230699\tvalid_1's binary_logloss: 0.230593\n",
            "[20]\ttraining's binary_logloss: 0.219935\tvalid_1's binary_logloss: 0.219935\n",
            "[30]\ttraining's binary_logloss: 0.213257\tvalid_1's binary_logloss: 0.213788\n",
            "[40]\ttraining's binary_logloss: 0.209365\tvalid_1's binary_logloss: 0.209993\n",
            "[50]\ttraining's binary_logloss: 0.206213\tvalid_1's binary_logloss: 0.207264\n",
            "[60]\ttraining's binary_logloss: 0.203912\tvalid_1's binary_logloss: 0.205672\n",
            "[70]\ttraining's binary_logloss: 0.201798\tvalid_1's binary_logloss: 0.20448\n",
            "[80]\ttraining's binary_logloss: 0.199869\tvalid_1's binary_logloss: 0.203461\n",
            "[90]\ttraining's binary_logloss: 0.198054\tvalid_1's binary_logloss: 0.202376\n",
            "[100]\ttraining's binary_logloss: 0.196806\tvalid_1's binary_logloss: 0.20186\n",
            "[110]\ttraining's binary_logloss: 0.195613\tvalid_1's binary_logloss: 0.201608\n",
            "[120]\ttraining's binary_logloss: 0.194464\tvalid_1's binary_logloss: 0.201467\n",
            "[130]\ttraining's binary_logloss: 0.193132\tvalid_1's binary_logloss: 0.201729\n",
            "[140]\ttraining's binary_logloss: 0.19182\tvalid_1's binary_logloss: 0.20157\n",
            "[150]\ttraining's binary_logloss: 0.190801\tvalid_1's binary_logloss: 0.201354\n",
            "[160]\ttraining's binary_logloss: 0.189621\tvalid_1's binary_logloss: 0.200919\n",
            "[170]\ttraining's binary_logloss: 0.188568\tvalid_1's binary_logloss: 0.20083\n",
            "[180]\ttraining's binary_logloss: 0.187426\tvalid_1's binary_logloss: 0.200883\n",
            "[190]\ttraining's binary_logloss: 0.186332\tvalid_1's binary_logloss: 0.200851\n",
            "[200]\ttraining's binary_logloss: 0.185091\tvalid_1's binary_logloss: 0.200511\n",
            "[210]\ttraining's binary_logloss: 0.18414\tvalid_1's binary_logloss: 0.200405\n",
            "[220]\ttraining's binary_logloss: 0.183159\tvalid_1's binary_logloss: 0.199873\n",
            "[230]\ttraining's binary_logloss: 0.182435\tvalid_1's binary_logloss: 0.199801\n",
            "[240]\ttraining's binary_logloss: 0.181563\tvalid_1's binary_logloss: 0.199703\n",
            "[250]\ttraining's binary_logloss: 0.180682\tvalid_1's binary_logloss: 0.199711\n",
            "[260]\ttraining's binary_logloss: 0.179748\tvalid_1's binary_logloss: 0.199445\n",
            "[270]\ttraining's binary_logloss: 0.17895\tvalid_1's binary_logloss: 0.199462\n",
            "[280]\ttraining's binary_logloss: 0.177978\tvalid_1's binary_logloss: 0.199801\n",
            "[290]\ttraining's binary_logloss: 0.176945\tvalid_1's binary_logloss: 0.199799\n",
            "[300]\ttraining's binary_logloss: 0.176316\tvalid_1's binary_logloss: 0.200081\n",
            "[310]\ttraining's binary_logloss: 0.175674\tvalid_1's binary_logloss: 0.200325\n",
            "[320]\ttraining's binary_logloss: 0.174914\tvalid_1's binary_logloss: 0.200363\n",
            "[330]\ttraining's binary_logloss: 0.174402\tvalid_1's binary_logloss: 0.200466\n",
            "[340]\ttraining's binary_logloss: 0.173816\tvalid_1's binary_logloss: 0.200351\n",
            "[350]\ttraining's binary_logloss: 0.173135\tvalid_1's binary_logloss: 0.200121\n",
            "[360]\ttraining's binary_logloss: 0.172482\tvalid_1's binary_logloss: 0.200307\n",
            "Early stopping, best iteration is:\n",
            "[263]\ttraining's binary_logloss: 0.179515\tvalid_1's binary_logloss: 0.199427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.197935:  80%|########  | 8/10 [00:11<00:02,  1.41s/it][I 2020-08-30 05:31:55,239] Trial 34 finished with value: 0.1994270985811866 and parameters: {'bagging_fraction': 0.5473884609530562, 'bagging_freq': 2}. Best is trial 28 with value: 0.19882138818949646.\n",
            "bagging, val_score: 0.197935:  80%|########  | 8/10 [00:11<00:02,  1.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230852\tvalid_1's binary_logloss: 0.231163\n",
            "[20]\ttraining's binary_logloss: 0.22044\tvalid_1's binary_logloss: 0.220841\n",
            "[30]\ttraining's binary_logloss: 0.214189\tvalid_1's binary_logloss: 0.214511\n",
            "[40]\ttraining's binary_logloss: 0.210006\tvalid_1's binary_logloss: 0.210683\n",
            "[50]\ttraining's binary_logloss: 0.20686\tvalid_1's binary_logloss: 0.208045\n",
            "[60]\ttraining's binary_logloss: 0.204571\tvalid_1's binary_logloss: 0.206477\n",
            "[70]\ttraining's binary_logloss: 0.202345\tvalid_1's binary_logloss: 0.205129\n",
            "[80]\ttraining's binary_logloss: 0.200346\tvalid_1's binary_logloss: 0.204072\n",
            "[90]\ttraining's binary_logloss: 0.198625\tvalid_1's binary_logloss: 0.203172\n",
            "[100]\ttraining's binary_logloss: 0.197104\tvalid_1's binary_logloss: 0.202503\n",
            "[110]\ttraining's binary_logloss: 0.195532\tvalid_1's binary_logloss: 0.201664\n",
            "[120]\ttraining's binary_logloss: 0.194353\tvalid_1's binary_logloss: 0.201317\n",
            "[130]\ttraining's binary_logloss: 0.193279\tvalid_1's binary_logloss: 0.201052\n",
            "[140]\ttraining's binary_logloss: 0.192144\tvalid_1's binary_logloss: 0.200701\n",
            "[150]\ttraining's binary_logloss: 0.190978\tvalid_1's binary_logloss: 0.200356\n",
            "[160]\ttraining's binary_logloss: 0.189922\tvalid_1's binary_logloss: 0.199802\n",
            "[170]\ttraining's binary_logloss: 0.188641\tvalid_1's binary_logloss: 0.199715\n",
            "[180]\ttraining's binary_logloss: 0.1876\tvalid_1's binary_logloss: 0.199568\n",
            "[190]\ttraining's binary_logloss: 0.186663\tvalid_1's binary_logloss: 0.199302\n",
            "[200]\ttraining's binary_logloss: 0.185733\tvalid_1's binary_logloss: 0.199295\n",
            "[210]\ttraining's binary_logloss: 0.184876\tvalid_1's binary_logloss: 0.19933\n",
            "[220]\ttraining's binary_logloss: 0.18389\tvalid_1's binary_logloss: 0.199265\n",
            "[230]\ttraining's binary_logloss: 0.182928\tvalid_1's binary_logloss: 0.199159\n",
            "[240]\ttraining's binary_logloss: 0.182194\tvalid_1's binary_logloss: 0.198884\n",
            "[250]\ttraining's binary_logloss: 0.181411\tvalid_1's binary_logloss: 0.199069\n",
            "[260]\ttraining's binary_logloss: 0.18057\tvalid_1's binary_logloss: 0.199062\n",
            "[270]\ttraining's binary_logloss: 0.179875\tvalid_1's binary_logloss: 0.199033\n",
            "[280]\ttraining's binary_logloss: 0.179146\tvalid_1's binary_logloss: 0.199048\n",
            "[290]\ttraining's binary_logloss: 0.178556\tvalid_1's binary_logloss: 0.199087\n",
            "[300]\ttraining's binary_logloss: 0.177752\tvalid_1's binary_logloss: 0.199205\n",
            "[310]\ttraining's binary_logloss: 0.176965\tvalid_1's binary_logloss: 0.199068\n",
            "[320]\ttraining's binary_logloss: 0.176239\tvalid_1's binary_logloss: 0.199012\n",
            "[330]\ttraining's binary_logloss: 0.175367\tvalid_1's binary_logloss: 0.198953\n",
            "[340]\ttraining's binary_logloss: 0.174577\tvalid_1's binary_logloss: 0.198839\n",
            "[350]\ttraining's binary_logloss: 0.173893\tvalid_1's binary_logloss: 0.198687\n",
            "[360]\ttraining's binary_logloss: 0.173253\tvalid_1's binary_logloss: 0.198845\n",
            "[370]\ttraining's binary_logloss: 0.172485\tvalid_1's binary_logloss: 0.198993\n",
            "[380]\ttraining's binary_logloss: 0.171831\tvalid_1's binary_logloss: 0.199026\n",
            "[390]\ttraining's binary_logloss: 0.171141\tvalid_1's binary_logloss: 0.19911\n",
            "[400]\ttraining's binary_logloss: 0.170538\tvalid_1's binary_logloss: 0.198993\n",
            "[410]\ttraining's binary_logloss: 0.169859\tvalid_1's binary_logloss: 0.19906\n",
            "[420]\ttraining's binary_logloss: 0.169227\tvalid_1's binary_logloss: 0.198925\n",
            "[430]\ttraining's binary_logloss: 0.168612\tvalid_1's binary_logloss: 0.198977\n",
            "[440]\ttraining's binary_logloss: 0.167997\tvalid_1's binary_logloss: 0.199039\n",
            "[450]\ttraining's binary_logloss: 0.167362\tvalid_1's binary_logloss: 0.198836\n",
            "Early stopping, best iteration is:\n",
            "[356]\ttraining's binary_logloss: 0.173556\tvalid_1's binary_logloss: 0.198669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.197935:  90%|######### | 9/10 [00:13<00:01,  1.52s/it][I 2020-08-30 05:31:57,042] Trial 35 finished with value: 0.1986689411683962 and parameters: {'bagging_fraction': 0.8789170489397242, 'bagging_freq': 3}. Best is trial 35 with value: 0.1986689411683962.\n",
            "bagging, val_score: 0.197935:  90%|######### | 9/10 [00:13<00:01,  1.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.231364\tvalid_1's binary_logloss: 0.231394\n",
            "[20]\ttraining's binary_logloss: 0.220355\tvalid_1's binary_logloss: 0.220295\n",
            "[30]\ttraining's binary_logloss: 0.214078\tvalid_1's binary_logloss: 0.214703\n",
            "[40]\ttraining's binary_logloss: 0.209879\tvalid_1's binary_logloss: 0.210342\n",
            "[50]\ttraining's binary_logloss: 0.20656\tvalid_1's binary_logloss: 0.208156\n",
            "[60]\ttraining's binary_logloss: 0.204076\tvalid_1's binary_logloss: 0.206419\n",
            "[70]\ttraining's binary_logloss: 0.202175\tvalid_1's binary_logloss: 0.204759\n",
            "[80]\ttraining's binary_logloss: 0.199867\tvalid_1's binary_logloss: 0.203342\n",
            "[90]\ttraining's binary_logloss: 0.198703\tvalid_1's binary_logloss: 0.202858\n",
            "[100]\ttraining's binary_logloss: 0.19715\tvalid_1's binary_logloss: 0.202072\n",
            "[110]\ttraining's binary_logloss: 0.195783\tvalid_1's binary_logloss: 0.201701\n",
            "[120]\ttraining's binary_logloss: 0.194434\tvalid_1's binary_logloss: 0.201289\n",
            "[130]\ttraining's binary_logloss: 0.193419\tvalid_1's binary_logloss: 0.20138\n",
            "[140]\ttraining's binary_logloss: 0.192065\tvalid_1's binary_logloss: 0.200993\n",
            "[150]\ttraining's binary_logloss: 0.191036\tvalid_1's binary_logloss: 0.200873\n",
            "[160]\ttraining's binary_logloss: 0.18987\tvalid_1's binary_logloss: 0.200726\n",
            "[170]\ttraining's binary_logloss: 0.188868\tvalid_1's binary_logloss: 0.200112\n",
            "[180]\ttraining's binary_logloss: 0.187967\tvalid_1's binary_logloss: 0.199912\n",
            "[190]\ttraining's binary_logloss: 0.187079\tvalid_1's binary_logloss: 0.199702\n",
            "[200]\ttraining's binary_logloss: 0.186263\tvalid_1's binary_logloss: 0.199661\n",
            "[210]\ttraining's binary_logloss: 0.185183\tvalid_1's binary_logloss: 0.199906\n",
            "[220]\ttraining's binary_logloss: 0.184288\tvalid_1's binary_logloss: 0.200008\n",
            "[230]\ttraining's binary_logloss: 0.183267\tvalid_1's binary_logloss: 0.199689\n",
            "[240]\ttraining's binary_logloss: 0.182283\tvalid_1's binary_logloss: 0.199615\n",
            "[250]\ttraining's binary_logloss: 0.181519\tvalid_1's binary_logloss: 0.19949\n",
            "[260]\ttraining's binary_logloss: 0.180776\tvalid_1's binary_logloss: 0.199784\n",
            "[270]\ttraining's binary_logloss: 0.180004\tvalid_1's binary_logloss: 0.199951\n",
            "[280]\ttraining's binary_logloss: 0.17935\tvalid_1's binary_logloss: 0.200082\n",
            "[290]\ttraining's binary_logloss: 0.17846\tvalid_1's binary_logloss: 0.200118\n",
            "[300]\ttraining's binary_logloss: 0.177861\tvalid_1's binary_logloss: 0.200085\n",
            "[310]\ttraining's binary_logloss: 0.177002\tvalid_1's binary_logloss: 0.200139\n",
            "[320]\ttraining's binary_logloss: 0.176135\tvalid_1's binary_logloss: 0.200366\n",
            "[330]\ttraining's binary_logloss: 0.175464\tvalid_1's binary_logloss: 0.200501\n",
            "Early stopping, best iteration is:\n",
            "[233]\ttraining's binary_logloss: 0.182877\tvalid_1's binary_logloss: 0.199471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "bagging, val_score: 0.197935: 100%|##########| 10/10 [00:14<00:00,  1.45s/it][I 2020-08-30 05:31:58,326] Trial 36 finished with value: 0.19947082418179846 and parameters: {'bagging_fraction': 0.5432632506323252, 'bagging_freq': 5}. Best is trial 35 with value: 0.1986689411683962.\n",
            "bagging, val_score: 0.197935: 100%|##########| 10/10 [00:14<00:00,  1.46s/it]\n",
            "feature_fraction_stage2, val_score: 0.197935:   0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230862\tvalid_1's binary_logloss: 0.231131\n",
            "[20]\ttraining's binary_logloss: 0.220396\tvalid_1's binary_logloss: 0.221132\n",
            "[30]\ttraining's binary_logloss: 0.213858\tvalid_1's binary_logloss: 0.214583\n",
            "[40]\ttraining's binary_logloss: 0.209745\tvalid_1's binary_logloss: 0.210472\n",
            "[50]\ttraining's binary_logloss: 0.206458\tvalid_1's binary_logloss: 0.207706\n",
            "[60]\ttraining's binary_logloss: 0.204093\tvalid_1's binary_logloss: 0.205749\n",
            "[70]\ttraining's binary_logloss: 0.20202\tvalid_1's binary_logloss: 0.204571\n",
            "[80]\ttraining's binary_logloss: 0.200243\tvalid_1's binary_logloss: 0.203297\n",
            "[90]\ttraining's binary_logloss: 0.19894\tvalid_1's binary_logloss: 0.202676\n",
            "[100]\ttraining's binary_logloss: 0.19761\tvalid_1's binary_logloss: 0.201912\n",
            "[110]\ttraining's binary_logloss: 0.196063\tvalid_1's binary_logloss: 0.201581\n",
            "[120]\ttraining's binary_logloss: 0.194862\tvalid_1's binary_logloss: 0.201388\n",
            "[130]\ttraining's binary_logloss: 0.193682\tvalid_1's binary_logloss: 0.200824\n",
            "[140]\ttraining's binary_logloss: 0.192465\tvalid_1's binary_logloss: 0.200484\n",
            "[150]\ttraining's binary_logloss: 0.191359\tvalid_1's binary_logloss: 0.200478\n",
            "[160]\ttraining's binary_logloss: 0.190408\tvalid_1's binary_logloss: 0.200329\n",
            "[170]\ttraining's binary_logloss: 0.189507\tvalid_1's binary_logloss: 0.20006\n",
            "[180]\ttraining's binary_logloss: 0.188519\tvalid_1's binary_logloss: 0.199874\n",
            "[190]\ttraining's binary_logloss: 0.187705\tvalid_1's binary_logloss: 0.199919\n",
            "[200]\ttraining's binary_logloss: 0.186915\tvalid_1's binary_logloss: 0.199828\n",
            "[210]\ttraining's binary_logloss: 0.186096\tvalid_1's binary_logloss: 0.199742\n",
            "[220]\ttraining's binary_logloss: 0.185215\tvalid_1's binary_logloss: 0.199758\n",
            "[230]\ttraining's binary_logloss: 0.184422\tvalid_1's binary_logloss: 0.199818\n",
            "[240]\ttraining's binary_logloss: 0.183581\tvalid_1's binary_logloss: 0.199744\n",
            "[250]\ttraining's binary_logloss: 0.18255\tvalid_1's binary_logloss: 0.199739\n",
            "[260]\ttraining's binary_logloss: 0.181725\tvalid_1's binary_logloss: 0.199626\n",
            "[270]\ttraining's binary_logloss: 0.181001\tvalid_1's binary_logloss: 0.199548\n",
            "[280]\ttraining's binary_logloss: 0.180204\tvalid_1's binary_logloss: 0.199653\n",
            "[290]\ttraining's binary_logloss: 0.179456\tvalid_1's binary_logloss: 0.199634\n",
            "[300]\ttraining's binary_logloss: 0.178707\tvalid_1's binary_logloss: 0.199687\n",
            "[310]\ttraining's binary_logloss: 0.17802\tvalid_1's binary_logloss: 0.19954\n",
            "[320]\ttraining's binary_logloss: 0.177286\tvalid_1's binary_logloss: 0.199385\n",
            "[330]\ttraining's binary_logloss: 0.176575\tvalid_1's binary_logloss: 0.199351\n",
            "[340]\ttraining's binary_logloss: 0.175806\tvalid_1's binary_logloss: 0.199351\n",
            "[350]\ttraining's binary_logloss: 0.175014\tvalid_1's binary_logloss: 0.199374\n",
            "[360]\ttraining's binary_logloss: 0.174412\tvalid_1's binary_logloss: 0.199336\n",
            "[370]\ttraining's binary_logloss: 0.173878\tvalid_1's binary_logloss: 0.199291\n",
            "[380]\ttraining's binary_logloss: 0.173405\tvalid_1's binary_logloss: 0.199278\n",
            "[390]\ttraining's binary_logloss: 0.172877\tvalid_1's binary_logloss: 0.199265\n",
            "[400]\ttraining's binary_logloss: 0.172263\tvalid_1's binary_logloss: 0.199361\n",
            "[410]\ttraining's binary_logloss: 0.171574\tvalid_1's binary_logloss: 0.199326\n",
            "[420]\ttraining's binary_logloss: 0.170917\tvalid_1's binary_logloss: 0.199324\n",
            "[430]\ttraining's binary_logloss: 0.170332\tvalid_1's binary_logloss: 0.19923\n",
            "[440]\ttraining's binary_logloss: 0.169755\tvalid_1's binary_logloss: 0.199379\n",
            "[450]\ttraining's binary_logloss: 0.16901\tvalid_1's binary_logloss: 0.199301\n",
            "Early stopping, best iteration is:\n",
            "[356]\ttraining's binary_logloss: 0.174614\tvalid_1's binary_logloss: 0.199201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction_stage2, val_score: 0.197935:  17%|#6        | 1/6 [00:01<00:08,  1.62s/it][I 2020-08-30 05:31:59,971] Trial 37 finished with value: 0.19920112287811528 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 37 with value: 0.19920112287811528.\n",
            "feature_fraction_stage2, val_score: 0.197935:  17%|#6        | 1/6 [00:01<00:08,  1.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230976\tvalid_1's binary_logloss: 0.23082\n",
            "[20]\ttraining's binary_logloss: 0.220046\tvalid_1's binary_logloss: 0.22008\n",
            "[30]\ttraining's binary_logloss: 0.213921\tvalid_1's binary_logloss: 0.21373\n",
            "[40]\ttraining's binary_logloss: 0.209435\tvalid_1's binary_logloss: 0.209334\n",
            "[50]\ttraining's binary_logloss: 0.206302\tvalid_1's binary_logloss: 0.206809\n",
            "[60]\ttraining's binary_logloss: 0.203853\tvalid_1's binary_logloss: 0.204967\n",
            "[70]\ttraining's binary_logloss: 0.201857\tvalid_1's binary_logloss: 0.203893\n",
            "[80]\ttraining's binary_logloss: 0.200126\tvalid_1's binary_logloss: 0.202934\n",
            "[90]\ttraining's binary_logloss: 0.198456\tvalid_1's binary_logloss: 0.202341\n",
            "[100]\ttraining's binary_logloss: 0.197026\tvalid_1's binary_logloss: 0.202027\n",
            "[110]\ttraining's binary_logloss: 0.195785\tvalid_1's binary_logloss: 0.201353\n",
            "[120]\ttraining's binary_logloss: 0.194537\tvalid_1's binary_logloss: 0.200976\n",
            "[130]\ttraining's binary_logloss: 0.193261\tvalid_1's binary_logloss: 0.201012\n",
            "[140]\ttraining's binary_logloss: 0.192175\tvalid_1's binary_logloss: 0.200647\n",
            "[150]\ttraining's binary_logloss: 0.191036\tvalid_1's binary_logloss: 0.200296\n",
            "[160]\ttraining's binary_logloss: 0.190081\tvalid_1's binary_logloss: 0.200072\n",
            "[170]\ttraining's binary_logloss: 0.188977\tvalid_1's binary_logloss: 0.199849\n",
            "[180]\ttraining's binary_logloss: 0.187911\tvalid_1's binary_logloss: 0.199604\n",
            "[190]\ttraining's binary_logloss: 0.186967\tvalid_1's binary_logloss: 0.199427\n",
            "[200]\ttraining's binary_logloss: 0.185997\tvalid_1's binary_logloss: 0.199257\n",
            "[210]\ttraining's binary_logloss: 0.185035\tvalid_1's binary_logloss: 0.199215\n",
            "[220]\ttraining's binary_logloss: 0.184091\tvalid_1's binary_logloss: 0.199127\n",
            "[230]\ttraining's binary_logloss: 0.183215\tvalid_1's binary_logloss: 0.199191\n",
            "[240]\ttraining's binary_logloss: 0.18238\tvalid_1's binary_logloss: 0.199158\n",
            "[250]\ttraining's binary_logloss: 0.181534\tvalid_1's binary_logloss: 0.199286\n",
            "[260]\ttraining's binary_logloss: 0.180656\tvalid_1's binary_logloss: 0.199053\n",
            "[270]\ttraining's binary_logloss: 0.179904\tvalid_1's binary_logloss: 0.198993\n",
            "[280]\ttraining's binary_logloss: 0.179082\tvalid_1's binary_logloss: 0.199177\n",
            "[290]\ttraining's binary_logloss: 0.178283\tvalid_1's binary_logloss: 0.199003\n",
            "[300]\ttraining's binary_logloss: 0.177506\tvalid_1's binary_logloss: 0.199011\n",
            "[310]\ttraining's binary_logloss: 0.176781\tvalid_1's binary_logloss: 0.198924\n",
            "[320]\ttraining's binary_logloss: 0.176029\tvalid_1's binary_logloss: 0.199032\n",
            "[330]\ttraining's binary_logloss: 0.175302\tvalid_1's binary_logloss: 0.199016\n",
            "[340]\ttraining's binary_logloss: 0.174452\tvalid_1's binary_logloss: 0.19894\n",
            "[350]\ttraining's binary_logloss: 0.173869\tvalid_1's binary_logloss: 0.19885\n",
            "[360]\ttraining's binary_logloss: 0.17316\tvalid_1's binary_logloss: 0.198817\n",
            "[370]\ttraining's binary_logloss: 0.172647\tvalid_1's binary_logloss: 0.198847\n",
            "[380]\ttraining's binary_logloss: 0.172074\tvalid_1's binary_logloss: 0.198719\n",
            "[390]\ttraining's binary_logloss: 0.171423\tvalid_1's binary_logloss: 0.198924\n",
            "[400]\ttraining's binary_logloss: 0.17066\tvalid_1's binary_logloss: 0.198932\n",
            "[410]\ttraining's binary_logloss: 0.169999\tvalid_1's binary_logloss: 0.199081\n",
            "[420]\ttraining's binary_logloss: 0.169374\tvalid_1's binary_logloss: 0.199218\n",
            "[430]\ttraining's binary_logloss: 0.168751\tvalid_1's binary_logloss: 0.199303\n",
            "[440]\ttraining's binary_logloss: 0.168162\tvalid_1's binary_logloss: 0.199347\n",
            "[450]\ttraining's binary_logloss: 0.167605\tvalid_1's binary_logloss: 0.199388\n",
            "[460]\ttraining's binary_logloss: 0.167105\tvalid_1's binary_logloss: 0.199475\n",
            "[470]\ttraining's binary_logloss: 0.166551\tvalid_1's binary_logloss: 0.199407\n",
            "Early stopping, best iteration is:\n",
            "[378]\ttraining's binary_logloss: 0.172251\tvalid_1's binary_logloss: 0.198691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction_stage2, val_score: 0.197935:  33%|###3      | 2/6 [00:03<00:06,  1.66s/it][I 2020-08-30 05:32:01,720] Trial 38 finished with value: 0.1986906182159047 and parameters: {'feature_fraction': 0.58}. Best is trial 38 with value: 0.1986906182159047.\n",
            "feature_fraction_stage2, val_score: 0.197935:  33%|###3      | 2/6 [00:03<00:06,  1.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169136\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction_stage2, val_score: 0.197935:  50%|#####     | 3/6 [00:05<00:05,  1.67s/it][I 2020-08-30 05:32:03,423] Trial 39 finished with value: 0.19793479158111074 and parameters: {'feature_fraction': 0.516}. Best is trial 39 with value: 0.19793479158111074.\n",
            "feature_fraction_stage2, val_score: 0.197935:  50%|#####     | 3/6 [00:05<00:05,  1.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230599\tvalid_1's binary_logloss: 0.230916\n",
            "[20]\ttraining's binary_logloss: 0.219996\tvalid_1's binary_logloss: 0.220463\n",
            "[30]\ttraining's binary_logloss: 0.214003\tvalid_1's binary_logloss: 0.214087\n",
            "[40]\ttraining's binary_logloss: 0.209709\tvalid_1's binary_logloss: 0.20989\n",
            "[50]\ttraining's binary_logloss: 0.206234\tvalid_1's binary_logloss: 0.207055\n",
            "[60]\ttraining's binary_logloss: 0.203986\tvalid_1's binary_logloss: 0.205369\n",
            "[70]\ttraining's binary_logloss: 0.201926\tvalid_1's binary_logloss: 0.204353\n",
            "[80]\ttraining's binary_logloss: 0.200038\tvalid_1's binary_logloss: 0.20297\n",
            "[90]\ttraining's binary_logloss: 0.198463\tvalid_1's binary_logloss: 0.202603\n",
            "[100]\ttraining's binary_logloss: 0.197177\tvalid_1's binary_logloss: 0.202034\n",
            "[110]\ttraining's binary_logloss: 0.195887\tvalid_1's binary_logloss: 0.201457\n",
            "[120]\ttraining's binary_logloss: 0.194675\tvalid_1's binary_logloss: 0.201213\n",
            "[130]\ttraining's binary_logloss: 0.193478\tvalid_1's binary_logloss: 0.200834\n",
            "[140]\ttraining's binary_logloss: 0.192446\tvalid_1's binary_logloss: 0.200615\n",
            "[150]\ttraining's binary_logloss: 0.191223\tvalid_1's binary_logloss: 0.200389\n",
            "[160]\ttraining's binary_logloss: 0.190261\tvalid_1's binary_logloss: 0.200173\n",
            "[170]\ttraining's binary_logloss: 0.189287\tvalid_1's binary_logloss: 0.199964\n",
            "[180]\ttraining's binary_logloss: 0.188373\tvalid_1's binary_logloss: 0.199778\n",
            "[190]\ttraining's binary_logloss: 0.187501\tvalid_1's binary_logloss: 0.199891\n",
            "[200]\ttraining's binary_logloss: 0.186628\tvalid_1's binary_logloss: 0.199925\n",
            "[210]\ttraining's binary_logloss: 0.185716\tvalid_1's binary_logloss: 0.199948\n",
            "[220]\ttraining's binary_logloss: 0.184695\tvalid_1's binary_logloss: 0.199822\n",
            "[230]\ttraining's binary_logloss: 0.183849\tvalid_1's binary_logloss: 0.19973\n",
            "[240]\ttraining's binary_logloss: 0.183018\tvalid_1's binary_logloss: 0.19963\n",
            "[250]\ttraining's binary_logloss: 0.182296\tvalid_1's binary_logloss: 0.19971\n",
            "[260]\ttraining's binary_logloss: 0.1815\tvalid_1's binary_logloss: 0.199553\n",
            "[270]\ttraining's binary_logloss: 0.180711\tvalid_1's binary_logloss: 0.199615\n",
            "[280]\ttraining's binary_logloss: 0.179973\tvalid_1's binary_logloss: 0.199514\n",
            "[290]\ttraining's binary_logloss: 0.179155\tvalid_1's binary_logloss: 0.199478\n",
            "[300]\ttraining's binary_logloss: 0.178407\tvalid_1's binary_logloss: 0.199485\n",
            "[310]\ttraining's binary_logloss: 0.177592\tvalid_1's binary_logloss: 0.199488\n",
            "[320]\ttraining's binary_logloss: 0.176868\tvalid_1's binary_logloss: 0.199317\n",
            "[330]\ttraining's binary_logloss: 0.176074\tvalid_1's binary_logloss: 0.199379\n",
            "[340]\ttraining's binary_logloss: 0.175468\tvalid_1's binary_logloss: 0.199291\n",
            "[350]\ttraining's binary_logloss: 0.174865\tvalid_1's binary_logloss: 0.199293\n",
            "[360]\ttraining's binary_logloss: 0.174194\tvalid_1's binary_logloss: 0.199322\n",
            "[370]\ttraining's binary_logloss: 0.173448\tvalid_1's binary_logloss: 0.199295\n",
            "[380]\ttraining's binary_logloss: 0.172782\tvalid_1's binary_logloss: 0.19922\n",
            "[390]\ttraining's binary_logloss: 0.172176\tvalid_1's binary_logloss: 0.199268\n",
            "[400]\ttraining's binary_logloss: 0.171585\tvalid_1's binary_logloss: 0.199369\n",
            "[410]\ttraining's binary_logloss: 0.170967\tvalid_1's binary_logloss: 0.199416\n",
            "[420]\ttraining's binary_logloss: 0.170386\tvalid_1's binary_logloss: 0.199467\n",
            "[430]\ttraining's binary_logloss: 0.169805\tvalid_1's binary_logloss: 0.199371\n",
            "[440]\ttraining's binary_logloss: 0.169196\tvalid_1's binary_logloss: 0.199372\n",
            "[450]\ttraining's binary_logloss: 0.168593\tvalid_1's binary_logloss: 0.199314\n",
            "[460]\ttraining's binary_logloss: 0.168013\tvalid_1's binary_logloss: 0.199266\n",
            "[470]\ttraining's binary_logloss: 0.167437\tvalid_1's binary_logloss: 0.199332\n",
            "[480]\ttraining's binary_logloss: 0.166661\tvalid_1's binary_logloss: 0.199478\n",
            "Early stopping, best iteration is:\n",
            "[385]\ttraining's binary_logloss: 0.172487\tvalid_1's binary_logloss: 0.199207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction_stage2, val_score: 0.197935:  67%|######6   | 4/6 [00:06<00:03,  1.68s/it][I 2020-08-30 05:32:05,114] Trial 40 finished with value: 0.1992065911771295 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 39 with value: 0.19793479158111074.\n",
            "feature_fraction_stage2, val_score: 0.197935:  67%|######6   | 4/6 [00:06<00:03,  1.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169136\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction_stage2, val_score: 0.197935:  83%|########3 | 5/6 [00:08<00:01,  1.68s/it][I 2020-08-30 05:32:06,816] Trial 41 finished with value: 0.19793479158111074 and parameters: {'feature_fraction': 0.484}. Best is trial 39 with value: 0.19793479158111074.\n",
            "feature_fraction_stage2, val_score: 0.197935:  83%|########3 | 5/6 [00:08<00:01,  1.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.232402\tvalid_1's binary_logloss: 0.232195\n",
            "[20]\ttraining's binary_logloss: 0.221003\tvalid_1's binary_logloss: 0.221689\n",
            "[30]\ttraining's binary_logloss: 0.214382\tvalid_1's binary_logloss: 0.214847\n",
            "[40]\ttraining's binary_logloss: 0.210456\tvalid_1's binary_logloss: 0.210722\n",
            "[50]\ttraining's binary_logloss: 0.206761\tvalid_1's binary_logloss: 0.207842\n",
            "[60]\ttraining's binary_logloss: 0.204611\tvalid_1's binary_logloss: 0.2061\n",
            "[70]\ttraining's binary_logloss: 0.20253\tvalid_1's binary_logloss: 0.204722\n",
            "[80]\ttraining's binary_logloss: 0.200487\tvalid_1's binary_logloss: 0.204058\n",
            "[90]\ttraining's binary_logloss: 0.199006\tvalid_1's binary_logloss: 0.20314\n",
            "[100]\ttraining's binary_logloss: 0.197523\tvalid_1's binary_logloss: 0.202379\n",
            "[110]\ttraining's binary_logloss: 0.196127\tvalid_1's binary_logloss: 0.201484\n",
            "[120]\ttraining's binary_logloss: 0.194829\tvalid_1's binary_logloss: 0.201161\n",
            "[130]\ttraining's binary_logloss: 0.193729\tvalid_1's binary_logloss: 0.200893\n",
            "[140]\ttraining's binary_logloss: 0.192669\tvalid_1's binary_logloss: 0.200657\n",
            "[150]\ttraining's binary_logloss: 0.191553\tvalid_1's binary_logloss: 0.200452\n",
            "[160]\ttraining's binary_logloss: 0.190635\tvalid_1's binary_logloss: 0.199988\n",
            "[170]\ttraining's binary_logloss: 0.189683\tvalid_1's binary_logloss: 0.199564\n",
            "[180]\ttraining's binary_logloss: 0.188795\tvalid_1's binary_logloss: 0.199543\n",
            "[190]\ttraining's binary_logloss: 0.18784\tvalid_1's binary_logloss: 0.199365\n",
            "[200]\ttraining's binary_logloss: 0.186952\tvalid_1's binary_logloss: 0.199491\n",
            "[210]\ttraining's binary_logloss: 0.185981\tvalid_1's binary_logloss: 0.199447\n",
            "[220]\ttraining's binary_logloss: 0.185009\tvalid_1's binary_logloss: 0.199343\n",
            "[230]\ttraining's binary_logloss: 0.184236\tvalid_1's binary_logloss: 0.199143\n",
            "[240]\ttraining's binary_logloss: 0.183316\tvalid_1's binary_logloss: 0.198909\n",
            "[250]\ttraining's binary_logloss: 0.1826\tvalid_1's binary_logloss: 0.198881\n",
            "[260]\ttraining's binary_logloss: 0.181778\tvalid_1's binary_logloss: 0.198802\n",
            "[270]\ttraining's binary_logloss: 0.181201\tvalid_1's binary_logloss: 0.198921\n",
            "[280]\ttraining's binary_logloss: 0.180459\tvalid_1's binary_logloss: 0.198948\n",
            "[290]\ttraining's binary_logloss: 0.179797\tvalid_1's binary_logloss: 0.198873\n",
            "[300]\ttraining's binary_logloss: 0.179073\tvalid_1's binary_logloss: 0.198888\n",
            "[310]\ttraining's binary_logloss: 0.178247\tvalid_1's binary_logloss: 0.19882\n",
            "[320]\ttraining's binary_logloss: 0.177397\tvalid_1's binary_logloss: 0.198782\n",
            "[330]\ttraining's binary_logloss: 0.176788\tvalid_1's binary_logloss: 0.198842\n",
            "[340]\ttraining's binary_logloss: 0.176209\tvalid_1's binary_logloss: 0.198815\n",
            "[350]\ttraining's binary_logloss: 0.175521\tvalid_1's binary_logloss: 0.198789\n",
            "[360]\ttraining's binary_logloss: 0.17488\tvalid_1's binary_logloss: 0.19878\n",
            "[370]\ttraining's binary_logloss: 0.174356\tvalid_1's binary_logloss: 0.198817\n",
            "[380]\ttraining's binary_logloss: 0.173796\tvalid_1's binary_logloss: 0.198843\n",
            "[390]\ttraining's binary_logloss: 0.173181\tvalid_1's binary_logloss: 0.198752\n",
            "[400]\ttraining's binary_logloss: 0.172608\tvalid_1's binary_logloss: 0.198622\n",
            "[410]\ttraining's binary_logloss: 0.172067\tvalid_1's binary_logloss: 0.198692\n",
            "[420]\ttraining's binary_logloss: 0.171448\tvalid_1's binary_logloss: 0.198711\n",
            "[430]\ttraining's binary_logloss: 0.170835\tvalid_1's binary_logloss: 0.198668\n",
            "[440]\ttraining's binary_logloss: 0.170137\tvalid_1's binary_logloss: 0.198728\n",
            "[450]\ttraining's binary_logloss: 0.169624\tvalid_1's binary_logloss: 0.198631\n",
            "[460]\ttraining's binary_logloss: 0.16904\tvalid_1's binary_logloss: 0.198762\n",
            "[470]\ttraining's binary_logloss: 0.168527\tvalid_1's binary_logloss: 0.198749\n",
            "[480]\ttraining's binary_logloss: 0.168006\tvalid_1's binary_logloss: 0.1988\n",
            "[490]\ttraining's binary_logloss: 0.167472\tvalid_1's binary_logloss: 0.198852\n",
            "Early stopping, best iteration is:\n",
            "[399]\ttraining's binary_logloss: 0.172678\tvalid_1's binary_logloss: 0.198606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "feature_fraction_stage2, val_score: 0.197935: 100%|##########| 6/6 [00:10<00:00,  1.70s/it][I 2020-08-30 05:32:08,561] Trial 42 finished with value: 0.19860592136306127 and parameters: {'feature_fraction': 0.42}. Best is trial 39 with value: 0.19793479158111074.\n",
            "feature_fraction_stage2, val_score: 0.197935: 100%|##########| 6/6 [00:10<00:00,  1.70s/it]\n",
            "regularization_factors, val_score: 0.197935:   0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230814\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214167\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209687\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200358\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193552\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192406\tvalid_1's binary_logloss: 0.200005\n",
            "[150]\ttraining's binary_logloss: 0.191266\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186419\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.185391\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184522\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.18357\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182771\tvalid_1's binary_logloss: 0.198243\n",
            "[250]\ttraining's binary_logloss: 0.182071\tvalid_1's binary_logloss: 0.198288\n",
            "[260]\ttraining's binary_logloss: 0.181305\tvalid_1's binary_logloss: 0.198155\n",
            "[270]\ttraining's binary_logloss: 0.180535\tvalid_1's binary_logloss: 0.198175\n",
            "[280]\ttraining's binary_logloss: 0.179739\tvalid_1's binary_logloss: 0.198246\n",
            "[290]\ttraining's binary_logloss: 0.179041\tvalid_1's binary_logloss: 0.198225\n",
            "[300]\ttraining's binary_logloss: 0.178242\tvalid_1's binary_logloss: 0.19814\n",
            "[310]\ttraining's binary_logloss: 0.177434\tvalid_1's binary_logloss: 0.198234\n",
            "[320]\ttraining's binary_logloss: 0.176712\tvalid_1's binary_logloss: 0.198218\n",
            "[330]\ttraining's binary_logloss: 0.176014\tvalid_1's binary_logloss: 0.198262\n",
            "[340]\ttraining's binary_logloss: 0.175407\tvalid_1's binary_logloss: 0.198289\n",
            "[350]\ttraining's binary_logloss: 0.174767\tvalid_1's binary_logloss: 0.198355\n",
            "[360]\ttraining's binary_logloss: 0.174104\tvalid_1's binary_logloss: 0.198303\n",
            "[370]\ttraining's binary_logloss: 0.173318\tvalid_1's binary_logloss: 0.198335\n",
            "Early stopping, best iteration is:\n",
            "[272]\ttraining's binary_logloss: 0.180367\tvalid_1's binary_logloss: 0.19807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197935:   5%|5         | 1/20 [00:01<00:24,  1.31s/it][I 2020-08-30 05:32:09,891] Trial 43 finished with value: 0.1980703776593155 and parameters: {'lambda_l1': 0.00031907282366722714, 'lambda_l2': 0.00021011904084377087}. Best is trial 43 with value: 0.1980703776593155.\n",
            "regularization_factors, val_score: 0.197935:   5%|5         | 1/20 [00:01<00:24,  1.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230814\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214167\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209687\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207249\n",
            "[60]\ttraining's binary_logloss: 0.203884\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200358\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195894\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193552\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192406\tvalid_1's binary_logloss: 0.200005\n",
            "[150]\ttraining's binary_logloss: 0.191266\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190288\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.189415\tvalid_1's binary_logloss: 0.199465\n",
            "[180]\ttraining's binary_logloss: 0.188419\tvalid_1's binary_logloss: 0.199372\n",
            "[190]\ttraining's binary_logloss: 0.187364\tvalid_1's binary_logloss: 0.199064\n",
            "[200]\ttraining's binary_logloss: 0.186511\tvalid_1's binary_logloss: 0.198904\n",
            "[210]\ttraining's binary_logloss: 0.185572\tvalid_1's binary_logloss: 0.198625\n",
            "[220]\ttraining's binary_logloss: 0.184652\tvalid_1's binary_logloss: 0.198576\n",
            "[230]\ttraining's binary_logloss: 0.1838\tvalid_1's binary_logloss: 0.198482\n",
            "[240]\ttraining's binary_logloss: 0.183031\tvalid_1's binary_logloss: 0.19839\n",
            "[250]\ttraining's binary_logloss: 0.182316\tvalid_1's binary_logloss: 0.198509\n",
            "[260]\ttraining's binary_logloss: 0.181446\tvalid_1's binary_logloss: 0.198338\n",
            "[270]\ttraining's binary_logloss: 0.180651\tvalid_1's binary_logloss: 0.198343\n",
            "[280]\ttraining's binary_logloss: 0.179822\tvalid_1's binary_logloss: 0.198273\n",
            "[290]\ttraining's binary_logloss: 0.179096\tvalid_1's binary_logloss: 0.198263\n",
            "[300]\ttraining's binary_logloss: 0.178433\tvalid_1's binary_logloss: 0.198263\n",
            "[310]\ttraining's binary_logloss: 0.17769\tvalid_1's binary_logloss: 0.198298\n",
            "[320]\ttraining's binary_logloss: 0.177039\tvalid_1's binary_logloss: 0.198267\n",
            "[330]\ttraining's binary_logloss: 0.17627\tvalid_1's binary_logloss: 0.198228\n",
            "[340]\ttraining's binary_logloss: 0.175653\tvalid_1's binary_logloss: 0.198115\n",
            "[350]\ttraining's binary_logloss: 0.17495\tvalid_1's binary_logloss: 0.198221\n",
            "[360]\ttraining's binary_logloss: 0.174269\tvalid_1's binary_logloss: 0.19803\n",
            "[370]\ttraining's binary_logloss: 0.173603\tvalid_1's binary_logloss: 0.198005\n",
            "[380]\ttraining's binary_logloss: 0.173005\tvalid_1's binary_logloss: 0.198007\n",
            "[390]\ttraining's binary_logloss: 0.172286\tvalid_1's binary_logloss: 0.198231\n",
            "[400]\ttraining's binary_logloss: 0.171733\tvalid_1's binary_logloss: 0.198182\n",
            "[410]\ttraining's binary_logloss: 0.171124\tvalid_1's binary_logloss: 0.19805\n",
            "[420]\ttraining's binary_logloss: 0.170514\tvalid_1's binary_logloss: 0.197963\n",
            "[430]\ttraining's binary_logloss: 0.169997\tvalid_1's binary_logloss: 0.197805\n",
            "[440]\ttraining's binary_logloss: 0.169449\tvalid_1's binary_logloss: 0.197926\n",
            "[450]\ttraining's binary_logloss: 0.168825\tvalid_1's binary_logloss: 0.197946\n",
            "[460]\ttraining's binary_logloss: 0.168183\tvalid_1's binary_logloss: 0.198076\n",
            "[470]\ttraining's binary_logloss: 0.167592\tvalid_1's binary_logloss: 0.198143\n",
            "[480]\ttraining's binary_logloss: 0.166942\tvalid_1's binary_logloss: 0.198308\n",
            "[490]\ttraining's binary_logloss: 0.166417\tvalid_1's binary_logloss: 0.19834\n",
            "[500]\ttraining's binary_logloss: 0.165846\tvalid_1's binary_logloss: 0.198404\n",
            "[510]\ttraining's binary_logloss: 0.1653\tvalid_1's binary_logloss: 0.198469\n",
            "[520]\ttraining's binary_logloss: 0.164644\tvalid_1's binary_logloss: 0.19846\n",
            "[530]\ttraining's binary_logloss: 0.164085\tvalid_1's binary_logloss: 0.198686\n",
            "Early stopping, best iteration is:\n",
            "[430]\ttraining's binary_logloss: 0.169997\tvalid_1's binary_logloss: 0.197805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197805:  10%|#         | 2/20 [00:03<00:26,  1.48s/it][I 2020-08-30 05:32:11,763] Trial 44 finished with value: 0.19780454270935094 and parameters: {'lambda_l1': 0.0005879954911090446, 'lambda_l2': 0.00015433260500989177}. Best is trial 44 with value: 0.19780454270935094.\n",
            "regularization_factors, val_score: 0.197805:  10%|#         | 2/20 [00:03<00:26,  1.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230814\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214167\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209687\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207249\n",
            "[60]\ttraining's binary_logloss: 0.203884\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202152\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200358\tvalid_1's binary_logloss: 0.203016\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195894\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.19481\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193552\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192406\tvalid_1's binary_logloss: 0.200005\n",
            "[150]\ttraining's binary_logloss: 0.191267\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190288\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.189415\tvalid_1's binary_logloss: 0.199465\n",
            "[180]\ttraining's binary_logloss: 0.188419\tvalid_1's binary_logloss: 0.199372\n",
            "[190]\ttraining's binary_logloss: 0.187364\tvalid_1's binary_logloss: 0.199064\n",
            "[200]\ttraining's binary_logloss: 0.186511\tvalid_1's binary_logloss: 0.198904\n",
            "[210]\ttraining's binary_logloss: 0.185573\tvalid_1's binary_logloss: 0.198625\n",
            "[220]\ttraining's binary_logloss: 0.184652\tvalid_1's binary_logloss: 0.198576\n",
            "[230]\ttraining's binary_logloss: 0.1838\tvalid_1's binary_logloss: 0.198482\n",
            "[240]\ttraining's binary_logloss: 0.183032\tvalid_1's binary_logloss: 0.19839\n",
            "[250]\ttraining's binary_logloss: 0.182317\tvalid_1's binary_logloss: 0.198509\n",
            "[260]\ttraining's binary_logloss: 0.181446\tvalid_1's binary_logloss: 0.198338\n",
            "[270]\ttraining's binary_logloss: 0.180652\tvalid_1's binary_logloss: 0.198343\n",
            "[280]\ttraining's binary_logloss: 0.179822\tvalid_1's binary_logloss: 0.198273\n",
            "[290]\ttraining's binary_logloss: 0.179097\tvalid_1's binary_logloss: 0.198263\n",
            "[300]\ttraining's binary_logloss: 0.178434\tvalid_1's binary_logloss: 0.198263\n",
            "[310]\ttraining's binary_logloss: 0.17769\tvalid_1's binary_logloss: 0.198298\n",
            "[320]\ttraining's binary_logloss: 0.17704\tvalid_1's binary_logloss: 0.198267\n",
            "[330]\ttraining's binary_logloss: 0.17627\tvalid_1's binary_logloss: 0.198228\n",
            "[340]\ttraining's binary_logloss: 0.175653\tvalid_1's binary_logloss: 0.198115\n",
            "[350]\ttraining's binary_logloss: 0.174951\tvalid_1's binary_logloss: 0.198221\n",
            "[360]\ttraining's binary_logloss: 0.174269\tvalid_1's binary_logloss: 0.19803\n",
            "[370]\ttraining's binary_logloss: 0.173604\tvalid_1's binary_logloss: 0.198005\n",
            "[380]\ttraining's binary_logloss: 0.173006\tvalid_1's binary_logloss: 0.198007\n",
            "[390]\ttraining's binary_logloss: 0.172287\tvalid_1's binary_logloss: 0.198231\n",
            "[400]\ttraining's binary_logloss: 0.171734\tvalid_1's binary_logloss: 0.198181\n",
            "[410]\ttraining's binary_logloss: 0.171125\tvalid_1's binary_logloss: 0.19805\n",
            "[420]\ttraining's binary_logloss: 0.170515\tvalid_1's binary_logloss: 0.197963\n",
            "[430]\ttraining's binary_logloss: 0.169998\tvalid_1's binary_logloss: 0.197804\n",
            "[440]\ttraining's binary_logloss: 0.16945\tvalid_1's binary_logloss: 0.197926\n",
            "[450]\ttraining's binary_logloss: 0.168826\tvalid_1's binary_logloss: 0.197946\n",
            "[460]\ttraining's binary_logloss: 0.168184\tvalid_1's binary_logloss: 0.198076\n",
            "[470]\ttraining's binary_logloss: 0.167593\tvalid_1's binary_logloss: 0.198143\n",
            "[480]\ttraining's binary_logloss: 0.166943\tvalid_1's binary_logloss: 0.198308\n",
            "[490]\ttraining's binary_logloss: 0.166418\tvalid_1's binary_logloss: 0.19834\n",
            "[500]\ttraining's binary_logloss: 0.165847\tvalid_1's binary_logloss: 0.198404\n",
            "[510]\ttraining's binary_logloss: 0.165336\tvalid_1's binary_logloss: 0.198499\n",
            "[520]\ttraining's binary_logloss: 0.164689\tvalid_1's binary_logloss: 0.198471\n",
            "[530]\ttraining's binary_logloss: 0.164086\tvalid_1's binary_logloss: 0.19861\n",
            "Early stopping, best iteration is:\n",
            "[430]\ttraining's binary_logloss: 0.169998\tvalid_1's binary_logloss: 0.197804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  15%|#5        | 3/20 [00:05<00:27,  1.61s/it][I 2020-08-30 05:32:13,673] Trial 45 finished with value: 0.19780442664242456 and parameters: {'lambda_l1': 0.0007273150607843104, 'lambda_l2': 0.00025316818794236204}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  15%|#5        | 3/20 [00:05<00:27,  1.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230814\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214167\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209687\n",
            "[50]\ttraining's binary_logloss: 0.206286\tvalid_1's binary_logloss: 0.207249\n",
            "[60]\ttraining's binary_logloss: 0.203884\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202152\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200358\tvalid_1's binary_logloss: 0.203016\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197278\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195894\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.19481\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193552\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192406\tvalid_1's binary_logloss: 0.200005\n",
            "[150]\ttraining's binary_logloss: 0.191267\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190288\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18934\tvalid_1's binary_logloss: 0.199343\n",
            "[180]\ttraining's binary_logloss: 0.188245\tvalid_1's binary_logloss: 0.19923\n",
            "[190]\ttraining's binary_logloss: 0.187203\tvalid_1's binary_logloss: 0.19913\n",
            "[200]\ttraining's binary_logloss: 0.186369\tvalid_1's binary_logloss: 0.199022\n",
            "[210]\ttraining's binary_logloss: 0.185442\tvalid_1's binary_logloss: 0.198857\n",
            "[220]\ttraining's binary_logloss: 0.184597\tvalid_1's binary_logloss: 0.198795\n",
            "[230]\ttraining's binary_logloss: 0.183772\tvalid_1's binary_logloss: 0.198808\n",
            "[240]\ttraining's binary_logloss: 0.183008\tvalid_1's binary_logloss: 0.198773\n",
            "[250]\ttraining's binary_logloss: 0.182211\tvalid_1's binary_logloss: 0.198913\n",
            "[260]\ttraining's binary_logloss: 0.181334\tvalid_1's binary_logloss: 0.198755\n",
            "[270]\ttraining's binary_logloss: 0.180508\tvalid_1's binary_logloss: 0.19874\n",
            "[280]\ttraining's binary_logloss: 0.179689\tvalid_1's binary_logloss: 0.198803\n",
            "[290]\ttraining's binary_logloss: 0.179013\tvalid_1's binary_logloss: 0.198666\n",
            "[300]\ttraining's binary_logloss: 0.178336\tvalid_1's binary_logloss: 0.198657\n",
            "[310]\ttraining's binary_logloss: 0.177623\tvalid_1's binary_logloss: 0.198745\n",
            "[320]\ttraining's binary_logloss: 0.176875\tvalid_1's binary_logloss: 0.198647\n",
            "[330]\ttraining's binary_logloss: 0.176177\tvalid_1's binary_logloss: 0.198526\n",
            "[340]\ttraining's binary_logloss: 0.175567\tvalid_1's binary_logloss: 0.198496\n",
            "[350]\ttraining's binary_logloss: 0.174824\tvalid_1's binary_logloss: 0.198346\n",
            "[360]\ttraining's binary_logloss: 0.174182\tvalid_1's binary_logloss: 0.198329\n",
            "[370]\ttraining's binary_logloss: 0.173544\tvalid_1's binary_logloss: 0.198457\n",
            "[380]\ttraining's binary_logloss: 0.172973\tvalid_1's binary_logloss: 0.198455\n",
            "[390]\ttraining's binary_logloss: 0.172165\tvalid_1's binary_logloss: 0.19858\n",
            "[400]\ttraining's binary_logloss: 0.171587\tvalid_1's binary_logloss: 0.198552\n",
            "[410]\ttraining's binary_logloss: 0.170952\tvalid_1's binary_logloss: 0.198616\n",
            "[420]\ttraining's binary_logloss: 0.170377\tvalid_1's binary_logloss: 0.198581\n",
            "[430]\ttraining's binary_logloss: 0.169703\tvalid_1's binary_logloss: 0.198684\n",
            "[440]\ttraining's binary_logloss: 0.169174\tvalid_1's binary_logloss: 0.198848\n",
            "[450]\ttraining's binary_logloss: 0.168591\tvalid_1's binary_logloss: 0.198771\n",
            "Early stopping, best iteration is:\n",
            "[355]\ttraining's binary_logloss: 0.174546\tvalid_1's binary_logloss: 0.198267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  20%|##        | 4/20 [00:06<00:25,  1.60s/it][I 2020-08-30 05:32:15,255] Trial 46 finished with value: 0.19826656075322094 and parameters: {'lambda_l1': 0.0010261251675819428, 'lambda_l2': 0.00012371547311955462}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  20%|##        | 4/20 [00:06<00:25,  1.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.231551\tvalid_1's binary_logloss: 0.231898\n",
            "[20]\ttraining's binary_logloss: 0.220673\tvalid_1's binary_logloss: 0.221252\n",
            "[30]\ttraining's binary_logloss: 0.214611\tvalid_1's binary_logloss: 0.214706\n",
            "[40]\ttraining's binary_logloss: 0.210284\tvalid_1's binary_logloss: 0.210151\n",
            "[50]\ttraining's binary_logloss: 0.206964\tvalid_1's binary_logloss: 0.207396\n",
            "[60]\ttraining's binary_logloss: 0.204809\tvalid_1's binary_logloss: 0.205514\n",
            "[70]\ttraining's binary_logloss: 0.202889\tvalid_1's binary_logloss: 0.203926\n",
            "[80]\ttraining's binary_logloss: 0.201365\tvalid_1's binary_logloss: 0.203214\n",
            "[90]\ttraining's binary_logloss: 0.199739\tvalid_1's binary_logloss: 0.202304\n",
            "[100]\ttraining's binary_logloss: 0.198417\tvalid_1's binary_logloss: 0.201684\n",
            "[110]\ttraining's binary_logloss: 0.197217\tvalid_1's binary_logloss: 0.201084\n",
            "[120]\ttraining's binary_logloss: 0.196238\tvalid_1's binary_logloss: 0.200887\n",
            "[130]\ttraining's binary_logloss: 0.195147\tvalid_1's binary_logloss: 0.200278\n",
            "[140]\ttraining's binary_logloss: 0.194338\tvalid_1's binary_logloss: 0.200141\n",
            "[150]\ttraining's binary_logloss: 0.193478\tvalid_1's binary_logloss: 0.199877\n",
            "[160]\ttraining's binary_logloss: 0.192714\tvalid_1's binary_logloss: 0.199591\n",
            "[170]\ttraining's binary_logloss: 0.191835\tvalid_1's binary_logloss: 0.199396\n",
            "[180]\ttraining's binary_logloss: 0.190996\tvalid_1's binary_logloss: 0.199252\n",
            "[190]\ttraining's binary_logloss: 0.190272\tvalid_1's binary_logloss: 0.199229\n",
            "[200]\ttraining's binary_logloss: 0.18942\tvalid_1's binary_logloss: 0.199255\n",
            "[210]\ttraining's binary_logloss: 0.188591\tvalid_1's binary_logloss: 0.199172\n",
            "[220]\ttraining's binary_logloss: 0.187848\tvalid_1's binary_logloss: 0.199016\n",
            "[230]\ttraining's binary_logloss: 0.186987\tvalid_1's binary_logloss: 0.198936\n",
            "[240]\ttraining's binary_logloss: 0.186222\tvalid_1's binary_logloss: 0.198801\n",
            "[250]\ttraining's binary_logloss: 0.185539\tvalid_1's binary_logloss: 0.198776\n",
            "[260]\ttraining's binary_logloss: 0.184836\tvalid_1's binary_logloss: 0.198625\n",
            "[270]\ttraining's binary_logloss: 0.184202\tvalid_1's binary_logloss: 0.198522\n",
            "[280]\ttraining's binary_logloss: 0.183385\tvalid_1's binary_logloss: 0.198552\n",
            "[290]\ttraining's binary_logloss: 0.182712\tvalid_1's binary_logloss: 0.198309\n",
            "[300]\ttraining's binary_logloss: 0.182017\tvalid_1's binary_logloss: 0.19821\n",
            "[310]\ttraining's binary_logloss: 0.18145\tvalid_1's binary_logloss: 0.198134\n",
            "[320]\ttraining's binary_logloss: 0.180845\tvalid_1's binary_logloss: 0.198044\n",
            "[330]\ttraining's binary_logloss: 0.180231\tvalid_1's binary_logloss: 0.198017\n",
            "[340]\ttraining's binary_logloss: 0.17967\tvalid_1's binary_logloss: 0.197921\n",
            "[350]\ttraining's binary_logloss: 0.17918\tvalid_1's binary_logloss: 0.197943\n",
            "[360]\ttraining's binary_logloss: 0.178612\tvalid_1's binary_logloss: 0.198011\n",
            "[370]\ttraining's binary_logloss: 0.178067\tvalid_1's binary_logloss: 0.198039\n",
            "[380]\ttraining's binary_logloss: 0.177582\tvalid_1's binary_logloss: 0.19796\n",
            "[390]\ttraining's binary_logloss: 0.177096\tvalid_1's binary_logloss: 0.198024\n",
            "[400]\ttraining's binary_logloss: 0.17656\tvalid_1's binary_logloss: 0.198067\n",
            "[410]\ttraining's binary_logloss: 0.176008\tvalid_1's binary_logloss: 0.198129\n",
            "[420]\ttraining's binary_logloss: 0.175516\tvalid_1's binary_logloss: 0.198094\n",
            "[430]\ttraining's binary_logloss: 0.175032\tvalid_1's binary_logloss: 0.198111\n",
            "[440]\ttraining's binary_logloss: 0.174499\tvalid_1's binary_logloss: 0.198206\n",
            "Early stopping, best iteration is:\n",
            "[347]\ttraining's binary_logloss: 0.179341\tvalid_1's binary_logloss: 0.197872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  25%|##5       | 5/20 [00:08<00:23,  1.59s/it][I 2020-08-30 05:32:16,833] Trial 47 finished with value: 0.197872135624636 and parameters: {'lambda_l1': 0.7437219209409562, 'lambda_l2': 2.1638648896187}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  25%|##5       | 5/20 [00:08<00:23,  1.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.233586\tvalid_1's binary_logloss: 0.233865\n",
            "[20]\ttraining's binary_logloss: 0.222638\tvalid_1's binary_logloss: 0.223031\n",
            "[30]\ttraining's binary_logloss: 0.215988\tvalid_1's binary_logloss: 0.215863\n",
            "[40]\ttraining's binary_logloss: 0.212182\tvalid_1's binary_logloss: 0.211765\n",
            "[50]\ttraining's binary_logloss: 0.209212\tvalid_1's binary_logloss: 0.208853\n",
            "[60]\ttraining's binary_logloss: 0.206843\tvalid_1's binary_logloss: 0.206522\n",
            "[70]\ttraining's binary_logloss: 0.204991\tvalid_1's binary_logloss: 0.205193\n",
            "[80]\ttraining's binary_logloss: 0.203514\tvalid_1's binary_logloss: 0.204072\n",
            "[90]\ttraining's binary_logloss: 0.2023\tvalid_1's binary_logloss: 0.203157\n",
            "[100]\ttraining's binary_logloss: 0.201165\tvalid_1's binary_logloss: 0.202239\n",
            "[110]\ttraining's binary_logloss: 0.200202\tvalid_1's binary_logloss: 0.201795\n",
            "[120]\ttraining's binary_logloss: 0.19931\tvalid_1's binary_logloss: 0.201367\n",
            "[130]\ttraining's binary_logloss: 0.198457\tvalid_1's binary_logloss: 0.200971\n",
            "[140]\ttraining's binary_logloss: 0.197609\tvalid_1's binary_logloss: 0.200613\n",
            "[150]\ttraining's binary_logloss: 0.196773\tvalid_1's binary_logloss: 0.200196\n",
            "[160]\ttraining's binary_logloss: 0.196152\tvalid_1's binary_logloss: 0.199982\n",
            "[170]\ttraining's binary_logloss: 0.195369\tvalid_1's binary_logloss: 0.199586\n",
            "[180]\ttraining's binary_logloss: 0.194721\tvalid_1's binary_logloss: 0.199337\n",
            "[190]\ttraining's binary_logloss: 0.194142\tvalid_1's binary_logloss: 0.199112\n",
            "[200]\ttraining's binary_logloss: 0.193495\tvalid_1's binary_logloss: 0.199023\n",
            "[210]\ttraining's binary_logloss: 0.19292\tvalid_1's binary_logloss: 0.199005\n",
            "[220]\ttraining's binary_logloss: 0.192402\tvalid_1's binary_logloss: 0.198873\n",
            "[230]\ttraining's binary_logloss: 0.191809\tvalid_1's binary_logloss: 0.198892\n",
            "[240]\ttraining's binary_logloss: 0.191226\tvalid_1's binary_logloss: 0.19886\n",
            "[250]\ttraining's binary_logloss: 0.190719\tvalid_1's binary_logloss: 0.198839\n",
            "[260]\ttraining's binary_logloss: 0.190245\tvalid_1's binary_logloss: 0.198723\n",
            "[270]\ttraining's binary_logloss: 0.189774\tvalid_1's binary_logloss: 0.198741\n",
            "[280]\ttraining's binary_logloss: 0.189296\tvalid_1's binary_logloss: 0.198729\n",
            "[290]\ttraining's binary_logloss: 0.188909\tvalid_1's binary_logloss: 0.198621\n",
            "[300]\ttraining's binary_logloss: 0.188504\tvalid_1's binary_logloss: 0.198544\n",
            "[310]\ttraining's binary_logloss: 0.188072\tvalid_1's binary_logloss: 0.19856\n",
            "[320]\ttraining's binary_logloss: 0.187558\tvalid_1's binary_logloss: 0.198524\n",
            "[330]\ttraining's binary_logloss: 0.187116\tvalid_1's binary_logloss: 0.198561\n",
            "[340]\ttraining's binary_logloss: 0.186675\tvalid_1's binary_logloss: 0.198543\n",
            "[350]\ttraining's binary_logloss: 0.186272\tvalid_1's binary_logloss: 0.198393\n",
            "[360]\ttraining's binary_logloss: 0.18586\tvalid_1's binary_logloss: 0.198369\n",
            "[370]\ttraining's binary_logloss: 0.185412\tvalid_1's binary_logloss: 0.198293\n",
            "[380]\ttraining's binary_logloss: 0.185111\tvalid_1's binary_logloss: 0.198168\n",
            "[390]\ttraining's binary_logloss: 0.184767\tvalid_1's binary_logloss: 0.198198\n",
            "[400]\ttraining's binary_logloss: 0.184441\tvalid_1's binary_logloss: 0.198142\n",
            "[410]\ttraining's binary_logloss: 0.18405\tvalid_1's binary_logloss: 0.198086\n",
            "[420]\ttraining's binary_logloss: 0.183682\tvalid_1's binary_logloss: 0.198088\n",
            "[430]\ttraining's binary_logloss: 0.183339\tvalid_1's binary_logloss: 0.198053\n",
            "[440]\ttraining's binary_logloss: 0.182989\tvalid_1's binary_logloss: 0.198061\n",
            "[450]\ttraining's binary_logloss: 0.182667\tvalid_1's binary_logloss: 0.198031\n",
            "[460]\ttraining's binary_logloss: 0.182355\tvalid_1's binary_logloss: 0.198074\n",
            "[470]\ttraining's binary_logloss: 0.182048\tvalid_1's binary_logloss: 0.198036\n",
            "[480]\ttraining's binary_logloss: 0.18167\tvalid_1's binary_logloss: 0.198031\n",
            "[490]\ttraining's binary_logloss: 0.18137\tvalid_1's binary_logloss: 0.198052\n",
            "[500]\ttraining's binary_logloss: 0.181104\tvalid_1's binary_logloss: 0.198007\n",
            "[510]\ttraining's binary_logloss: 0.180789\tvalid_1's binary_logloss: 0.198015\n",
            "[520]\ttraining's binary_logloss: 0.180437\tvalid_1's binary_logloss: 0.198046\n",
            "[530]\ttraining's binary_logloss: 0.180104\tvalid_1's binary_logloss: 0.198046\n",
            "[540]\ttraining's binary_logloss: 0.179872\tvalid_1's binary_logloss: 0.198027\n",
            "[550]\ttraining's binary_logloss: 0.179584\tvalid_1's binary_logloss: 0.198112\n",
            "[560]\ttraining's binary_logloss: 0.179317\tvalid_1's binary_logloss: 0.198144\n",
            "[570]\ttraining's binary_logloss: 0.17902\tvalid_1's binary_logloss: 0.198172\n",
            "[580]\ttraining's binary_logloss: 0.178762\tvalid_1's binary_logloss: 0.198166\n",
            "[590]\ttraining's binary_logloss: 0.178456\tvalid_1's binary_logloss: 0.198179\n",
            "[600]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198222\n",
            "Early stopping, best iteration is:\n",
            "[504]\ttraining's binary_logloss: 0.180979\tvalid_1's binary_logloss: 0.197996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  30%|###       | 6/20 [00:10<00:24,  1.76s/it][I 2020-08-30 05:32:18,991] Trial 48 finished with value: 0.19799635531846252 and parameters: {'lambda_l1': 3.2371039255374896, 'lambda_l2': 9.381474462803464}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  30%|###       | 6/20 [00:10<00:24,  1.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.231573\tvalid_1's binary_logloss: 0.231728\n",
            "[20]\ttraining's binary_logloss: 0.2206\tvalid_1's binary_logloss: 0.220631\n",
            "[30]\ttraining's binary_logloss: 0.214592\tvalid_1's binary_logloss: 0.214401\n",
            "[40]\ttraining's binary_logloss: 0.210212\tvalid_1's binary_logloss: 0.209799\n",
            "[50]\ttraining's binary_logloss: 0.207121\tvalid_1's binary_logloss: 0.20686\n",
            "[60]\ttraining's binary_logloss: 0.204985\tvalid_1's binary_logloss: 0.205045\n",
            "[70]\ttraining's binary_logloss: 0.203163\tvalid_1's binary_logloss: 0.203723\n",
            "[80]\ttraining's binary_logloss: 0.201534\tvalid_1's binary_logloss: 0.20296\n",
            "[90]\ttraining's binary_logloss: 0.200049\tvalid_1's binary_logloss: 0.202243\n",
            "[100]\ttraining's binary_logloss: 0.198649\tvalid_1's binary_logloss: 0.201402\n",
            "[110]\ttraining's binary_logloss: 0.197322\tvalid_1's binary_logloss: 0.200745\n",
            "[120]\ttraining's binary_logloss: 0.196219\tvalid_1's binary_logloss: 0.200487\n",
            "[130]\ttraining's binary_logloss: 0.19515\tvalid_1's binary_logloss: 0.1999\n",
            "[140]\ttraining's binary_logloss: 0.194156\tvalid_1's binary_logloss: 0.199681\n",
            "[150]\ttraining's binary_logloss: 0.19306\tvalid_1's binary_logloss: 0.19963\n",
            "[160]\ttraining's binary_logloss: 0.192292\tvalid_1's binary_logloss: 0.199368\n",
            "[170]\ttraining's binary_logloss: 0.191439\tvalid_1's binary_logloss: 0.199264\n",
            "[180]\ttraining's binary_logloss: 0.190586\tvalid_1's binary_logloss: 0.199229\n",
            "[190]\ttraining's binary_logloss: 0.189763\tvalid_1's binary_logloss: 0.199083\n",
            "[200]\ttraining's binary_logloss: 0.188962\tvalid_1's binary_logloss: 0.198995\n",
            "[210]\ttraining's binary_logloss: 0.188181\tvalid_1's binary_logloss: 0.198855\n",
            "[220]\ttraining's binary_logloss: 0.187431\tvalid_1's binary_logloss: 0.198858\n",
            "[230]\ttraining's binary_logloss: 0.186698\tvalid_1's binary_logloss: 0.198888\n",
            "[240]\ttraining's binary_logloss: 0.185932\tvalid_1's binary_logloss: 0.198731\n",
            "[250]\ttraining's binary_logloss: 0.185214\tvalid_1's binary_logloss: 0.19863\n",
            "[260]\ttraining's binary_logloss: 0.184432\tvalid_1's binary_logloss: 0.198688\n",
            "[270]\ttraining's binary_logloss: 0.183661\tvalid_1's binary_logloss: 0.198762\n",
            "[280]\ttraining's binary_logloss: 0.182924\tvalid_1's binary_logloss: 0.198533\n",
            "[290]\ttraining's binary_logloss: 0.182191\tvalid_1's binary_logloss: 0.198612\n",
            "[300]\ttraining's binary_logloss: 0.181531\tvalid_1's binary_logloss: 0.198637\n",
            "[310]\ttraining's binary_logloss: 0.180912\tvalid_1's binary_logloss: 0.198462\n",
            "[320]\ttraining's binary_logloss: 0.180359\tvalid_1's binary_logloss: 0.198325\n",
            "[330]\ttraining's binary_logloss: 0.179762\tvalid_1's binary_logloss: 0.198303\n",
            "[340]\ttraining's binary_logloss: 0.179205\tvalid_1's binary_logloss: 0.198373\n",
            "[350]\ttraining's binary_logloss: 0.178607\tvalid_1's binary_logloss: 0.198402\n",
            "[360]\ttraining's binary_logloss: 0.178082\tvalid_1's binary_logloss: 0.198187\n",
            "[370]\ttraining's binary_logloss: 0.17753\tvalid_1's binary_logloss: 0.198268\n",
            "[380]\ttraining's binary_logloss: 0.177012\tvalid_1's binary_logloss: 0.198243\n",
            "[390]\ttraining's binary_logloss: 0.176519\tvalid_1's binary_logloss: 0.198408\n",
            "[400]\ttraining's binary_logloss: 0.175925\tvalid_1's binary_logloss: 0.19838\n",
            "[410]\ttraining's binary_logloss: 0.175439\tvalid_1's binary_logloss: 0.198455\n",
            "[420]\ttraining's binary_logloss: 0.174985\tvalid_1's binary_logloss: 0.198499\n",
            "[430]\ttraining's binary_logloss: 0.174468\tvalid_1's binary_logloss: 0.198477\n",
            "[440]\ttraining's binary_logloss: 0.173968\tvalid_1's binary_logloss: 0.198477\n",
            "[450]\ttraining's binary_logloss: 0.173464\tvalid_1's binary_logloss: 0.19838\n",
            "[460]\ttraining's binary_logloss: 0.172995\tvalid_1's binary_logloss: 0.198286\n",
            "Early stopping, best iteration is:\n",
            "[360]\ttraining's binary_logloss: 0.178082\tvalid_1's binary_logloss: 0.198187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  35%|###5      | 7/20 [00:12<00:22,  1.72s/it][I 2020-08-30 05:32:20,605] Trial 49 finished with value: 0.19818688220133754 and parameters: {'lambda_l1': 0.02729787520909197, 'lambda_l2': 2.2641417580054575}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  35%|###5      | 7/20 [00:12<00:22,  1.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169136\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  40%|####      | 8/20 [00:13<00:20,  1.72s/it][I 2020-08-30 05:32:22,339] Trial 50 finished with value: 0.19793479154591156 and parameters: {'lambda_l1': 7.480964036026327e-08, 'lambda_l2': 1.410010005832339e-08}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  40%|####      | 8/20 [00:13<00:20,  1.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169136\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  45%|####5     | 9/20 [00:15<00:19,  1.76s/it][I 2020-08-30 05:32:24,187] Trial 51 finished with value: 0.19793479157037955 and parameters: {'lambda_l1': 1.674464361870465e-08, 'lambda_l2': 1.551476003846762e-08}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  45%|####5     | 9/20 [00:15<00:19,  1.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169136\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  50%|#####     | 10/20 [00:17<00:17,  1.77s/it][I 2020-08-30 05:32:25,994] Trial 52 finished with value: 0.19793479155947585 and parameters: {'lambda_l1': 4.571388160287313e-08, 'lambda_l2': 1.2090890011249921e-08}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  50%|#####     | 10/20 [00:17<00:17,  1.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169136\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  55%|#####5    | 11/20 [00:19<00:15,  1.76s/it][I 2020-08-30 05:32:27,712] Trial 53 finished with value: 0.1979347915708342 and parameters: {'lambda_l1': 1.1920039660832735e-08, 'lambda_l2': 1.3765482381411385e-08}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  55%|#####5    | 11/20 [00:19<00:15,  1.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169136\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  60%|######    | 12/20 [00:20<00:14,  1.76s/it][I 2020-08-30 05:32:29,481] Trial 54 finished with value: 0.19793479155806318 and parameters: {'lambda_l1': 2.5636511042934637e-08, 'lambda_l2': 2.6983589448398543e-08}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  60%|######    | 12/20 [00:20<00:14,  1.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169136\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  65%|######5   | 13/20 [00:22<00:12,  1.74s/it][I 2020-08-30 05:32:31,158] Trial 55 finished with value: 0.19793479148574866 and parameters: {'lambda_l1': 2.45436969235126e-07, 'lambda_l2': 1.2725771995020642e-08}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  65%|######5   | 13/20 [00:22<00:12,  1.74s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169137\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  70%|#######   | 14/20 [00:24<00:10,  1.71s/it][I 2020-08-30 05:32:32,814] Trial 56 finished with value: 0.19793479063528582 and parameters: {'lambda_l1': 2.885932110161648e-07, 'lambda_l2': 1.7611154545222791e-06}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  70%|#######   | 14/20 [00:24<00:10,  1.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169137\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  75%|#######5  | 15/20 [00:25<00:08,  1.71s/it][I 2020-08-30 05:32:34,525] Trial 57 finished with value: 0.1979347897048173 and parameters: {'lambda_l1': 3.2693428693510504e-06, 'lambda_l2': 1.453362562952521e-06}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  75%|#######5  | 15/20 [00:25<00:08,  1.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169137\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  80%|########  | 16/20 [00:27<00:06,  1.73s/it][I 2020-08-30 05:32:36,287] Trial 58 finished with value: 0.1979347892092385 and parameters: {'lambda_l1': 1.38481846197844e-06, 'lambda_l2': 3.874892755402137e-06}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  80%|########  | 16/20 [00:27<00:06,  1.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169137\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  85%|########5 | 17/20 [00:29<00:05,  1.72s/it][I 2020-08-30 05:32:37,977] Trial 59 finished with value: 0.19793478636879364 and parameters: {'lambda_l1': 7.806292618392871e-06, 'lambda_l2': 4.953937457584669e-06}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  85%|########5 | 17/20 [00:29<00:05,  1.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176662\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169137\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  90%|######### | 18/20 [00:31<00:03,  1.72s/it][I 2020-08-30 05:32:39,709] Trial 60 finished with value: 0.19793478568317105 and parameters: {'lambda_l1': 1.363411580123454e-05, 'lambda_l2': 2.0665094225292437e-06}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  90%|######### | 18/20 [00:31<00:03,  1.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169137\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804:  95%|#########5| 19/20 [00:32<00:01,  1.71s/it][I 2020-08-30 05:32:41,395] Trial 61 finished with value: 0.19793478728663977 and parameters: {'lambda_l1': 7.921041899174184e-06, 'lambda_l2': 2.9654622140722593e-06}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804:  95%|#########5| 19/20 [00:32<00:01,  1.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230813\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214166\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209686\n",
            "[50]\ttraining's binary_logloss: 0.206285\tvalid_1's binary_logloss: 0.207248\n",
            "[60]\ttraining's binary_logloss: 0.203883\tvalid_1's binary_logloss: 0.205071\n",
            "[70]\ttraining's binary_logloss: 0.202151\tvalid_1's binary_logloss: 0.204111\n",
            "[80]\ttraining's binary_logloss: 0.200357\tvalid_1's binary_logloss: 0.203015\n",
            "[90]\ttraining's binary_logloss: 0.198733\tvalid_1's binary_logloss: 0.202468\n",
            "[100]\ttraining's binary_logloss: 0.197277\tvalid_1's binary_logloss: 0.201653\n",
            "[110]\ttraining's binary_logloss: 0.195893\tvalid_1's binary_logloss: 0.201022\n",
            "[120]\ttraining's binary_logloss: 0.194809\tvalid_1's binary_logloss: 0.200725\n",
            "[130]\ttraining's binary_logloss: 0.193551\tvalid_1's binary_logloss: 0.200235\n",
            "[140]\ttraining's binary_logloss: 0.192405\tvalid_1's binary_logloss: 0.200004\n",
            "[150]\ttraining's binary_logloss: 0.191265\tvalid_1's binary_logloss: 0.199844\n",
            "[160]\ttraining's binary_logloss: 0.190287\tvalid_1's binary_logloss: 0.199717\n",
            "[170]\ttraining's binary_logloss: 0.18943\tvalid_1's binary_logloss: 0.199442\n",
            "[180]\ttraining's binary_logloss: 0.18845\tvalid_1's binary_logloss: 0.199322\n",
            "[190]\ttraining's binary_logloss: 0.187359\tvalid_1's binary_logloss: 0.1989\n",
            "[200]\ttraining's binary_logloss: 0.186418\tvalid_1's binary_logloss: 0.198708\n",
            "[210]\ttraining's binary_logloss: 0.18539\tvalid_1's binary_logloss: 0.19872\n",
            "[220]\ttraining's binary_logloss: 0.184521\tvalid_1's binary_logloss: 0.198524\n",
            "[230]\ttraining's binary_logloss: 0.183569\tvalid_1's binary_logloss: 0.198311\n",
            "[240]\ttraining's binary_logloss: 0.182796\tvalid_1's binary_logloss: 0.198248\n",
            "[250]\ttraining's binary_logloss: 0.182049\tvalid_1's binary_logloss: 0.198347\n",
            "[260]\ttraining's binary_logloss: 0.181325\tvalid_1's binary_logloss: 0.198347\n",
            "[270]\ttraining's binary_logloss: 0.18056\tvalid_1's binary_logloss: 0.198613\n",
            "[280]\ttraining's binary_logloss: 0.179706\tvalid_1's binary_logloss: 0.198537\n",
            "[290]\ttraining's binary_logloss: 0.17908\tvalid_1's binary_logloss: 0.198478\n",
            "[300]\ttraining's binary_logloss: 0.178206\tvalid_1's binary_logloss: 0.198453\n",
            "[310]\ttraining's binary_logloss: 0.177362\tvalid_1's binary_logloss: 0.198328\n",
            "[320]\ttraining's binary_logloss: 0.176661\tvalid_1's binary_logloss: 0.198342\n",
            "[330]\ttraining's binary_logloss: 0.175976\tvalid_1's binary_logloss: 0.198331\n",
            "[340]\ttraining's binary_logloss: 0.175253\tvalid_1's binary_logloss: 0.19827\n",
            "[350]\ttraining's binary_logloss: 0.174654\tvalid_1's binary_logloss: 0.198135\n",
            "[360]\ttraining's binary_logloss: 0.173982\tvalid_1's binary_logloss: 0.198045\n",
            "[370]\ttraining's binary_logloss: 0.173347\tvalid_1's binary_logloss: 0.197978\n",
            "[380]\ttraining's binary_logloss: 0.172874\tvalid_1's binary_logloss: 0.197959\n",
            "[390]\ttraining's binary_logloss: 0.172242\tvalid_1's binary_logloss: 0.197985\n",
            "[400]\ttraining's binary_logloss: 0.171761\tvalid_1's binary_logloss: 0.198036\n",
            "[410]\ttraining's binary_logloss: 0.171039\tvalid_1's binary_logloss: 0.198242\n",
            "[420]\ttraining's binary_logloss: 0.17038\tvalid_1's binary_logloss: 0.198329\n",
            "[430]\ttraining's binary_logloss: 0.169706\tvalid_1's binary_logloss: 0.198135\n",
            "[440]\ttraining's binary_logloss: 0.169137\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.168579\tvalid_1's binary_logloss: 0.198\n",
            "[460]\ttraining's binary_logloss: 0.168062\tvalid_1's binary_logloss: 0.198135\n",
            "[470]\ttraining's binary_logloss: 0.167487\tvalid_1's binary_logloss: 0.198088\n",
            "[480]\ttraining's binary_logloss: 0.166961\tvalid_1's binary_logloss: 0.198156\n",
            "Early stopping, best iteration is:\n",
            "[386]\ttraining's binary_logloss: 0.172486\tvalid_1's binary_logloss: 0.197935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "regularization_factors, val_score: 0.197804: 100%|##########| 20/20 [00:34<00:00,  1.70s/it][I 2020-08-30 05:32:43,082] Trial 62 finished with value: 0.1979347871059169 and parameters: {'lambda_l1': 7.3332529470029615e-06, 'lambda_l2': 3.7917485628779787e-06}. Best is trial 45 with value: 0.19780442664242456.\n",
            "regularization_factors, val_score: 0.197804: 100%|##########| 20/20 [00:34<00:00,  1.73s/it]\n",
            "min_data_in_leaf, val_score: 0.197804:   0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230814\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214167\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209687\n",
            "[50]\ttraining's binary_logloss: 0.206283\tvalid_1's binary_logloss: 0.207098\n",
            "[60]\ttraining's binary_logloss: 0.203913\tvalid_1's binary_logloss: 0.205177\n",
            "[70]\ttraining's binary_logloss: 0.201935\tvalid_1's binary_logloss: 0.204143\n",
            "[80]\ttraining's binary_logloss: 0.200186\tvalid_1's binary_logloss: 0.203114\n",
            "[90]\ttraining's binary_logloss: 0.198659\tvalid_1's binary_logloss: 0.202447\n",
            "[100]\ttraining's binary_logloss: 0.197158\tvalid_1's binary_logloss: 0.201832\n",
            "[110]\ttraining's binary_logloss: 0.195591\tvalid_1's binary_logloss: 0.201135\n",
            "[120]\ttraining's binary_logloss: 0.194261\tvalid_1's binary_logloss: 0.200809\n",
            "[130]\ttraining's binary_logloss: 0.193055\tvalid_1's binary_logloss: 0.200277\n",
            "[140]\ttraining's binary_logloss: 0.191909\tvalid_1's binary_logloss: 0.200119\n",
            "[150]\ttraining's binary_logloss: 0.190795\tvalid_1's binary_logloss: 0.199935\n",
            "[160]\ttraining's binary_logloss: 0.189847\tvalid_1's binary_logloss: 0.199785\n",
            "[170]\ttraining's binary_logloss: 0.188769\tvalid_1's binary_logloss: 0.19938\n",
            "[180]\ttraining's binary_logloss: 0.187866\tvalid_1's binary_logloss: 0.199276\n",
            "[190]\ttraining's binary_logloss: 0.186765\tvalid_1's binary_logloss: 0.19896\n",
            "[200]\ttraining's binary_logloss: 0.18579\tvalid_1's binary_logloss: 0.198928\n",
            "[210]\ttraining's binary_logloss: 0.184824\tvalid_1's binary_logloss: 0.198918\n",
            "[220]\ttraining's binary_logloss: 0.18404\tvalid_1's binary_logloss: 0.198949\n",
            "[230]\ttraining's binary_logloss: 0.182995\tvalid_1's binary_logloss: 0.198814\n",
            "[240]\ttraining's binary_logloss: 0.182173\tvalid_1's binary_logloss: 0.198738\n",
            "[250]\ttraining's binary_logloss: 0.181336\tvalid_1's binary_logloss: 0.198856\n",
            "[260]\ttraining's binary_logloss: 0.180403\tvalid_1's binary_logloss: 0.198621\n",
            "[270]\ttraining's binary_logloss: 0.179665\tvalid_1's binary_logloss: 0.198645\n",
            "[280]\ttraining's binary_logloss: 0.178926\tvalid_1's binary_logloss: 0.198684\n",
            "[290]\ttraining's binary_logloss: 0.178022\tvalid_1's binary_logloss: 0.198706\n",
            "[300]\ttraining's binary_logloss: 0.177205\tvalid_1's binary_logloss: 0.198627\n",
            "[310]\ttraining's binary_logloss: 0.176346\tvalid_1's binary_logloss: 0.198484\n",
            "[320]\ttraining's binary_logloss: 0.17558\tvalid_1's binary_logloss: 0.19855\n",
            "[330]\ttraining's binary_logloss: 0.174921\tvalid_1's binary_logloss: 0.198631\n",
            "[340]\ttraining's binary_logloss: 0.174329\tvalid_1's binary_logloss: 0.198645\n",
            "[350]\ttraining's binary_logloss: 0.173698\tvalid_1's binary_logloss: 0.198619\n",
            "[360]\ttraining's binary_logloss: 0.173084\tvalid_1's binary_logloss: 0.19853\n",
            "[370]\ttraining's binary_logloss: 0.172364\tvalid_1's binary_logloss: 0.198563\n",
            "[380]\ttraining's binary_logloss: 0.171735\tvalid_1's binary_logloss: 0.198534\n",
            "[390]\ttraining's binary_logloss: 0.170958\tvalid_1's binary_logloss: 0.198658\n",
            "[400]\ttraining's binary_logloss: 0.170324\tvalid_1's binary_logloss: 0.198597\n",
            "[410]\ttraining's binary_logloss: 0.169686\tvalid_1's binary_logloss: 0.198569\n",
            "[420]\ttraining's binary_logloss: 0.169003\tvalid_1's binary_logloss: 0.198457\n",
            "[430]\ttraining's binary_logloss: 0.168418\tvalid_1's binary_logloss: 0.198273\n",
            "[440]\ttraining's binary_logloss: 0.167828\tvalid_1's binary_logloss: 0.198282\n",
            "[450]\ttraining's binary_logloss: 0.167099\tvalid_1's binary_logloss: 0.198247\n",
            "[460]\ttraining's binary_logloss: 0.166536\tvalid_1's binary_logloss: 0.198315\n",
            "[470]\ttraining's binary_logloss: 0.165953\tvalid_1's binary_logloss: 0.198344\n",
            "[480]\ttraining's binary_logloss: 0.165327\tvalid_1's binary_logloss: 0.198472\n",
            "[490]\ttraining's binary_logloss: 0.164758\tvalid_1's binary_logloss: 0.198415\n",
            "[500]\ttraining's binary_logloss: 0.164276\tvalid_1's binary_logloss: 0.198339\n",
            "[510]\ttraining's binary_logloss: 0.163625\tvalid_1's binary_logloss: 0.198389\n",
            "[520]\ttraining's binary_logloss: 0.16301\tvalid_1's binary_logloss: 0.198535\n",
            "[530]\ttraining's binary_logloss: 0.162421\tvalid_1's binary_logloss: 0.198425\n",
            "Early stopping, best iteration is:\n",
            "[432]\ttraining's binary_logloss: 0.168287\tvalid_1's binary_logloss: 0.19816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 0.197804:  20%|##        | 1/5 [00:01<00:07,  1.91s/it][I 2020-08-30 05:32:45,015] Trial 63 finished with value: 0.19815991703803562 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.19815991703803562.\n",
            "min_data_in_leaf, val_score: 0.197804:  20%|##        | 1/5 [00:01<00:07,  1.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230814\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214167\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.20973\tvalid_1's binary_logloss: 0.209642\n",
            "[50]\ttraining's binary_logloss: 0.206472\tvalid_1's binary_logloss: 0.206816\n",
            "[60]\ttraining's binary_logloss: 0.204188\tvalid_1's binary_logloss: 0.205027\n",
            "[70]\ttraining's binary_logloss: 0.202296\tvalid_1's binary_logloss: 0.20384\n",
            "[80]\ttraining's binary_logloss: 0.200486\tvalid_1's binary_logloss: 0.202618\n",
            "[90]\ttraining's binary_logloss: 0.198964\tvalid_1's binary_logloss: 0.201946\n",
            "[100]\ttraining's binary_logloss: 0.197672\tvalid_1's binary_logloss: 0.201468\n",
            "[110]\ttraining's binary_logloss: 0.196586\tvalid_1's binary_logloss: 0.200986\n",
            "[120]\ttraining's binary_logloss: 0.195403\tvalid_1's binary_logloss: 0.20056\n",
            "[130]\ttraining's binary_logloss: 0.194254\tvalid_1's binary_logloss: 0.200224\n",
            "[140]\ttraining's binary_logloss: 0.193218\tvalid_1's binary_logloss: 0.200029\n",
            "[150]\ttraining's binary_logloss: 0.192347\tvalid_1's binary_logloss: 0.199842\n",
            "[160]\ttraining's binary_logloss: 0.191557\tvalid_1's binary_logloss: 0.199632\n",
            "[170]\ttraining's binary_logloss: 0.190745\tvalid_1's binary_logloss: 0.19934\n",
            "[180]\ttraining's binary_logloss: 0.189774\tvalid_1's binary_logloss: 0.199407\n",
            "[190]\ttraining's binary_logloss: 0.188912\tvalid_1's binary_logloss: 0.199171\n",
            "[200]\ttraining's binary_logloss: 0.187851\tvalid_1's binary_logloss: 0.199113\n",
            "[210]\ttraining's binary_logloss: 0.187171\tvalid_1's binary_logloss: 0.198933\n",
            "[220]\ttraining's binary_logloss: 0.186419\tvalid_1's binary_logloss: 0.198997\n",
            "[230]\ttraining's binary_logloss: 0.18555\tvalid_1's binary_logloss: 0.198926\n",
            "[240]\ttraining's binary_logloss: 0.184689\tvalid_1's binary_logloss: 0.198647\n",
            "[250]\ttraining's binary_logloss: 0.183958\tvalid_1's binary_logloss: 0.198569\n",
            "[260]\ttraining's binary_logloss: 0.183113\tvalid_1's binary_logloss: 0.198717\n",
            "[270]\ttraining's binary_logloss: 0.182416\tvalid_1's binary_logloss: 0.198843\n",
            "[280]\ttraining's binary_logloss: 0.18159\tvalid_1's binary_logloss: 0.198653\n",
            "[290]\ttraining's binary_logloss: 0.180941\tvalid_1's binary_logloss: 0.198492\n",
            "[300]\ttraining's binary_logloss: 0.180275\tvalid_1's binary_logloss: 0.198466\n",
            "[310]\ttraining's binary_logloss: 0.179565\tvalid_1's binary_logloss: 0.198252\n",
            "[320]\ttraining's binary_logloss: 0.178901\tvalid_1's binary_logloss: 0.198043\n",
            "[330]\ttraining's binary_logloss: 0.178298\tvalid_1's binary_logloss: 0.197925\n",
            "[340]\ttraining's binary_logloss: 0.177761\tvalid_1's binary_logloss: 0.197921\n",
            "[350]\ttraining's binary_logloss: 0.177159\tvalid_1's binary_logloss: 0.19793\n",
            "[360]\ttraining's binary_logloss: 0.176673\tvalid_1's binary_logloss: 0.197941\n",
            "[370]\ttraining's binary_logloss: 0.176058\tvalid_1's binary_logloss: 0.197914\n",
            "[380]\ttraining's binary_logloss: 0.175557\tvalid_1's binary_logloss: 0.197863\n",
            "[390]\ttraining's binary_logloss: 0.1749\tvalid_1's binary_logloss: 0.197861\n",
            "[400]\ttraining's binary_logloss: 0.174315\tvalid_1's binary_logloss: 0.197879\n",
            "[410]\ttraining's binary_logloss: 0.173799\tvalid_1's binary_logloss: 0.198019\n",
            "[420]\ttraining's binary_logloss: 0.173232\tvalid_1's binary_logloss: 0.198113\n",
            "[430]\ttraining's binary_logloss: 0.172706\tvalid_1's binary_logloss: 0.198076\n",
            "[440]\ttraining's binary_logloss: 0.172243\tvalid_1's binary_logloss: 0.198082\n",
            "[450]\ttraining's binary_logloss: 0.171765\tvalid_1's binary_logloss: 0.19802\n",
            "[460]\ttraining's binary_logloss: 0.17126\tvalid_1's binary_logloss: 0.19804\n",
            "[470]\ttraining's binary_logloss: 0.170808\tvalid_1's binary_logloss: 0.198071\n",
            "[480]\ttraining's binary_logloss: 0.170367\tvalid_1's binary_logloss: 0.198155\n",
            "Early stopping, best iteration is:\n",
            "[389]\ttraining's binary_logloss: 0.174946\tvalid_1's binary_logloss: 0.197844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 0.197804:  40%|####      | 2/5 [00:03<00:05,  1.87s/it][I 2020-08-30 05:32:46,774] Trial 64 finished with value: 0.19784432254626416 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.19784432254626416.\n",
            "min_data_in_leaf, val_score: 0.197804:  40%|####      | 2/5 [00:03<00:05,  1.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230814\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214167\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209687\n",
            "[50]\ttraining's binary_logloss: 0.206379\tvalid_1's binary_logloss: 0.206924\n",
            "[60]\ttraining's binary_logloss: 0.204044\tvalid_1's binary_logloss: 0.204859\n",
            "[70]\ttraining's binary_logloss: 0.201898\tvalid_1's binary_logloss: 0.203296\n",
            "[80]\ttraining's binary_logloss: 0.200067\tvalid_1's binary_logloss: 0.202517\n",
            "[90]\ttraining's binary_logloss: 0.19858\tvalid_1's binary_logloss: 0.202046\n",
            "[100]\ttraining's binary_logloss: 0.197096\tvalid_1's binary_logloss: 0.201192\n",
            "[110]\ttraining's binary_logloss: 0.195914\tvalid_1's binary_logloss: 0.200656\n",
            "[120]\ttraining's binary_logloss: 0.194755\tvalid_1's binary_logloss: 0.200414\n",
            "[130]\ttraining's binary_logloss: 0.19363\tvalid_1's binary_logloss: 0.200101\n",
            "[140]\ttraining's binary_logloss: 0.192605\tvalid_1's binary_logloss: 0.199978\n",
            "[150]\ttraining's binary_logloss: 0.191564\tvalid_1's binary_logloss: 0.199656\n",
            "[160]\ttraining's binary_logloss: 0.190667\tvalid_1's binary_logloss: 0.199375\n",
            "[170]\ttraining's binary_logloss: 0.189683\tvalid_1's binary_logloss: 0.198956\n",
            "[180]\ttraining's binary_logloss: 0.188638\tvalid_1's binary_logloss: 0.198892\n",
            "[190]\ttraining's binary_logloss: 0.187769\tvalid_1's binary_logloss: 0.198803\n",
            "[200]\ttraining's binary_logloss: 0.186946\tvalid_1's binary_logloss: 0.198869\n",
            "[210]\ttraining's binary_logloss: 0.186162\tvalid_1's binary_logloss: 0.198771\n",
            "[220]\ttraining's binary_logloss: 0.185326\tvalid_1's binary_logloss: 0.198771\n",
            "[230]\ttraining's binary_logloss: 0.18449\tvalid_1's binary_logloss: 0.19873\n",
            "[240]\ttraining's binary_logloss: 0.183665\tvalid_1's binary_logloss: 0.198654\n",
            "[250]\ttraining's binary_logloss: 0.182976\tvalid_1's binary_logloss: 0.198621\n",
            "[260]\ttraining's binary_logloss: 0.182067\tvalid_1's binary_logloss: 0.198608\n",
            "[270]\ttraining's binary_logloss: 0.181355\tvalid_1's binary_logloss: 0.198607\n",
            "[280]\ttraining's binary_logloss: 0.180513\tvalid_1's binary_logloss: 0.198304\n",
            "[290]\ttraining's binary_logloss: 0.179912\tvalid_1's binary_logloss: 0.19814\n",
            "[300]\ttraining's binary_logloss: 0.179111\tvalid_1's binary_logloss: 0.198238\n",
            "[310]\ttraining's binary_logloss: 0.17838\tvalid_1's binary_logloss: 0.19823\n",
            "[320]\ttraining's binary_logloss: 0.177683\tvalid_1's binary_logloss: 0.198267\n",
            "[330]\ttraining's binary_logloss: 0.17706\tvalid_1's binary_logloss: 0.198265\n",
            "[340]\ttraining's binary_logloss: 0.176552\tvalid_1's binary_logloss: 0.198346\n",
            "[350]\ttraining's binary_logloss: 0.175858\tvalid_1's binary_logloss: 0.198381\n",
            "[360]\ttraining's binary_logloss: 0.175247\tvalid_1's binary_logloss: 0.198334\n",
            "[370]\ttraining's binary_logloss: 0.17461\tvalid_1's binary_logloss: 0.198278\n",
            "[380]\ttraining's binary_logloss: 0.174066\tvalid_1's binary_logloss: 0.1983\n",
            "[390]\ttraining's binary_logloss: 0.173421\tvalid_1's binary_logloss: 0.198361\n",
            "Early stopping, best iteration is:\n",
            "[296]\ttraining's binary_logloss: 0.179489\tvalid_1's binary_logloss: 0.198057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 0.197804:  60%|######    | 3/5 [00:05<00:03,  1.73s/it][I 2020-08-30 05:32:48,175] Trial 65 finished with value: 0.19805739467662622 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.19784432254626416.\n",
            "min_data_in_leaf, val_score: 0.197804:  60%|######    | 3/5 [00:05<00:03,  1.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230814\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.213958\tvalid_1's binary_logloss: 0.214164\n",
            "[40]\ttraining's binary_logloss: 0.209677\tvalid_1's binary_logloss: 0.209546\n",
            "[50]\ttraining's binary_logloss: 0.206457\tvalid_1's binary_logloss: 0.207224\n",
            "[60]\ttraining's binary_logloss: 0.203916\tvalid_1's binary_logloss: 0.205554\n",
            "[70]\ttraining's binary_logloss: 0.201654\tvalid_1's binary_logloss: 0.204233\n",
            "[80]\ttraining's binary_logloss: 0.199861\tvalid_1's binary_logloss: 0.203192\n",
            "[90]\ttraining's binary_logloss: 0.198279\tvalid_1's binary_logloss: 0.202522\n",
            "[100]\ttraining's binary_logloss: 0.196828\tvalid_1's binary_logloss: 0.201663\n",
            "[110]\ttraining's binary_logloss: 0.195445\tvalid_1's binary_logloss: 0.201107\n",
            "[120]\ttraining's binary_logloss: 0.194077\tvalid_1's binary_logloss: 0.200881\n",
            "[130]\ttraining's binary_logloss: 0.192829\tvalid_1's binary_logloss: 0.200648\n",
            "[140]\ttraining's binary_logloss: 0.191737\tvalid_1's binary_logloss: 0.200476\n",
            "[150]\ttraining's binary_logloss: 0.190602\tvalid_1's binary_logloss: 0.200394\n",
            "[160]\ttraining's binary_logloss: 0.189488\tvalid_1's binary_logloss: 0.200062\n",
            "[170]\ttraining's binary_logloss: 0.188407\tvalid_1's binary_logloss: 0.199856\n",
            "[180]\ttraining's binary_logloss: 0.187452\tvalid_1's binary_logloss: 0.199788\n",
            "[190]\ttraining's binary_logloss: 0.186517\tvalid_1's binary_logloss: 0.199635\n",
            "[200]\ttraining's binary_logloss: 0.185539\tvalid_1's binary_logloss: 0.199767\n",
            "[210]\ttraining's binary_logloss: 0.184661\tvalid_1's binary_logloss: 0.199817\n",
            "[220]\ttraining's binary_logloss: 0.183789\tvalid_1's binary_logloss: 0.199442\n",
            "[230]\ttraining's binary_logloss: 0.182844\tvalid_1's binary_logloss: 0.199323\n",
            "[240]\ttraining's binary_logloss: 0.182182\tvalid_1's binary_logloss: 0.199006\n",
            "[250]\ttraining's binary_logloss: 0.18127\tvalid_1's binary_logloss: 0.198902\n",
            "[260]\ttraining's binary_logloss: 0.1804\tvalid_1's binary_logloss: 0.19879\n",
            "[270]\ttraining's binary_logloss: 0.179635\tvalid_1's binary_logloss: 0.198848\n",
            "[280]\ttraining's binary_logloss: 0.178907\tvalid_1's binary_logloss: 0.198788\n",
            "[290]\ttraining's binary_logloss: 0.178015\tvalid_1's binary_logloss: 0.198777\n",
            "[300]\ttraining's binary_logloss: 0.17717\tvalid_1's binary_logloss: 0.198683\n",
            "[310]\ttraining's binary_logloss: 0.176387\tvalid_1's binary_logloss: 0.198622\n",
            "[320]\ttraining's binary_logloss: 0.175528\tvalid_1's binary_logloss: 0.198508\n",
            "[330]\ttraining's binary_logloss: 0.17479\tvalid_1's binary_logloss: 0.198442\n",
            "[340]\ttraining's binary_logloss: 0.174199\tvalid_1's binary_logloss: 0.198424\n",
            "[350]\ttraining's binary_logloss: 0.173299\tvalid_1's binary_logloss: 0.198429\n",
            "[360]\ttraining's binary_logloss: 0.172638\tvalid_1's binary_logloss: 0.198534\n",
            "[370]\ttraining's binary_logloss: 0.171861\tvalid_1's binary_logloss: 0.198514\n",
            "[380]\ttraining's binary_logloss: 0.171256\tvalid_1's binary_logloss: 0.198365\n",
            "[390]\ttraining's binary_logloss: 0.170564\tvalid_1's binary_logloss: 0.198613\n",
            "[400]\ttraining's binary_logloss: 0.169869\tvalid_1's binary_logloss: 0.198622\n",
            "[410]\ttraining's binary_logloss: 0.169216\tvalid_1's binary_logloss: 0.198785\n",
            "[420]\ttraining's binary_logloss: 0.168654\tvalid_1's binary_logloss: 0.198662\n",
            "[430]\ttraining's binary_logloss: 0.168123\tvalid_1's binary_logloss: 0.198748\n",
            "[440]\ttraining's binary_logloss: 0.167535\tvalid_1's binary_logloss: 0.198753\n",
            "Early stopping, best iteration is:\n",
            "[346]\ttraining's binary_logloss: 0.173655\tvalid_1's binary_logloss: 0.198342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 0.197804:  80%|########  | 4/5 [00:06<00:01,  1.69s/it][I 2020-08-30 05:32:49,788] Trial 66 finished with value: 0.1983420362595189 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.19784432254626416.\n",
            "min_data_in_leaf, val_score: 0.197804:  80%|########  | 4/5 [00:06<00:01,  1.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[10]\ttraining's binary_logloss: 0.230814\tvalid_1's binary_logloss: 0.231108\n",
            "[20]\ttraining's binary_logloss: 0.220096\tvalid_1's binary_logloss: 0.220334\n",
            "[30]\ttraining's binary_logloss: 0.214167\tvalid_1's binary_logloss: 0.214102\n",
            "[40]\ttraining's binary_logloss: 0.209689\tvalid_1's binary_logloss: 0.209687\n",
            "[50]\ttraining's binary_logloss: 0.206649\tvalid_1's binary_logloss: 0.207217\n",
            "[60]\ttraining's binary_logloss: 0.204335\tvalid_1's binary_logloss: 0.205308\n",
            "[70]\ttraining's binary_logloss: 0.202234\tvalid_1's binary_logloss: 0.204108\n",
            "[80]\ttraining's binary_logloss: 0.200443\tvalid_1's binary_logloss: 0.203397\n",
            "[90]\ttraining's binary_logloss: 0.198928\tvalid_1's binary_logloss: 0.202678\n",
            "[100]\ttraining's binary_logloss: 0.197514\tvalid_1's binary_logloss: 0.202009\n",
            "[110]\ttraining's binary_logloss: 0.196225\tvalid_1's binary_logloss: 0.2012\n",
            "[120]\ttraining's binary_logloss: 0.194875\tvalid_1's binary_logloss: 0.200953\n",
            "[130]\ttraining's binary_logloss: 0.193687\tvalid_1's binary_logloss: 0.200775\n",
            "[140]\ttraining's binary_logloss: 0.192678\tvalid_1's binary_logloss: 0.200465\n",
            "[150]\ttraining's binary_logloss: 0.191493\tvalid_1's binary_logloss: 0.200288\n",
            "[160]\ttraining's binary_logloss: 0.190349\tvalid_1's binary_logloss: 0.199861\n",
            "[170]\ttraining's binary_logloss: 0.189451\tvalid_1's binary_logloss: 0.199539\n",
            "[180]\ttraining's binary_logloss: 0.188445\tvalid_1's binary_logloss: 0.199316\n",
            "[190]\ttraining's binary_logloss: 0.187378\tvalid_1's binary_logloss: 0.198981\n",
            "[200]\ttraining's binary_logloss: 0.186455\tvalid_1's binary_logloss: 0.199139\n",
            "[210]\ttraining's binary_logloss: 0.185686\tvalid_1's binary_logloss: 0.198857\n",
            "[220]\ttraining's binary_logloss: 0.184799\tvalid_1's binary_logloss: 0.198826\n",
            "[230]\ttraining's binary_logloss: 0.183996\tvalid_1's binary_logloss: 0.19872\n",
            "[240]\ttraining's binary_logloss: 0.183159\tvalid_1's binary_logloss: 0.198572\n",
            "[250]\ttraining's binary_logloss: 0.182269\tvalid_1's binary_logloss: 0.198497\n",
            "[260]\ttraining's binary_logloss: 0.181441\tvalid_1's binary_logloss: 0.198489\n",
            "[270]\ttraining's binary_logloss: 0.180678\tvalid_1's binary_logloss: 0.198466\n",
            "[280]\ttraining's binary_logloss: 0.179974\tvalid_1's binary_logloss: 0.198301\n",
            "[290]\ttraining's binary_logloss: 0.179286\tvalid_1's binary_logloss: 0.198302\n",
            "[300]\ttraining's binary_logloss: 0.178529\tvalid_1's binary_logloss: 0.198293\n",
            "[310]\ttraining's binary_logloss: 0.177813\tvalid_1's binary_logloss: 0.198242\n",
            "[320]\ttraining's binary_logloss: 0.177124\tvalid_1's binary_logloss: 0.198306\n",
            "[330]\ttraining's binary_logloss: 0.176245\tvalid_1's binary_logloss: 0.198206\n",
            "[340]\ttraining's binary_logloss: 0.175495\tvalid_1's binary_logloss: 0.198187\n",
            "[350]\ttraining's binary_logloss: 0.174742\tvalid_1's binary_logloss: 0.197966\n",
            "[360]\ttraining's binary_logloss: 0.174202\tvalid_1's binary_logloss: 0.198005\n",
            "[370]\ttraining's binary_logloss: 0.17353\tvalid_1's binary_logloss: 0.197914\n",
            "[380]\ttraining's binary_logloss: 0.172905\tvalid_1's binary_logloss: 0.197832\n",
            "[390]\ttraining's binary_logloss: 0.172266\tvalid_1's binary_logloss: 0.1979\n",
            "[400]\ttraining's binary_logloss: 0.171677\tvalid_1's binary_logloss: 0.197877\n",
            "[410]\ttraining's binary_logloss: 0.171001\tvalid_1's binary_logloss: 0.197963\n",
            "[420]\ttraining's binary_logloss: 0.170413\tvalid_1's binary_logloss: 0.197985\n",
            "[430]\ttraining's binary_logloss: 0.169723\tvalid_1's binary_logloss: 0.197842\n",
            "[440]\ttraining's binary_logloss: 0.169146\tvalid_1's binary_logloss: 0.197877\n",
            "[450]\ttraining's binary_logloss: 0.16865\tvalid_1's binary_logloss: 0.197848\n",
            "[460]\ttraining's binary_logloss: 0.168009\tvalid_1's binary_logloss: 0.197972\n",
            "[470]\ttraining's binary_logloss: 0.167491\tvalid_1's binary_logloss: 0.197928\n",
            "Early stopping, best iteration is:\n",
            "[378]\ttraining's binary_logloss: 0.173013\tvalid_1's binary_logloss: 0.197795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "min_data_in_leaf, val_score: 0.197795: 100%|##########| 5/5 [00:08<00:00,  1.69s/it][I 2020-08-30 05:32:51,485] Trial 67 finished with value: 0.19779466846646243 and parameters: {'min_child_samples': 25}. Best is trial 67 with value: 0.19779466846646243.\n",
            "min_data_in_leaf, val_score: 0.197795: 100%|##########| 5/5 [00:08<00:00,  1.68s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sFBiJLq-r39",
        "colab_type": "text"
      },
      "source": [
        "# バリデーション"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYtdKKZq-stW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9407377-8ad6-492a-892c-dfca2e4cbeb6"
      },
      "source": [
        "y_valid_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
        "accuracy = accuracy_score(y_valid, y_valid_pred.round())\n",
        "accuracy"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9347785977859778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l3kfPrH6foE",
        "colab_type": "text"
      },
      "source": [
        "# 重要度出力"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMiRgfe66ohU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "43d3a543-4054-4478-a0de-d81d9df983ad"
      },
      "source": [
        "cols = list(X_train.columns)\n",
        "f_importance = np.array(model.feature_importance())\n",
        "df_importance = pd.DataFrame({'feature':cols, 'importance':f_importance})\n",
        "df_importance = df_importance.sort_values('importance', ascending=False)\n",
        "plt.barh(df_importance['feature'], df_importance['importance'])\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WdZkcTT8J19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f16354b2-674f-4861-d305-5ba11a7a39b3"
      },
      "source": [
        "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
        "print(y_pred)\n",
        "# 反応率を出力"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.76816576 0.07361535 0.01893207 ... 0.05854702 0.0024952  0.1136031 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTFH7iEpAp2A",
        "colab_type": "text"
      },
      "source": [
        "# 提出ファイル作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dju3djfpAtEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6bb2782f-62a0-4197-d4d5-8868f6d0532f"
      },
      "source": [
        "submit_df[1]=y_pred\n",
        "submit_df.to_csv('beginner-'+datetime.date.today().isoformat()+\".csv\", index=False, header=False) #headerなしで出力\n",
        "files.download('beginner-'+datetime.date.today().isoformat()+\".csv\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_e62d03a5-b55c-49e6-ad1e-813180eb11c4\", \"beginner-2020-08-30.csv\", 465196)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}